{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhsDF_5UdqLI"
   },
   "source": [
    "# Menjalankan QA Tanpa Intermediate Task - Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKm8qASDXqR-"
   },
   "source": [
    "# Import semua module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DH9DifnXp5_",
    "outputId": "94161dcf-e635-486d-c6d8-5747b267b64f"
   },
   "outputs": [],
   "source": [
    "#!pip install datasets\n",
    "#!pip install transformers\n",
    "#!pip install tensorboard\n",
    "#!pip install evaluate\n",
    "#!pip install git+https://github.com/IndoNLP/nusa-crowd.git@release_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nusacrowd@ git+https://github.com/IndoNLP/nusa-crowd.git@7748513d20331e72f9969f94f5d43c7f2d4a59a5\n",
      "  Cloning https://github.com/IndoNLP/nusa-crowd.git (to revision 7748513d20331e72f9969f94f5d43c7f2d4a59a5) to /tmp/pip-install-i60hyohe/nusacrowd_b8fd39892f6a409c99b4227a9c4ffcb7\n",
      "  Running command git clone --filter=blob:none -q https://github.com/IndoNLP/nusa-crowd.git /tmp/pip-install-i60hyohe/nusacrowd_b8fd39892f6a409c99b4227a9c4ffcb7\n",
      "  Running command git rev-parse -q --verify 'sha^7748513d20331e72f9969f94f5d43c7f2d4a59a5'\n",
      "  Running command git fetch -q https://github.com/IndoNLP/nusa-crowd.git 7748513d20331e72f9969f94f5d43c7f2d4a59a5\n",
      "  Running command git checkout -q 7748513d20331e72f9969f94f5d43c7f2d4a59a5\n",
      "  Resolved https://github.com/IndoNLP/nusa-crowd.git to commit 7748513d20331e72f9969f94f5d43c7f2d4a59a5\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py==1.4.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: aiohttp==3.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (3.8.1)\n",
      "Requirement already satisfied: aiosignal==1.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: appdirs==1.4.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.4.4)\n",
      "Requirement already satisfied: async-timeout==4.0.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (4.0.2)\n",
      "Requirement already satisfied: attrs==22.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (22.2.0)\n",
      "Requirement already satisfied: audioread==3.0.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: bioc==1.3.7 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (1.3.7)\n",
      "Requirement already satisfied: black==22.12.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (22.12.0)\n",
      "Requirement already satisfied: cachetools==5.3.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (5.3.0)\n",
      "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (2022.12.7)\n",
      "Requirement already satisfied: cffi==1.15.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (1.15.1)\n",
      "Requirement already satisfied: cfgv==3.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (3.3.1)\n",
      "Requirement already satisfied: charset-normalizer==2.1.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 14)) (2.1.1)\n",
      "Requirement already satisfied: click==8.1.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 15)) (8.1.3)\n",
      "Requirement already satisfied: colorama==0.4.6 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 16)) (0.4.6)\n",
      "Requirement already satisfied: conllu==4.5.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 17)) (4.5.2)\n",
      "Requirement already satisfied: datasets==2.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 18)) (2.2.0)\n",
      "Requirement already satisfied: decorator==5.1.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 19)) (5.1.1)\n",
      "Requirement already satisfied: dill==0.3.6 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 20)) (0.3.6)\n",
      "Requirement already satisfied: distlib==0.3.6 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 21)) (0.3.6)\n",
      "Requirement already satisfied: docutils==0.19 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 22)) (0.19)\n",
      "Requirement already satisfied: et-xmlfile==1.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 23)) (1.1.0)\n",
      "Requirement already satisfied: evaluate==0.4.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 24)) (0.4.0)\n",
      "Requirement already satisfied: ffmpeg==1.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 25)) (1.4)\n",
      "Requirement already satisfied: filelock==3.9.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 26)) (3.9.0)\n",
      "Requirement already satisfied: flake8==6.0.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 27)) (6.0.0)\n",
      "Requirement already satisfied: frozenlist==1.3.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 28)) (1.3.3)\n",
      "Requirement already satisfied: fsspec==2023.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 29)) (2023.1.0)\n",
      "Requirement already satisfied: git-lfs==1.6 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 30)) (1.6)\n",
      "Requirement already satisfied: google-auth==2.16.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 31)) (2.16.1)\n",
      "Requirement already satisfied: google-auth-oauthlib==0.4.6 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 32)) (0.4.6)\n",
      "Requirement already satisfied: grpcio==1.51.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 33)) (1.51.1)\n",
      "Requirement already satisfied: huggingface-hub==0.12.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 34)) (0.12.1)\n",
      "Requirement already satisfied: identify==2.5.18 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 35)) (2.5.18)\n",
      "Requirement already satisfied: idna==3.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 36)) (3.4)\n",
      "Requirement already satisfied: importlib-metadata==6.0.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 37)) (6.0.0)\n",
      "Requirement already satisfied: isort==5.12.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 38)) (5.12.0)\n",
      "Requirement already satisfied: joblib==1.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 39)) (1.2.0)\n",
      "Requirement already satisfied: jsonlines==3.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 40)) (3.1.0)\n",
      "Requirement already satisfied: librosa==0.9.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 41)) (0.9.2)\n",
      "Requirement already satisfied: llvmlite==0.39.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 42)) (0.39.1)\n",
      "Requirement already satisfied: loguru==0.5.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 43)) (0.5.3)\n",
      "Requirement already satisfied: lxml==4.9.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 44)) (4.9.2)\n",
      "Requirement already satisfied: Markdown==3.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 45)) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe==2.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 46)) (2.1.2)\n",
      "Requirement already satisfied: mccabe==0.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 47)) (0.7.0)\n",
      "Requirement already satisfied: multidict==6.0.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 48)) (6.0.4)\n",
      "Requirement already satisfied: multiprocess==0.70.14 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 49)) (0.70.14)\n",
      "Requirement already satisfied: mypy-extensions==1.0.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 50)) (1.0.0)\n",
      "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 51)) (3.8.1)\n",
      "Requirement already satisfied: nodeenv==1.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 52)) (1.7.0)\n",
      "Requirement already satisfied: numba==0.56.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 53)) (0.56.4)\n",
      "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 54)) (1.23.5)\n",
      "Requirement already satisfied: oauthlib==3.2.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 56)) (3.2.2)\n",
      "Requirement already satisfied: openpyxl==3.1.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 57)) (3.1.1)\n",
      "Requirement already satisfied: packaging==23.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 58)) (23.0)\n",
      "Requirement already satisfied: pandas==1.3.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 59)) (1.3.3)\n",
      "Requirement already satisfied: pathspec==0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 60)) (0.11.0)\n",
      "Requirement already satisfied: platformdirs==3.0.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 61)) (3.0.0)\n",
      "Requirement already satisfied: pooch==1.6.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 62)) (1.6.0)\n",
      "Requirement already satisfied: pre-commit==2.19.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 63)) (2.19.0)\n",
      "Requirement already satisfied: protobuf==4.22.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 64)) (4.22.0)\n",
      "Requirement already satisfied: pyarrow==11.0.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 65)) (11.0.0)\n",
      "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 66)) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 67)) (0.2.8)\n",
      "Requirement already satisfied: pycodestyle==2.10.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 68)) (2.10.0)\n",
      "Requirement already satisfied: pycparser==2.21 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 69)) (2.21)\n",
      "Requirement already satisfied: pyflakes==3.0.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 70)) (3.0.1)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 71)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.7.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 72)) (2022.7.1)\n",
      "Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 73)) (6.0)\n",
      "Requirement already satisfied: regex==2022.10.31 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 74)) (2022.10.31)\n",
      "Requirement already satisfied: requests==2.28.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 75)) (2.28.2)\n",
      "Requirement already satisfied: requests-oauthlib==1.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 76)) (1.3.1)\n",
      "Requirement already satisfied: resampy==0.4.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 77)) (0.4.2)\n",
      "Requirement already satisfied: responses==0.18.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 78)) (0.18.0)\n",
      "Requirement already satisfied: rsa==4.9 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 79)) (4.9)\n",
      "Requirement already satisfied: scikit-learn==1.2.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 80)) (1.2.1)\n",
      "Requirement already satisfied: scipy==1.10.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 81)) (1.10.0)\n",
      "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 82)) (1.16.0)\n",
      "Requirement already satisfied: soundfile==0.12.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 83)) (0.12.1)\n",
      "Requirement already satisfied: tensorboard==2.12.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 84)) (2.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server==0.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 85)) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit==1.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 86)) (1.8.1)\n",
      "Requirement already satisfied: termcolor==2.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 87)) (2.2.0)\n",
      "Requirement already satisfied: threadpoolctl==3.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 88)) (3.1.0)\n",
      "Requirement already satisfied: tokenizers==0.13.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 89)) (0.13.2)\n",
      "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 90)) (0.10.2)\n",
      "Requirement already satisfied: tomli==2.0.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 91)) (2.0.1)\n",
      "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 92)) (1.13.1)\n",
      "Requirement already satisfied: torchaudio==0.13.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 93)) (0.13.1)\n",
      "Requirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 94)) (4.64.1)\n",
      "Requirement already satisfied: transformers==4.26.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 95)) (4.26.1)\n",
      "Requirement already satisfied: translate-toolkit==3.8.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 96)) (3.8.4)\n",
      "Requirement already satisfied: typing_extensions==4.5.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 97)) (4.5.0)\n",
      "Requirement already satisfied: urllib3==1.26.14 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 98)) (1.26.14)\n",
      "Requirement already satisfied: virtualenv==20.19.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 99)) (20.19.0)\n",
      "Requirement already satisfied: Werkzeug==2.2.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 100)) (2.2.3)\n",
      "Requirement already satisfied: win32-setctime==1.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 101)) (1.1.0)\n",
      "Requirement already satisfied: xxhash==3.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 102)) (3.2.0)\n",
      "Requirement already satisfied: yarl==1.8.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 103)) (1.8.2)\n",
      "Requirement already satisfied: zipp==3.14.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 104)) (3.14.0)\n",
      "Requirement already satisfied: zstandard==0.19.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 105)) (0.19.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nodeenv==1.7.0->-r requirements.txt (line 52)) (45.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard==2.12.0->-r requirements.txt (line 84)) (0.34.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->-r requirements.txt (line 92)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->-r requirements.txt (line 92)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->-r requirements.txt (line 92)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->-r requirements.txt (line 92)) (11.10.3.66)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 10 10:50:34 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.126.02   Driver Version: 418.126.02   CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    44W / 300W |     11MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   47C    P0   253W / 300W |  24686MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    44W / 300W |     11MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    43W / 300W |     11MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    59W / 300W |  10310MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    58W / 300W |   8628MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    44W / 300W |     11MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    56W / 300W |  12914MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Melihat GPU yang tersedia dan penggunaannya.\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memilih GPU yang akan digunakan (contohnya: GPU #7)\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pgY_FL4lXuEu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import evaluate\n",
    "import torch\n",
    "import operator\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from evaluate import load\n",
    "from nusacrowd import NusantaraConfigHelper\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from huggingface_hub import notebook_login\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import (\n",
    "    load_dataset, \n",
    "    load_from_disk,\n",
    "    Dataset,\n",
    "    DatasetDict\n",
    ")\n",
    "from transformers import (\n",
    "    BigBirdTokenizerFast,\n",
    "    BigBirdForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BertForSequenceClassification,\n",
    "    BertForQuestionAnswering,\n",
    "    AutoModel, \n",
    "    BertTokenizerFast,\n",
    "    AutoTokenizer, \n",
    "    AutoModel, \n",
    "    BertTokenizer, \n",
    "    BertForPreTraining,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    EvalPrediction,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtu0yFqMYsX9"
   },
   "source": [
    "# Definisikan hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gjHJwpxeYugs"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"indolem/indobert-base-uncased\"\n",
    "#MODEL_NAME = \"afaji/fine-tuned-IndoNLI-Translated-with-indobert-base-uncased\"\n",
    "SEED = 42\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 32\n",
    "GRADIENT_ACCUMULATION = 4\n",
    "LEARNING_RATE = 1e-5\n",
    "MAX_LENGTH = 400\n",
    "STRIDE = 100\n",
    "LOGGING_STEPS = 50\n",
    "WARMUP_RATIO = 0.06\n",
    "WEIGHT_DECAY = 0.01\n",
    "# Untuk mempercepat training, saya ubah SAMPLE menjadi 100.\n",
    "# Bila mau menggunakan keseluruhan data, gunakan: \n",
    "SAMPLE = sys.maxsize\n",
    "# SAMPLE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyH7dlPGYOSk"
   },
   "source": [
    "# Import dataset QAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/IndoNLP/nusa-crowd.git\n",
      "  Cloning https://github.com/IndoNLP/nusa-crowd.git to /tmp/pip-req-build-loyehmwa\n",
      "  Running command git clone --filter=blob:none -q https://github.com/IndoNLP/nusa-crowd.git /tmp/pip-req-build-loyehmwa\n",
      "  Resolved https://github.com/IndoNLP/nusa-crowd.git to commit bea0aedb653c65d2dbc65a5f7b6950bd2cad274d\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: aiohttp==3.8.1 in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (3.8.1)\n",
      "Requirement already satisfied: bioc==1.3.7 in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (1.3.7)\n",
      "Requirement already satisfied: black~=22.0 in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (22.12.0)\n",
      "Requirement already satisfied: conllu in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (4.5.2)\n",
      "Requirement already satisfied: datasets==2.2.0 in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (2.2.0)\n",
      "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (1.4)\n",
      "Requirement already satisfied: flake8>=3.8.3 in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (6.0.0)\n",
      "Requirement already satisfied: isort>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (5.12.0)\n",
      "Requirement already satisfied: jsonlines>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (3.1.0)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (0.9.2)\n",
      "Requirement already satisfied: loguru==0.5.3 in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (0.5.3)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (1.23.5)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (3.1.1)\n",
      "Requirement already satisfied: pandas==1.3.3 in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (1.3.3)\n",
      "Requirement already satisfied: pre-commit==2.19.0 in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (2.19.0)\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (0.12.1)\n",
      "Requirement already satisfied: torchaudio>=0.11 in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (0.13.1)\n",
      "Requirement already satisfied: translate-toolkit>=3.7.3 in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (3.8.4)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (4.5.0)\n",
      "Requirement already satisfied: zstandard in /usr/local/lib/python3.8/dist-packages (from nusacrowd==0.0.1) (0.19.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp==3.8.1->nusacrowd==0.0.1) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp==3.8.1->nusacrowd==0.0.1) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp==3.8.1->nusacrowd==0.0.1) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp==3.8.1->nusacrowd==0.0.1) (2.1.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp==3.8.1->nusacrowd==0.0.1) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp==3.8.1->nusacrowd==0.0.1) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp==3.8.1->nusacrowd==0.0.1) (1.3.3)\n",
      "Requirement already satisfied: lxml>=4.6.3 in /usr/local/lib/python3.8/dist-packages (from bioc==1.3.7->nusacrowd==0.0.1) (4.9.2)\n",
      "Requirement already satisfied: docutils>=0.15.2 in /usr/local/lib/python3.8/dist-packages (from bioc==1.3.7->nusacrowd==0.0.1) (0.19)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.2.0->nusacrowd==0.0.1) (0.12.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets==2.2.0->nusacrowd==0.0.1) (23.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets==2.2.0->nusacrowd==0.0.1) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets==2.2.0->nusacrowd==0.0.1) (0.70.14)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets==2.2.0->nusacrowd==0.0.1) (4.64.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.2.0->nusacrowd==0.0.1) (11.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.2.0->nusacrowd==0.0.1) (2.28.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets==2.2.0->nusacrowd==0.0.1) (3.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from datasets==2.2.0->nusacrowd==0.0.1) (2023.1.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from datasets==2.2.0->nusacrowd==0.0.1) (0.3.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.3.3->nusacrowd==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.3.3->nusacrowd==0.0.1) (2022.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from pre-commit==2.19.0->nusacrowd==0.0.1) (6.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from pre-commit==2.19.0->nusacrowd==0.0.1) (3.3.1)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from pre-commit==2.19.0->nusacrowd==0.0.1) (1.7.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from pre-commit==2.19.0->nusacrowd==0.0.1) (0.10.2)\n",
      "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from pre-commit==2.19.0->nusacrowd==0.0.1) (2.5.18)\n",
      "Requirement already satisfied: virtualenv>=20.0.8 in /usr/local/lib/python3.8/dist-packages (from pre-commit==2.19.0->nusacrowd==0.0.1) (20.19.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from black~=22.0->nusacrowd==0.0.1) (0.11.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black~=22.0->nusacrowd==0.0.1) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.8/dist-packages (from black~=22.0->nusacrowd==0.0.1) (8.1.3)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black~=22.0->nusacrowd==0.0.1) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.8/dist-packages (from black~=22.0->nusacrowd==0.0.1) (1.0.0)\n",
      "Requirement already satisfied: pyflakes<3.1.0,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from flake8>=3.8.3->nusacrowd==0.0.1) (3.0.1)\n",
      "Requirement already satisfied: pycodestyle<2.11.0,>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from flake8>=3.8.3->nusacrowd==0.0.1) (2.10.0)\n",
      "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from flake8>=3.8.3->nusacrowd==0.0.1) (0.7.0)\n",
      "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchaudio>=0.11->nusacrowd==0.0.1) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchaudio>=0.11->nusacrowd==0.0.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchaudio>=0.11->nusacrowd==0.0.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchaudio>=0.11->nusacrowd==0.0.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchaudio>=0.11->nusacrowd==0.0.1) (11.10.3.66)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchaudio>=0.11->nusacrowd==0.0.1) (45.2.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchaudio>=0.11->nusacrowd==0.0.1) (0.34.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from librosa->nusacrowd==0.0.1) (1.10.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa->nusacrowd==0.0.1) (1.2.0)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa->nusacrowd==0.0.1) (1.6.0)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.8/dist-packages (from librosa->nusacrowd==0.0.1) (5.1.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa->nusacrowd==0.0.1) (0.4.2)\n",
      "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.8/dist-packages (from librosa->nusacrowd==0.0.1) (0.56.4)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from librosa->nusacrowd==0.0.1) (1.2.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.8/dist-packages (from librosa->nusacrowd==0.0.1) (3.0.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile->nusacrowd==0.0.1) (1.15.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->nusacrowd==0.0.1) (2022.10.31)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl->nusacrowd==0.0.1) (1.1.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile->nusacrowd==0.0.1) (2.21)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.2.0->nusacrowd==0.0.1) (3.9.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.45.1->librosa->nusacrowd==0.0.1) (0.39.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.45.1->librosa->nusacrowd==0.0.1) (6.0.0)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa->nusacrowd==0.0.1) (1.4.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.3->nusacrowd==0.0.1) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.2.0->nusacrowd==0.0.1) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.2.0->nusacrowd==0.0.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==2.2.0->nusacrowd==0.0.1) (2022.12.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19.1->librosa->nusacrowd==0.0.1) (3.1.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.8->pre-commit==2.19.0->nusacrowd==0.0.1) (0.3.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.45.1->librosa->nusacrowd==0.0.1) (3.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/IndoNLP/nusa-crowd.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlNhPlmDY2tk"
   },
   "source": [
    "# Definisikan tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "z3uXWOkUY4GD"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYYbFXzWYTr3"
   },
   "source": [
    "# Definisikan fungsi pre-processnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset s_qu_ad_id_dataset (/root/.cache/huggingface/datasets/s_qu_ad_id_dataset/squad_id_source/1.0.0/e1e15a705d3cdb2ce8a2f55db6b8de7355eabe707dcb6ca309972d0d160c2011)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15b9bd4df9a440ba29fe29f02edf441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 11873/11873 [00:22<00:00, 531.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 130319/130319 [08:53<00:00, 244.28it/s]\n"
     ]
    }
   ],
   "source": [
    "conhelps = NusantaraConfigHelper()\n",
    "data_qas_id = conhelps.filtered(lambda x: 'squad_id' in x.dataset_name)[0].load_dataset()\n",
    "\n",
    "df_train = pd.DataFrame(data_qas_id['train'])\n",
    "df_validation = pd.DataFrame(data_qas_id['validation'])\n",
    "\n",
    "cols = ['context', 'question', 'answer']\n",
    "new_df_val = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(df_validation['context']))):\n",
    "    new_df_val = new_df_val.append({'context': df_validation[\"context\"][i], \n",
    "                                    'question': df_validation[\"question\"][i], \n",
    "                                    'answer': {\"text\": eval(df_validation[\"answer\"][i][0])['text'], \n",
    "                                    \"answer_start\": eval(df_validation[\"answer\"][i][0])['answer_start'], \n",
    "                                    \"answer_end\": eval(df_validation[\"answer\"][i][0])['answer_end']}}, \n",
    "                                ignore_index=True)\n",
    "\n",
    "cols = ['context', 'question', 'answer']\n",
    "new_df_train = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(df_train['context']))):\n",
    "    new_df_train = new_df_train.append({'context': df_train[\"context\"][i], \n",
    "                                    'question': df_train[\"question\"][i], \n",
    "                                    'answer': {\"text\": eval(df_train[\"answer\"][i][0])['text'], \n",
    "                                    \"answer_start\": eval(df_train[\"answer\"][i][0])['answer_start'], \n",
    "                                    \"answer_end\": eval(df_train[\"answer\"][i][0])['answer_end']}}, \n",
    "                                ignore_index=True)\n",
    "\n",
    "train_dataset = Dataset.from_dict(new_df_train)\n",
    "validation_dataset = Dataset.from_dict(new_df_val)\n",
    "\n",
    "data_qas_id = DatasetDict({\"train\": train_dataset, \"validation\": validation_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "EuSjYelvXJ9x"
   },
   "outputs": [],
   "source": [
    "def rindex(lst, value, operator=operator):\n",
    "      return len(lst) - operator.indexOf(reversed(lst), value) - 1\n",
    "\n",
    "def preprocess_function_qa(examples, tokenizer, MAX_LENGTH=MAX_LENGTH, STRIDE=STRIDE, rindex=rindex, operator=operator):\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    examples[\"context\"] = [c.lstrip() for c in examples[\"context\"]]\n",
    "\n",
    "    tokenized_examples = tokenizer(\n",
    "      examples['question'],\n",
    "      examples['context'],\n",
    "      truncation=True,\n",
    "      max_length = MAX_LENGTH,\n",
    "      stride=STRIDE,\n",
    "      return_overflowing_tokens=True,\n",
    "      return_offsets_mapping=True,\n",
    "      padding=\"max_length\",\n",
    "      return_tensors='np'\n",
    "    )\n",
    "\n",
    "    tokenized_examples['start_positions'] = []\n",
    "    tokenized_examples['end_positions'] = []\n",
    "\n",
    "    for seq_idx in range(len(tokenized_examples['input_ids'])):\n",
    "        seq_ids = tokenized_examples.sequence_ids(seq_idx)\n",
    "        offset_mappings = tokenized_examples['offset_mapping'][seq_idx]\n",
    "\n",
    "        cur_example_idx = tokenized_examples['overflow_to_sample_mapping'][seq_idx]\n",
    "\n",
    "        #answer = examples['answer'][seq_idx][0]\n",
    "        answer = examples['answer'][cur_example_idx]\n",
    "        answer = eval(str(answer))\n",
    "        #answer_text = answer['text'][0]\n",
    "        answer_start = answer['answer_start']\n",
    "        #answer_end = answer_start + len(answer_text)\n",
    "        answer_end = answer['answer_end']\n",
    "\n",
    "        context_pos_start = seq_ids.index(1)\n",
    "        context_pos_end = rindex(seq_ids, 1, operator)\n",
    "\n",
    "        s = e = 0\n",
    "        if (offset_mappings[context_pos_start][0] <= answer_start and\n",
    "            offset_mappings[context_pos_end][1] >= answer_end):\n",
    "          i = context_pos_start\n",
    "          while offset_mappings[i][0] < answer_start:\n",
    "            i += 1\n",
    "          if offset_mappings[i][0] == answer_start:\n",
    "            s = i\n",
    "          else:\n",
    "            s = i - 1\n",
    "\n",
    "          j = context_pos_end\n",
    "          while offset_mappings[j][1] > answer_end:\n",
    "            j -= 1      \n",
    "          if offset_mappings[j][1] == answer_end:\n",
    "            e = j\n",
    "          else:\n",
    "            e = j + 1\n",
    "\n",
    "        tokenized_examples['start_positions'].append(s)\n",
    "        tokenized_examples['end_positions'].append(e)\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0o9vkQ1YaO2"
   },
   "source": [
    "# Mulai tokenisasi dan pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217,
     "referenced_widgets": [
      "2721b15477d741519a3041a8f256575b",
      "6a373f9cb48a481d85803f0792ff27b3",
      "54a2637e8c8e4ca0917e35f4b58b48f3",
      "7dc3dc97044c48afb06a14575fc8e91b",
      "6c3c7e4da5af40b088f3046d7698edff",
      "a040ab99cb964c32a0a968d97dd55a16",
      "9ef8c0b24cb5490b8fa7e8ea8ad619fe",
      "dce089e985634a67a381bc85cbaca017",
      "bd9cb96d5a3c4400bb7d145590540a54",
      "f940438113734ccdb198efd12b8a3936",
      "c5b567cd34b340dea77cefd40e9aaec9",
      "6516c5b02aa24db2bc42cdd4d1f2c260",
      "cbed771e77314789bf8817404e5d6f67",
      "b0be384a887847e981868df7c551d3de",
      "10fb50db270449b48382c815904245a8",
      "b23174d38e3940718252770bd39177f8",
      "7b80b681b46b4671a14a7cf82fd50991",
      "bce02c83fbc142c5bb2d8c1f905a478d",
      "12c3fd408f914038acb511c4ef57f965",
      "540c7fcbf3b14e538cba18329bc1fc20",
      "fc7073fb093543fc990abc620348c1ca",
      "acac4d071be4488fbb272df63b625213",
      "29b13cbb638947d5a17071d299e2420f",
      "113ae282ca5a499a8a2ad36a796e763f",
      "0ce874e529474f478a7acd45b4ffd649",
      "935752d8733c41fbb25ed436606352ca",
      "cf2b519cc5ff446dae45afa2439c840e",
      "f10632530a1b499ba3d20f0286446bab",
      "94da3d6dfccc4a289c659b94bcc90658",
      "902bd6c12ea54039b8c913a7c1782ff4",
      "1d86de7f1fbf452892fe6d4b177558f9",
      "3f6183fb8ca348e0ac35b495681c705a",
      "bdf2cb9d10cc4b2aab466a9dfe7be5bc",
      "c069967001a542f5b0c3b88ff1841eba",
      "f46e4c24b9294ffdb25e1e64bc594eee",
      "14a450c5594148c3a4ca340521d167ba",
      "9c9b27a0b2ac4be3b8dcbb65e23b84a2",
      "c99472b37d644d63a471b65ecbe3bfbd",
      "e9ca9f63982744aba53e883882373160",
      "4f80ae88d884407ab8f9e08aa58632a4",
      "13ea541bb13b42738e74885a2c1db8df",
      "68818d7eea5849afa82c3003a57a5b8d",
      "065d96b02c7840019af97e3c135693a8",
      "45f8bfb31705441c80a22dbb955dd933"
     ]
    },
    "id": "uVGfobd8XNIF",
    "outputId": "9b911f15-dce5-456f-a0fd-446f9615be1c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.fingerprint:Parameter 'fn_kwargs'={'tokenizer': BertTokenizerFast(name_or_path='indolem/indobert-base-uncased', vocab_size=31923, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), 'MAX_LENGTH': 400, 'STRIDE': 100, 'rindex': <function rindex at 0x7fd74c4ab160>, 'operator': <module 'operator' from '/usr/lib/python3.8/operator.py'>} of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc759bd6778646909e48ec22ecfce12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc412a3fc7b417a9bbaa531f54db216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data_qas_id = data_qas_id.map(\n",
    "    preprocess_function_qa,\n",
    "    batched=True,\n",
    "    remove_columns=data_qas_id['train'].column_names,\n",
    "    num_proc=1,\n",
    "    fn_kwargs={'tokenizer': tokenizer, 'MAX_LENGTH': MAX_LENGTH, 'STRIDE': STRIDE, 'rindex': rindex, 'operator': operator}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data_qas_id = tokenized_data_qas_id.remove_columns([\"offset_mapping\", \n",
    "                                            \"overflow_to_sample_mapping\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Fk1RbGEeldvi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_data_qas_id.set_format(\"torch\", columns=[\"input_ids\", \"token_type_ids\"], output_all_columns=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SLfcGWQEjd36"
   },
   "outputs": [],
   "source": [
    "tokenized_data_qas_id_train = Dataset.from_dict(tokenized_data_qas_id[\"train\"][:SAMPLE])\n",
    "tokenized_data_qas_id_validation = Dataset.from_dict(tokenized_data_qas_id[\"validation\"][:SAMPLE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06_Y5Xw9bLj3"
   },
   "source": [
    "# Mendefinisikan argumen (dataops) untuk training nanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "foTQgHuujf46"
   },
   "outputs": [],
   "source": [
    "TIME_NOW = str(datetime.now()).replace(\":\", \"-\").replace(\" \", \"_\").replace(\".\", \"_\")\n",
    "QA = './results/alur2-idk-mrc'\n",
    "CHECKPOINT_DIR = f'{QA}-{TIME_NOW}/checkpoint/'\n",
    "MODEL_DIR = f'{QA}-{TIME_NOW}/model/'\n",
    "OUTPUT_DIR = f'{QA}-{TIME_NOW}/output/'\n",
    "ACCURACY_DIR = f'{QA}-{TIME_NOW}/accuracy/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9YdVKNRbPHk"
   },
   "source": [
    "# Mendefinisikan Training Arguments untuk train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3VMs4pBjgXE",
    "outputId": "577270d3-fe73-44be-f1c2-e710bb5e1d1b"
   },
   "outputs": [],
   "source": [
    "training_args_qa = TrainingArguments(\n",
    "    \n",
    "    # Checkpoint\n",
    "    output_dir=CHECKPOINT_DIR,\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=EPOCH,\n",
    "    \n",
    "    # Log\n",
    "    report_to='tensorboard',\n",
    "    logging_strategy='steps',\n",
    "    logging_first_step=True,\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    \n",
    "    # Train\n",
    "    num_train_epochs=EPOCH,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    bf16=False,\n",
    "    dataloader_num_workers=cpu_count(),\n",
    "    \n",
    "    # Miscellaneous\n",
    "    evaluation_strategy='epoch',\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INibCqT5bR3d"
   },
   "source": [
    "# Pendefinisian model Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqTEhdqqtL4z",
    "outputId": "5b4394f3-63f5-4610-e72d-d383d9b8940a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_qa = BertForQuestionAnswering.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qa = model_qa.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyJvhxZ6bbbF"
   },
   "source": [
    "# Melakukan pengumpulan data dengan padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rGeJNonStSXT"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nF_E_CHbb8m"
   },
   "source": [
    "# Mulai training untuk fine-tune SQUAD diatas IndoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import collections\n",
    "\n",
    "# # Melakukan evaluasi dari prediksi\n",
    "def normalize_text(s):\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_f1_prec_rec(pred, gold):\n",
    "    pred_tokens = normalize_text(pred).split() # True positive + False positive = Untuk precision\n",
    "    gold_tokens = normalize_text(gold).split() # True positive + False negatives = Untuk recall\n",
    "    common = collections.Counter(pred_tokens) & collections.Counter(gold_tokens)\n",
    "    num_same = sum(common.values()) # True positive\n",
    "\n",
    "    if len(gold_tokens) == 0 or len(pred_tokens) == 0: \n",
    "        var = int(gold_tokens == pred_tokens)\n",
    "        return var, var, var\n",
    "\n",
    "    if num_same == 0:\n",
    "        return 0, 0, 0\n",
    "\n",
    "    precision = 1.0 * num_same / len(pred_tokens)\n",
    "    recall = 1.0 * num_same / len(gold_tokens)\n",
    "    f1 = (2.0 * precision * recall) / (precision + recall)\n",
    "\n",
    "    return f1, precision, recall\n",
    "\n",
    "def compute_metrics(predict_result):\n",
    "    predictions_idx = np.argmax(predict_result.predictions, axis=2)\n",
    "    denominator = len(predictions_idx[0])\n",
    "    label_array = np.asarray(predict_result.label_ids)\n",
    "    total_correct = 0\n",
    "    f1_array = []\n",
    "    precision_array = []\n",
    "    recall_array = []\n",
    "\n",
    "    for i in range(len(predict_result.predictions[0])):\n",
    "        start_pred_idx = predictions_idx[0][i]\n",
    "        end_pred_idx = predictions_idx[1][i] + 1\n",
    "        start_gold_idx = label_array[0][i]\n",
    "        end_gold_idx = label_array[1][i] + 1\n",
    "\n",
    "        pred_text = tokenizer.decode(tokenized_data_qas_id_validation[i]['input_ids']\n",
    "                                    [start_pred_idx: end_pred_idx])\n",
    "        gold_text = tokenizer.decode(tokenized_data_qas_id_validation[i]['input_ids']\n",
    "                                    [start_gold_idx: end_gold_idx])\n",
    "\n",
    "        if pred_text == gold_text:\n",
    "            total_correct += 1\n",
    "\n",
    "        f1, precision, recall = compute_f1_prec_rec(pred=pred_text, gold=gold_text)\n",
    "\n",
    "        f1_array.append(f1)\n",
    "        precision_array.append(precision)\n",
    "        recall_array.append(recall)\n",
    "\n",
    "    exact_match = ((total_correct / denominator) * 100.0)\n",
    "    final_f1 = np.mean(f1_array) * 100.0\n",
    "    final_precision = np.mean(precision_array) * 100.0\n",
    "    final_recall = np.mean(recall_array) * 100.0\n",
    "\n",
    "    return {'exact_match': exact_match, 'f1': final_f1, 'precision': final_precision, 'recall': final_recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "G6pLmNzCjhra"
   },
   "outputs": [],
   "source": [
    "trainer_qa = Trainer(\n",
    "    model=model_qa.to(device),\n",
    "    args=training_args_qa,\n",
    "    train_dataset=tokenized_data_qas_id_train,\n",
    "    eval_dataset=tokenized_data_qas_id_validation,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qp96lB8vjtXG",
    "outputId": "b118d7ac-a90d-43c2-bd8b-ee0a0c4ab8de",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 131028\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 1023\n",
      "  Number of trainable parameters = 109969154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1023' max='1023' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1023/1023 48:31, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.949300</td>\n",
       "      <td>1.928556</td>\n",
       "      <td>37.802545</td>\n",
       "      <td>52.933379</td>\n",
       "      <td>54.562138</td>\n",
       "      <td>60.610682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 12023\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/alur2-idk-mrc-2023-03-10_11-03-04_966438/checkpoint/checkpoint-1023\n",
      "Configuration saved in ./results/alur2-idk-mrc-2023-03-10_11-03-04_966438/checkpoint/checkpoint-1023/config.json\n",
      "Model weights saved in ./results/alur2-idk-mrc-2023-03-10_11-03-04_966438/checkpoint/checkpoint-1023/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/alur2-idk-mrc-2023-03-10_11-03-04_966438/checkpoint/checkpoint-1023/tokenizer_config.json\n",
      "Special tokens file saved in ./results/alur2-idk-mrc-2023-03-10_11-03-04_966438/checkpoint/checkpoint-1023/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1023, training_loss=2.4144637153528534, metrics={'train_runtime': 2937.8283, 'train_samples_per_second': 44.6, 'train_steps_per_second': 0.348, 'total_flos': 2.67306582140928e+16, 'train_loss': 2.4144637153528534, 'epoch': 1.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_qa.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DreIeglDbrHY"
   },
   "source": [
    "# Menyimpan model Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "KJick7YDjuoq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/alur2-idk-mrc-2023-03-10_11-03-04_966438/model/\n",
      "Configuration saved in ./results/alur2-idk-mrc-2023-03-10_11-03-04_966438/model/config.json\n",
      "Model weights saved in ./results/alur2-idk-mrc-2023-03-10_11-03-04_966438/model/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/alur2-idk-mrc-2023-03-10_11-03-04_966438/model/tokenizer_config.json\n",
      "Special tokens file saved in ./results/alur2-idk-mrc-2023-03-10_11-03-04_966438/model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer_qa.save_model(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dX-y8EbobugF"
   },
   "source": [
    "# Melakukan prediksi dari model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6aE7w2yMkWxj",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 12023\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=(array([[ 2.3400595, -4.9847035, -5.3231263, ..., -7.67994  , -7.6520615,\n",
       "        -7.993825 ],\n",
       "       [ 2.0694578, -4.7709394, -5.695021 , ..., -7.479656 , -7.634318 ,\n",
       "        -7.8908734],\n",
       "       [ 2.2772768, -6.0087466, -6.756085 , ..., -7.807231 , -7.785742 ,\n",
       "        -7.6126475],\n",
       "       ...,\n",
       "       [ 2.2395368, -1.4549687, -5.6119843, ..., -8.549288 , -8.349885 ,\n",
       "        -7.8284698],\n",
       "       [ 2.460146 , -3.6223714, -7.33974  , ..., -7.147509 , -7.0236773,\n",
       "        -7.917438 ],\n",
       "       [ 2.387605 , -3.9669983, -6.922913 , ..., -6.703164 , -7.771115 ,\n",
       "        -7.5800157]], dtype=float32), array([[ 1.8328297, -5.4852195, -5.9295864, ..., -8.226759 , -8.231143 ,\n",
       "        -8.035612 ],\n",
       "       [ 1.8535712, -6.1044908, -6.478697 , ..., -8.087011 , -7.573409 ,\n",
       "        -6.808301 ],\n",
       "       [ 1.944047 , -6.583405 , -6.6930447, ..., -8.277608 , -8.29374  ,\n",
       "        -8.166326 ],\n",
       "       ...,\n",
       "       [ 1.9341775, -3.4373777, -3.8312209, ..., -5.731249 , -6.1923976,\n",
       "        -7.712329 ],\n",
       "       [ 2.3398125, -4.7683105, -6.068818 , ..., -8.096396 , -8.102752 ,\n",
       "        -8.0577   ],\n",
       "       [ 2.2920477, -5.2558722, -5.7245855, ..., -7.7867603, -8.072109 ,\n",
       "        -8.136473 ]], dtype=float32)), label_ids=(array([50, 35, 75, ...,  0,  0,  0]), array([50, 37, 79, ...,  0,  0,  0])), metrics={'test_loss': 1.928556203842163, 'test_exact_match': 37.80254512184979, 'test_f1': 52.93337928997236, 'test_precision': 54.56213837306034, 'test_recall': 60.61068180559022, 'test_runtime': 117.0852, 'test_samples_per_second': 102.686, 'test_steps_per_second': 12.837})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_result = trainer_qa.predict(tokenized_data_qas_id_validation)\n",
    "predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(OUTPUT_DIR), exist_ok=True)\n",
    "with open(f'{OUTPUT_DIR}/output.txt', \"w\") as f:\n",
    "  f.write(str(predict_result))\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2BS4XC5byxE"
   },
   "source": [
    "# Melakukan evaluasi dari prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "9J-zKl_zkUze"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 37.80254512184979,\n",
       " 'f1': 52.93337928997236,\n",
       " 'precision': 54.56213837306034,\n",
       " 'recall': 60.61068180559022}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_result = compute_metrics(predict_result)\n",
    "accuracy_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(ACCURACY_DIR), exist_ok=True)\n",
    "with open(f'{ACCURACY_DIR}/accuracy.txt', \"w\") as f:\n",
    "  f.write(str(accuracy_result))\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coba Alur 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19]],\n",
       "\n",
       "       [[20, 21, 22, 23, 24],\n",
       "        [25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34],\n",
       "        [35, 36, 37, 38, 39]],\n",
       "\n",
       "       [[40, 41, 42, 43, 44],\n",
       "        [45, 46, 47, 48, 49],\n",
       "        [50, 51, 52, 53, 54],\n",
       "        [55, 56, 57, 58, 59]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(60).reshape(3, 4, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  8, 13, 18],\n",
       "       [23, 28, 33, 38],\n",
       "       [43, 48, 53, 58]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:3, 0:4, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_result.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 3], [2, 2], [4, 2]])\n",
    "print(x.shape)\n",
    "print(np.argsort(x)[-1][-1])\n",
    "print(np.argmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 12023)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[50, 32, 75, ..., 29, 54, 96],\n",
       "       [50, 39, 75, ..., 30, 55, 97]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.argmax(predict_result.predictions, axis=2)\n",
    "print(x.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 12023)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[238, 236, 196, ..., 262, 260, 259],\n",
       "       [224, 166, 225, ..., 327, 240, 356]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.argsort(predict_result.predictions, axis=2)[:,:, -0]\n",
    "print(x.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def create_qas_dataframe(predict_result=predict_result, index_largest=1):\n",
    "    predictions_idx = np.argsort(predict_result.predictions, axis=2)[:, :, index_largest * -1]\n",
    "    #predictions_idx = np.argmax(predict_result.predictions, axis=2)\n",
    "    label_array = np.asarray(predict_result.label_ids)\n",
    "    question_decoded = []\n",
    "    context_decoded = []\n",
    "    pred_answer_decoded = []\n",
    "    gold_answer_decoded = []\n",
    "    \n",
    "    for i in tqdm(range(len(predict_result.predictions[0]))):\n",
    "        start_pred_idx = predictions_idx[0][i]\n",
    "        end_pred_idx = predictions_idx[1][i] + 1\n",
    "        pred_answer = tokenizer.decode(tokenized_data_qas_id_validation[i]['input_ids']\n",
    "                                       [start_pred_idx: end_pred_idx], skip_special_tokens=True)\n",
    "        pred_answer_decoded.append(pred_answer)\n",
    "        \n",
    "        start_gold_idx = label_array[0][i]\n",
    "        end_gold_idx = label_array[1][i] + 1\n",
    "        gold_answer = tokenizer.decode(tokenized_data_qas_id_validation[i]['input_ids']\n",
    "                                       [start_gold_idx: end_gold_idx], skip_special_tokens=True)\n",
    "        gold_answer_decoded.append(gold_answer)\n",
    "        \n",
    "        question = []\n",
    "        context = []\n",
    "         \n",
    "        for j in range(len(tokenized_data_qas_id_validation[i]['token_type_ids'])):\n",
    "            if tokenized_data_qas_id_validation[i]['token_type_ids'][j] == 0:\n",
    "                question.append(tokenized_data_qas_id_validation[i]['input_ids'][j])\n",
    "            else:\n",
    "                context.append(tokenized_data_qas_id_validation[i]['input_ids'][j])\n",
    "\n",
    "        question_decoded.append(tokenizer.decode(question, skip_special_tokens=True))\n",
    "        context_decoded.append(tokenizer.decode(context, skip_special_tokens=True))\n",
    "    \n",
    "    qas_df = pd.DataFrame({'Context': context_decoded, \n",
    "                           'Question': question_decoded, \n",
    "                           'Prediction Answer': pred_answer_decoded,\n",
    "                          'Gold Answer': gold_answer_decoded})\n",
    "                      \n",
    "    return qas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████▎                         | 8059/12023 [54:54<33:07,  1.99it/s]"
     ]
    }
   ],
   "source": [
    "qas_df = create_qas_dataframe(predict_result)\n",
    "qas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_mark = ['siapa', 'siapakah',\n",
    "                    'apa', 'apakah', 'adakah',\n",
    "                    'dimana', 'dimanakah', 'darimanakah',\n",
    "                    'kapan', 'kapankah',\n",
    "                    'bagaimana', 'bagaimanakah',\n",
    "                    'kenapa', 'mengapa',\n",
    "                    'berapa', 'berapakah', 'seberapa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hipo = \"kapankah musik hip hop kah pertama kali muncul?\"\n",
    "\n",
    "for i in hipo.split():\n",
    "    if (i == \"kah\") and (i not in question_mark):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nli_dataframe(df, type='replace first'):\n",
    "    \n",
    "    nli_df = pd.DataFrame()\n",
    "    \n",
    "    question_mark = ['siapa', 'siapakah',\n",
    "                    'apa', 'apakah', 'adakah',\n",
    "                    'dimana', 'dimanakah', 'darimanakah',\n",
    "                    'kapan', 'kapankah',\n",
    "                    'bagaimana', 'bagaimanakah',\n",
    "                    'kenapa', 'mengapa',\n",
    "                    'berapa', 'berapakah', 'seberapa']\n",
    "    \n",
    "    if type == 'rule based':\n",
    "        for i in tqdm(range(df.shape[0])):\n",
    "            premise = df['Context'][i]\n",
    "            hypothesis = df['Question'][i]\n",
    "            \n",
    "            hypothesis = hypothesis.replace('kah', '')\n",
    "            \n",
    "            for j in hypothesis.split():\n",
    "                if j in question_mark:\n",
    "                    if j == 'siapa' or j == 'siapakah':\n",
    "                        pred_hypothesis = hypothesis.replace('?', '')\n",
    "                        pred_hypothesis = pred_hypothesis.replace(j, '')\n",
    "                        pred_hypothesis = f\"{pred_hypothesis} adalah {df['Prediction Answer'][i]}\"\n",
    "\n",
    "                        gold_hypothesis = hypothesis.replace('?', '')\n",
    "                        gold_hypothesis = gold_hypothesis.replace(j, '')\n",
    "                        gold_hypothesis = f\"{gold_hypothesis} adalah {df['Gold Answer'][i]}\"\n",
    "                    \n",
    "                    elif j == 'apa' or j == 'apakah' or j == 'adakah':\n",
    "                        pred_hypothesis = hypothesis.replace('?', '')\n",
    "                        pred_hypothesis = pred_hypothesis.replace(j, '')\n",
    "                        pred_hypothesis = f\"{pred_hypothesis} adalah {df['Prediction Answer'][i]}\"\n",
    "\n",
    "                        gold_hypothesis = hypothesis.replace('?', '')\n",
    "                        gold_hypothesis = gold_hypothesis.replace(j, '')\n",
    "                        gold_hypothesis = f\"{gold_hypothesis} adalah {df['Gold Answer'][i]}\"\n",
    "                        \n",
    "                    elif j == 'dimana' or j == 'dimanakah':\n",
    "                        pred_hypothesis = hypothesis.replace('?', '')\n",
    "                        pred_hypothesis = pred_hypothesis.replace(j, '')\n",
    "                        pred_hypothesis = f\"{pred_hypothesis} di {df['Prediction Answer'][i]}\"\n",
    "\n",
    "                        gold_hypothesis = hypothesis.replace('?', '')\n",
    "                        gold_hypothesis = gold_hypothesis.replace(j, '')\n",
    "                        gold_hypothesis = f\"{gold_hypothesis} di {df['Gold Answer'][i]}\"\n",
    "                    \n",
    "                    elif j == 'darimanakah':\n",
    "                        pred_hypothesis = hypothesis.replace('?', '')\n",
    "                        pred_hypothesis = pred_hypothesis.replace(j, '')\n",
    "                        pred_hypothesis = f\"{pred_hypothesis} dari {df['Prediction Answer'][i]}\"\n",
    "\n",
    "                        gold_hypothesis = hypothesis.replace('?', '')\n",
    "                        gold_hypothesis = gold_hypothesis.replace(j, '')\n",
    "                        gold_hypothesis = f\"{gold_hypothesis} dari {df['Gold Answer'][i]}\"\n",
    "                    \n",
    "                    elif j == 'kapan' or j == 'kapankah':\n",
    "                        pred_hypothesis = hypothesis.replace('?', '')\n",
    "                        pred_hypothesis = pred_hypothesis.replace(j, '')\n",
    "                        pred_hypothesis = f\"{pred_hypothesis} pada {df['Prediction Answer'][i]}\"\n",
    "\n",
    "                        gold_hypothesis = hypothesis.replace('?', '')\n",
    "                        gold_hypothesis = gold_hypothesis.replace(j, '')\n",
    "                        gold_hypothesis = f\"{gold_hypothesis} pada {df['Gold Answer'][i]}\"\n",
    "\n",
    "                    elif j == 'bagaimana' or j == 'bagaimanakah':\n",
    "                        pred_hypothesis = hypothesis.replace('?', '')\n",
    "                        pred_hypothesis = pred_hypothesis.replace(j, '')\n",
    "                        pred_hypothesis = f\"{pred_hypothesis} adalah {df['Prediction Answer'][i]}\"\n",
    "\n",
    "                        gold_hypothesis = hypothesis.replace('?', '')\n",
    "                        gold_hypothesis = gold_hypothesis.replace(j, '')\n",
    "                        gold_hypothesis = f\"{gold_hypothesis} adalah {df['Gold Answer'][i]}\"\n",
    "                    \n",
    "                    elif j == 'kenapa' or j == 'mengapa':\n",
    "                        pred_hypothesis = hypothesis.replace('?', '')\n",
    "                        pred_hypothesis = pred_hypothesis.replace(j, 'alasan')\n",
    "                        pred_hypothesis = f\"{pred_hypothesis} adalah karena {df['Prediction Answer'][i]}\"\n",
    "\n",
    "                        gold_hypothesis = hypothesis.replace('?', '')\n",
    "                        gold_hypothesis = gold_hypothesis.replace(j, 'alasan')\n",
    "                        gold_hypothesis = f\"{gold_hypothesis} adalah karena {df['Gold Answer'][i]}\"\n",
    "                    \n",
    "                    elif j == 'berapa' or j == 'berapakah' or j == 'seberapa': \n",
    "                        pred_hypothesis = hypothesis.replace('?', '')\n",
    "                        pred_hypothesis = pred_hypothesis.replace(j, '')\n",
    "                        pred_hypothesis = f\"{pred_hypothesis} adalah {df['Prediction Answer'][i]}\"\n",
    "\n",
    "                        gold_hypothesis = hypothesis.replace('?', '')\n",
    "                        gold_hypothesis = gold_hypothesis.replace(j, '')\n",
    "                        gold_hypothesis = f\"{gold_hypothesis} adalah {df['Gold Answer'][i]}\"\n",
    "                    \n",
    "            nli_df = nli_df.append({'Premise': premise,\n",
    "                           'Prediction Hypothesis': pred_hypothesis,\n",
    "                            'Gold Hypothesis': gold_hypothesis\n",
    "                           }, ignore_index=True)\n",
    "\n",
    "    elif type == 'replace first':\n",
    "        for i in tqdm(range(df.shape[0])):\n",
    "            premise = df['Context'][i]\n",
    "            hypothesis = df['Question'][i]\n",
    "            pred_hypothesis = hypothesis.replace('?', '')\n",
    "            pred_hypothesis = pred_hypothesis.replace(hypothesis.split()[0], \n",
    "                                            df['Prediction Answer'][i])\n",
    "\n",
    "            gold_hypothesis = hypothesis.replace('?', '')\n",
    "            gold_hypothesis = gold_hypothesis.replace(hypothesis.split()[0], \n",
    "                                            df['Gold Answer'][i])\n",
    "            \n",
    "            nli_df = nli_df.append({'Premise': premise,\n",
    "                               'Prediction Hypothesis': pred_hypothesis,\n",
    "                                'Gold Hypothesis': gold_hypothesis\n",
    "                               }, ignore_index=True)\n",
    "    \n",
    "    elif type == 'replace question mark':\n",
    "        for i in tqdm(range(df.shape[0])):\n",
    "            premise = df['Context'][i]\n",
    "            hypothesis = df['Question'][i]\n",
    "            for j in hypothesis.split():\n",
    "                if j in question_mark:\n",
    "                    pred_hypothesis = hypothesis.replace('?', '')\n",
    "                    pred_hypothesis = pred_hypothesis.replace(j, df['Prediction Answer'][i])\n",
    "                    \n",
    "                    gold_hypothesis = hypothesis.replace('?', '')\n",
    "                    gold_hypothesis = gold_hypothesis.replace(j, df['Gold Answer'][i])\n",
    "                \n",
    "            nli_df = nli_df.append({'Premise': premise,\n",
    "                                   'Prediction Hypothesis': pred_hypothesis,\n",
    "                                    'Gold Hypothesis': gold_hypothesis\n",
    "                                   }, ignore_index=True)\n",
    "    \n",
    "    elif type == 'machine generation': pass # TODO\n",
    "    \n",
    "    elif type == 'add adalah': \n",
    "        for i in tqdm(range(df.shape[0])):\n",
    "            premise = df['Context'][i]\n",
    "            hypothesis = df['Question'][i]\n",
    "            pred_hypothesis = hypothesis.replace('?', '')\n",
    "            pred_hypothesis = pred_hypothesis.replace(hypothesis.split()[0], '')\n",
    "            pred_hypothesis = f\"{pred_hypothesis} adalah {df['Prediction Answer'][i]}\"\n",
    "\n",
    "            gold_hypothesis = hypothesis.replace('?', '')\n",
    "            gold_hypothesis = gold_hypothesis.replace(hypothesis.split()[0], '')\n",
    "            gold_hypothesis = f\"{gold_hypothesis} adalah {df['Gold Answer'][i]}\"\n",
    "            \n",
    "            nli_df = nli_df.append({'Premise': premise,\n",
    "                               'Prediction Hypothesis': pred_hypothesis,\n",
    "                                'Gold Hypothesis': gold_hypothesis\n",
    "                               }, ignore_index=True)\n",
    "    \n",
    "    elif type == 'just concat answer and question':\n",
    "        for i in tqdm(range(df.shape[0])):\n",
    "            premise = df['Context'][i]\n",
    "            hypothesis = df['Question'][i]\n",
    "\n",
    "            pred_hypothesis = f\"{hypothesis} {df['Prediction Answer'][i]}\"         \n",
    "            gold_hypothesis = f\"{hypothesis} {df['Gold Answer'][i]}\"\n",
    "                \n",
    "            nli_df = nli_df.append({'Premise': premise,\n",
    "                                   'Prediction Hypothesis': pred_hypothesis,\n",
    "                                    'Gold Hypothesis': gold_hypothesis\n",
    "                                   }, ignore_index=True)\n",
    "    '''\n",
    "    kata_tanya = []\n",
    "    for i in tqdm(range(df.shape[0])): \n",
    "        hypothesis = df['Question'][i]\n",
    "        kata_tanya.append(hypothesis.split()[0])\n",
    "    unik = set(np.unique(kata_tanya))\n",
    "    temp3 = [x for x in unik if x not in question_mark]\n",
    "    print(temp3)\n",
    "    '''\n",
    "        \n",
    "    return nli_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nli_df = create_nli_dataframe(qas_df, type='rule based')\n",
    "nli_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mencoba cara retrieve model dari HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pretrained_name_sc = \"afaji/fine-tuned-IndoNLI-Augmented-with-indobert-base-uncased\"\n",
    "pretrained_name_qa = \"afaji/fine-tuned-DatasetQAS-TYDI-QA-ID-with-indobert-base-uncased-with-ITTL-without-freeze-LR-1e-05\"\n",
    "tokenizer_kwargs = {'padding': True, 'truncation': True, 'max_length': 512}\n",
    "\n",
    "nlp_sc = pipeline(task=\"text-classification\", model=pretrained_name_sc, tokenizer=pretrained_name_sc)\n",
    "nlp_qa = pipeline(task=\"question-answering\", model=pretrained_name_qa, tokenizer=pretrained_name_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nlp_sc({'text': nli_df['Premise'][0], 'text_pair': nli_df['Prediction Hypothesis'][0]}, top_k=3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_qa(question=qas_df['Question'][1], context=qas_df['Context'][1], device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coba buat method evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_after_postprocess(df=nli_df):\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        predicted = nlp_sc({'text': df['Premise'][i], 'text_pair': df['Prediction Hypothesis'][i]}, \n",
    "                           top_k=1, **tokenizer_kwargs)[0]['label']\n",
    "        print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_idx = np.argsort(predict_result.predictions, axis=2)[:, :, 1 * -1]\n",
    "predictions_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(predict_result, type='regular'):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(predict_result, type_smoothing=\"replace first\", type_qas=\"TODO\"):\n",
    "    \n",
    "    # 1. Ekstrak dari QAS\n",
    "    DEFAULT_INDEX_LARGEST = 1\n",
    "    predictions_idx = np.argsort(predict_result.predictions, axis=2)[:, :, DEFAULT_INDEX_LARGEST * -1]\n",
    "    label_array = np.asarray(predict_result.label_ids)\n",
    "    question_decoded = []\n",
    "    context_decoded = []\n",
    "    pred_answer_decoded = []\n",
    "    gold_answer_decoded = []\n",
    "    \n",
    "    question_d = None\n",
    "    context_d = None\n",
    "    \n",
    "    for i in tqdm(range(len(predict_result.predictions[0]))):\n",
    "        start_pred_idx = predictions_idx[0][i]\n",
    "        end_pred_idx = predictions_idx[1][i] + 1\n",
    "        pred_answer = tokenizer.decode(tokenized_data_qas_id_validation[i]['input_ids']\n",
    "                                       [start_pred_idx: end_pred_idx], skip_special_tokens=True)\n",
    "        #pred_answer_decoded.append(pred_answer)\n",
    "        \n",
    "        start_gold_idx = label_array[0][i]\n",
    "        end_gold_idx = label_array[1][i] + 1\n",
    "        gold_answer = tokenizer.decode(tokenized_data_qas_id_validation[i]['input_ids']\n",
    "                                       [start_gold_idx: end_gold_idx], skip_special_tokens=True)\n",
    "        gold_answer_decoded.append(gold_answer)\n",
    "        \n",
    "        question = []\n",
    "        context = []\n",
    "        \n",
    "        for j in range(len(tokenized_data_qas_id_validation[i]['token_type_ids'])):\n",
    "            if tokenized_data_qas_id_validation[i]['token_type_ids'][j] == 0:\n",
    "                question.append(tokenized_data_qas_id_validation[i]['input_ids'][j])\n",
    "                question_d = tokenizer.decode(question, skip_special_tokens=True)\n",
    "            else:\n",
    "                context.append(tokenized_data_qas_id_validation[i]['input_ids'][j])\n",
    "                context_d = tokenizer.decode(context, skip_special_tokens=True)\n",
    "            \n",
    "            # Smoothing (OTW)\n",
    "            if type_smoothing == 'replace first':\n",
    "                for k in tqdm(range(df.shape[0])):\n",
    "                    premise = df['Context'][k]\n",
    "                    hypothesis = df['Question'][k]\n",
    "                    pred_hypothesis = hypothesis.replace('?', '')\n",
    "                    pred_hypothesis = pred_hypothesis.replace(hypothesis.split()[0], \n",
    "                                                    df['Prediction Answer'][k])\n",
    "\n",
    "                    gold_hypothesis = hypothesis.replace('?', '')\n",
    "                    gold_hypothesis = gold_hypothesis.replace(hypothesis.split()[0], \n",
    "                                                    df['Gold Answer'][k])\n",
    "\n",
    "                    nli_df = nli_df.append({'Premise': premise,\n",
    "                                       'Prediction Hypothesis': pred_hypothesis,\n",
    "                                        'Gold Hypothesis': gold_hypothesis\n",
    "                                       }, ignore_index=True)\n",
    "\n",
    "            elif type_smoothing == 'replace question mark':\n",
    "                for k in tqdm(range(df.shape[0])):\n",
    "                    premise = df['Context'][k]\n",
    "                    hypothesis = df['Question'][k]\n",
    "                    for l in hypothesis.split():\n",
    "                        if j in question_mark:\n",
    "                            pred_hypothesis = hypothesis.replace('?', '')\n",
    "                            pred_hypothesis = pred_hypothesis.replace(l, df['Prediction Answer'][k])\n",
    "\n",
    "                            gold_hypothesis = hypothesis.replace('?', '')\n",
    "                            gold_hypothesis = gold_hypothesis.replace(l, df['Gold Answer'][k])\n",
    "            \n",
    "            # Cek entails\n",
    "            #predicted = nlp_sc({'text': pred_answer, 'text_pair': context_d}, top_k=3, **tokenizer_kwargs)[0]['label'] \n",
    "            \"\"\"\n",
    "            if predicted == 'entailment':\n",
    "                question_decoded.append(tokenizer.decode(question, skip_special_tokens=True))\n",
    "                context_decoded.append(tokenizer.decode(context, skip_special_tokens=True))\n",
    "                pred_answer_decoded.append(pred_answer)\n",
    "                # Bisa jadi: break;\n",
    "            \n",
    "            # Bagian elif bisa di-comment untuk opsi kedua\n",
    "            elif predicted == 'neutral':\n",
    "                question_decoded.append(tokenizer.decode(question, skip_special_tokens=True))\n",
    "                context_decoded.append(tokenizer.decode(context, skip_special_tokens=True))\n",
    "                pred_answer_decoded.append(pred_answer)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                for index_largest in range(400 + 1):\n",
    "                    \n",
    "                    predictions_idx_inside_loop = np.argsort(predict_result.predictions, axis=2)[:, :, index_largest * -1]\n",
    "                    start_pred_idx = predictions_idx_inside_loop[0][i]\n",
    "                    end_pred_idx = predictions_idx_inside_loop[1][i] + 1\n",
    "                    pred_answer_inside_loop = tokenizer.decode(tokenized_data_qas_id_validation[i]['input_ids']\n",
    "                                                   [start_pred_idx: end_pred_idx], skip_special_tokens=True)\n",
    "                    \n",
    "                    predicted = nlp_sc({'text': pred_answer_inside_loop, 'text_pair': context_d}, \n",
    "                               top_k=3, **tokenizer_kwargs)[0]['label']\n",
    "                    \n",
    "                    if predicted == 'entailment':\n",
    "                        question_decoded.append(tokenizer.decode(question, skip_special_tokens=True))\n",
    "                        context_decoded.append(tokenizer.decode(context, skip_special_tokens=True))\n",
    "                        pred_answer_decoded.append(pred_answer_inside_loop)\n",
    "                        break\n",
    "                    \n",
    "                    else: continue\n",
    "            \"\"\"\n",
    "        \n",
    "    \n",
    "    qas_df = pd.DataFrame({'Context': context_decoded, \n",
    "                           'Question': question_decoded, \n",
    "                           'Prediction Answer': pred_answer_decoded,\n",
    "                          'Gold Answer': gold_answer_decoded})\n",
    "    \n",
    "    return qas_df\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 2. Jalanin smoothing.\n",
    "    #qas_df = create_qas_dataframe(predict_result, index_largest=1)\n",
    "    #nli_df = create_nli_dataframe(qas_df, type='replace first')\n",
    "    \n",
    "    # 3. Cek entail, mau only entail, atau entail & neutral\n",
    "    # 4. Return DataFrame QAS.\n",
    "    #pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation(predict_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05c4878c74ad419f81e6abc2b9f9fae1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0633918b582f45c38356130338ccfb58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8aa4db7376e3445089af950c446aab70",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7c6178f42ed4b9f8c5169c21783ce2d",
      "value": 2
     }
    },
    "065d96b02c7840019af97e3c135693a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ce874e529474f478a7acd45b4ffd649": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_902bd6c12ea54039b8c913a7c1782ff4",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d86de7f1fbf452892fe6d4b177558f9",
      "value": 6
     }
    },
    "10fb50db270449b48382c815904245a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc7073fb093543fc990abc620348c1ca",
      "placeholder": "​",
      "style": "IPY_MODEL_acac4d071be4488fbb272df63b625213",
      "value": " 66/66 [23:11&lt;00:00, 14.47s/ba]"
     }
    },
    "113ae282ca5a499a8a2ad36a796e763f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f10632530a1b499ba3d20f0286446bab",
      "placeholder": "​",
      "style": "IPY_MODEL_94da3d6dfccc4a289c659b94bcc90658",
      "value": "#0: 100%"
     }
    },
    "12c3fd408f914038acb511c4ef57f965": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13ea541bb13b42738e74885a2c1db8df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14a450c5594148c3a4ca340521d167ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13ea541bb13b42738e74885a2c1db8df",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68818d7eea5849afa82c3003a57a5b8d",
      "value": 6
     }
    },
    "1d86de7f1fbf452892fe6d4b177558f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "23ce34e28a524ad9ab44a3715c8be175": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05c4878c74ad419f81e6abc2b9f9fae1",
      "placeholder": "​",
      "style": "IPY_MODEL_7fc9c87c6cc44cdf82ea4f74c0bfe7b4",
      "value": "100%"
     }
    },
    "2721b15477d741519a3041a8f256575b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6a373f9cb48a481d85803f0792ff27b3",
       "IPY_MODEL_54a2637e8c8e4ca0917e35f4b58b48f3",
       "IPY_MODEL_7dc3dc97044c48afb06a14575fc8e91b"
      ],
      "layout": "IPY_MODEL_6c3c7e4da5af40b088f3046d7698edff"
     }
    },
    "29b13cbb638947d5a17071d299e2420f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_113ae282ca5a499a8a2ad36a796e763f",
       "IPY_MODEL_0ce874e529474f478a7acd45b4ffd649",
       "IPY_MODEL_935752d8733c41fbb25ed436606352ca"
      ],
      "layout": "IPY_MODEL_cf2b519cc5ff446dae45afa2439c840e"
     }
    },
    "2e0e9b7ee63b4c748d6294d63cc7b088": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd4d3c6663db46c9934c0d1f7a128d4c",
      "placeholder": "​",
      "style": "IPY_MODEL_3db65eb148504de6a4207708554874f0",
      "value": " 2/2 [00:00&lt;00:00,  8.75it/s]"
     }
    },
    "3db65eb148504de6a4207708554874f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f3c8a647bb24840ae71ce6e3219f4dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_23ce34e28a524ad9ab44a3715c8be175",
       "IPY_MODEL_87c26a64111847f3a6cdb2f0797ae1f5",
       "IPY_MODEL_2e0e9b7ee63b4c748d6294d63cc7b088"
      ],
      "layout": "IPY_MODEL_750e7a8018e6415f8cfc15288d80f13f"
     }
    },
    "3f6183fb8ca348e0ac35b495681c705a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45f8bfb31705441c80a22dbb955dd933": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4836cff910304df894759890642ac333": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4f2a3658a0f14f66a59c14d36558c7e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86b094a2e5564e4d8af8693dab674961",
      "placeholder": "​",
      "style": "IPY_MODEL_7fc619affab644758cfea5857adb7c93",
      "value": " 2/2 [00:00&lt;00:00,  4.72it/s]"
     }
    },
    "4f80ae88d884407ab8f9e08aa58632a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "540c7fcbf3b14e538cba18329bc1fc20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "54a2637e8c8e4ca0917e35f4b58b48f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dce089e985634a67a381bc85cbaca017",
      "max": 66,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bd9cb96d5a3c4400bb7d145590540a54",
      "value": 66
     }
    },
    "6516c5b02aa24db2bc42cdd4d1f2c260": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cbed771e77314789bf8817404e5d6f67",
       "IPY_MODEL_b0be384a887847e981868df7c551d3de",
       "IPY_MODEL_10fb50db270449b48382c815904245a8"
      ],
      "layout": "IPY_MODEL_b23174d38e3940718252770bd39177f8"
     }
    },
    "68818d7eea5849afa82c3003a57a5b8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6a373f9cb48a481d85803f0792ff27b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a040ab99cb964c32a0a968d97dd55a16",
      "placeholder": "​",
      "style": "IPY_MODEL_9ef8c0b24cb5490b8fa7e8ea8ad619fe",
      "value": "#0: 100%"
     }
    },
    "6c3c7e4da5af40b088f3046d7698edff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "750e7a8018e6415f8cfc15288d80f13f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b80b681b46b4671a14a7cf82fd50991": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7dc3dc97044c48afb06a14575fc8e91b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f940438113734ccdb198efd12b8a3936",
      "placeholder": "​",
      "style": "IPY_MODEL_c5b567cd34b340dea77cefd40e9aaec9",
      "value": " 66/66 [23:07&lt;00:00, 15.32s/ba]"
     }
    },
    "7fc619affab644758cfea5857adb7c93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fc9c87c6cc44cdf82ea4f74c0bfe7b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8104b020ba8b498591e14a51af34306d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83abc2e663e447e7af2f826eacd155c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86b094a2e5564e4d8af8693dab674961": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87c26a64111847f3a6cdb2f0797ae1f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb1fb197045a44ab8c204a8bdc3c4584",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4836cff910304df894759890642ac333",
      "value": 2
     }
    },
    "8aa4db7376e3445089af950c446aab70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ce95fb7cd2f4cf49b54dfa319f1e835": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83abc2e663e447e7af2f826eacd155c7",
      "placeholder": "​",
      "style": "IPY_MODEL_8104b020ba8b498591e14a51af34306d",
      "value": "100%"
     }
    },
    "902bd6c12ea54039b8c913a7c1782ff4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "935752d8733c41fbb25ed436606352ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f6183fb8ca348e0ac35b495681c705a",
      "placeholder": "​",
      "style": "IPY_MODEL_bdf2cb9d10cc4b2aab466a9dfe7be5bc",
      "value": " 6/6 [02:04&lt;00:00, 20.17s/ba]"
     }
    },
    "94da3d6dfccc4a289c659b94bcc90658": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c9b27a0b2ac4be3b8dcbb65e23b84a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_065d96b02c7840019af97e3c135693a8",
      "placeholder": "​",
      "style": "IPY_MODEL_45f8bfb31705441c80a22dbb955dd933",
      "value": " 6/6 [02:03&lt;00:00, 20.04s/ba]"
     }
    },
    "9ef8c0b24cb5490b8fa7e8ea8ad619fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a040ab99cb964c32a0a968d97dd55a16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acac4d071be4488fbb272df63b625213": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0be384a887847e981868df7c551d3de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12c3fd408f914038acb511c4ef57f965",
      "max": 66,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_540c7fcbf3b14e538cba18329bc1fc20",
      "value": 66
     }
    },
    "b23174d38e3940718252770bd39177f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bce02c83fbc142c5bb2d8c1f905a478d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd9cb96d5a3c4400bb7d145590540a54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bdf2cb9d10cc4b2aab466a9dfe7be5bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c069967001a542f5b0c3b88ff1841eba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f46e4c24b9294ffdb25e1e64bc594eee",
       "IPY_MODEL_14a450c5594148c3a4ca340521d167ba",
       "IPY_MODEL_9c9b27a0b2ac4be3b8dcbb65e23b84a2"
      ],
      "layout": "IPY_MODEL_c99472b37d644d63a471b65ecbe3bfbd"
     }
    },
    "c5b567cd34b340dea77cefd40e9aaec9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c99472b37d644d63a471b65ecbe3bfbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb1fb197045a44ab8c204a8bdc3c4584": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbed771e77314789bf8817404e5d6f67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b80b681b46b4671a14a7cf82fd50991",
      "placeholder": "​",
      "style": "IPY_MODEL_bce02c83fbc142c5bb2d8c1f905a478d",
      "value": "#1: 100%"
     }
    },
    "cf2b519cc5ff446dae45afa2439c840e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7c6178f42ed4b9f8c5169c21783ce2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dce089e985634a67a381bc85cbaca017": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd4d3c6663db46c9934c0d1f7a128d4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8eebd19f57348669da4353e690a64eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8ce95fb7cd2f4cf49b54dfa319f1e835",
       "IPY_MODEL_0633918b582f45c38356130338ccfb58",
       "IPY_MODEL_4f2a3658a0f14f66a59c14d36558c7e6"
      ],
      "layout": "IPY_MODEL_f2758827907544acaa282673eebff9d0"
     }
    },
    "e9ca9f63982744aba53e883882373160": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f10632530a1b499ba3d20f0286446bab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2758827907544acaa282673eebff9d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f46e4c24b9294ffdb25e1e64bc594eee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9ca9f63982744aba53e883882373160",
      "placeholder": "​",
      "style": "IPY_MODEL_4f80ae88d884407ab8f9e08aa58632a4",
      "value": "#1: 100%"
     }
    },
    "f940438113734ccdb198efd12b8a3936": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc7073fb093543fc990abc620348c1ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
