%---------------------------------------------------------------
\chapter{\kesimpulan}
\label{bab:6}
%---------------------------------------------------------------
Bab keenam ini menjelaskan mengenai kesimpulan dari penelitian ini dan juga saran untuk penelitian selanjutnya. Sub-bab \ref{6.1} menjelaskan beberapa poin utama kesimpulan dari penelitian ini. Sub-bab \ref{6.2} menjelaskan saran untuk penelitian selanjutnya.

%---------------------------------------------------------------
\section{Kesimpulan}
\label{6.1}
%---------------------------------------------------------------
Pada sub-bab ini, akan dijelaskan mengenai kesimpulan utama dari penelitian ini. Berikut ini adalah poin-poin kesimpulan terkait pekerjaan yang dilakukan dalam penelitian ini:

\begin{enumerate}
	
 \item \bo{Peningkatan Performa Dengan Pemanfaatan \emph{Natural Language Inference}.}
	
 Pada metode \emph{intermediate-task transfer learning}, dapat dilihat bahwa pemanfaatan metode ini berdampak \textbf{positif} bagi keseluruhan performa sistem tanya jawab, dan juga secara kecenderungan, metode \emph{intermediate-task transfer learning with freezing layer} memiliki skor yang lebih tinggi dibandingkan dengan metode \emph{intermediate-task transfer learning} maupun dengan \emph{baseline}-nya. Model terbaik untuk metode \emph{intermediate-task transfer learning} adalah: model \texttt{xlm-roberta-large} dengan metode \emph{intermediate-task transfer learning with freezing layer}, dengan skor \emph{exact match} dan skor F1 model dan metode tersebut mengungguli semua model dan metode lainnya, dengan mendapatkan skor \emph{exact match} sebesar 78.30 dan skor F1 sebesar 85.14. Namun, kenaikan paling signifikan terhadap \emph{baseline}, terdapat pada model \texttt{IndoBERT-large} dengan metode \emph{intermediate-task transfer learning with freezing layer}, dapat dilihat skor \emph{exact match} naik sekitar 5.66 dan skor F1 naik sekitar 5.69. Hal tersebut membuat model dan metode ini memiliki kenaikan skor paling signifikan di antara model dan metode lainnya. 
 
 Kemudian, pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}, dapat dilihat bahwa pemanfaatan metode ini berdampak \textbf{negatif} bagi keseluruhan performa sistem tanya jawab, dan juga secara kecenderungan, metode \emph{entailment or neutral} memiliki skor yang lebih tinggi dibandingkan dengan metode \emph{entailment only}, namun lebih rendah dibanding \emph{baseline}-nya. Model terbaik untuk metode \emph{task recasting} sebagai verifikator adalah: model \texttt{xlm-roberta-large} dengan parameter \emph{entailment or neutral}, dengan skor \emph{exact match} dan skor F1 model dan metode tersebut mengungguli semua model dan metode lainnya, dengan mendapatkan skor \emph{exact match} sebesar 72.52 dan skor F1 sebesar 79.19. Namun, kenaikan paling signifikan terhadap \emph{baseline}, terdapat pada model \texttt{IndoBERT-large} dengan parameter \emph{entailment only}, dapat dilihat skor \emph{exact match} naik sekitar 1.77 dan skor F1 naik sekitar 1.50. Hal tersebut membuat model dan metode ini memiliki kenaikan skor paling signifikan di antara model dan parameter lainnya.

 Terakhir, pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat, dapat dilihat bahwa pemanfaatan metode ini berdampak \textbf{negatif} bagi keseluruhan performa sistem tanya jawab, dan juga secara kecenderungan, parameter \emph{just concat answer and question} memiliki skor yang lebih tinggi dibandingkan dengan parameter lainnya, namun lebih rendah dibanding \emph{baseline}-nya. Model terbaik untuk metode \emph{task recasting} sebagai verifikator adalah: model \texttt{xlm-roberta-large} dengan parameter \emph{pure machine generation}, dengan skor \emph{exact match} dan skor F1 model dan metode tersebut mengungguli semua model dan metode lainnya, dengan mendapatkan skor \emph{exact match} sebesar 74.17 dan skor F1 sebesar 81.03 Namun, kenaikan paling signifikan terhadap \emph{baseline}, terdapat pada model \texttt{IndoBERT-large} dengan parameter \emph{just concat answer and question}, dapat dilihat skor \emph{exact match} naik sekitar 0.59 dan skor F1 naik sekitar 0.56. Hal tersebut membuat model dan metode ini memiliki kenaikan skor paling signifikan di antara model dan parameter lainnya.

 \item \bo{Karakteristik Pasangan Konteks-Pertanyaan-Jawaban Yang Meningkat Dengan Pemanfaatan \emph{Natural Language Inference}.}

 Pada metode \emph{intermediate-task transfer learning}, dapat dilihat karakteristik pasangan konteks-pertanyaan-jawaban yang cenderung meningkat dengan metode ini antara lain pada tipe pertanyaan: apa, dimana, kapan, siapa, bagaimana, dan lainnya; kemudian pada panjang konteks $\leq100$ dan $101-150$; lalu pada panjang pertanyaan $\leq5$ dan $6-10$; kemudian pada panjang jawaban \emph{golden truth} $\leq5$ dan $6-10$; lalu pada keseluruhan \emph{answer type} selain \emph{law} dan \emph{time}; terakhir pada \emph{reasoning type} WM, SSR, dan MSR. Mirip dengan performa dalam metrik skor \emph{exact match} dan skor F1, metode \emph{intermediate-task transfer learning with freezing layer} memiliki skor yang lebih tinggi dibandingkan dengan metode \emph{intermediate-task transfer learning} maupun dengan \emph{baseline}-nya; namun, persentase nilai benarnya cenderung meningkat tidak signifikan kecuali dengan beberapa kasus dengan menggunakan model \emph{IndoBERT-large}. 
 
 Kemudian, pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}, dapat dilihat karakteristik pasangan konteks-pertanyaan-jawaban yang cenderung meningkat (walaupun kecenderungannya tetap menurun dibandingkan \emph{baseline}-nya) dengan metode ini antara lain pada tipe pertanyaan: bagaimana; kemudian pada panjang konteks $\leq100$; lalu pada panjang pertanyaan $6-10$; kemudian pada panjang jawaban \emph{golden truth} $\leq5$; lalu tidak terdapat \emph{answer type} yang meningkat; terakhir pada \emph{reasoning type} SSR dan MSR. Mirip dengan performa dalam metrik skor \emph{exact match} dan skor F1, parameter \emph{entailment or neutral} memiliki skor yang lebih tinggi dibandingkan dengan parameter \emph{entailment only} namun lebih rendah dibanding \emph{baseline}-nya; namun tetap, persentase nilai benarnya cenderung menurun dibandingkan \emph{baseline} secara tidak signifikan kecuali dengan beberapa kasus dengan menggunakan model \emph{IndoBERT-base}. 

 Terakhir, pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat, dapat dilihat karakteristik pasangan konteks-pertanyaan-jawaban yang cenderung meningkat (walaupun kecenderungannya tetap menurun dibandingkan \emph{baseline}-nya) dengan metode ini antara lain pada tipe pertanyaan: kenapa dan bagaimana; kemudian pada panjang konteks $\leq100$; lalu pada panjang pertanyaan $6-10$; kemudian pada panjang jawaban \emph{golden truth} $6-10$; lalu pada \emph{answer type} \emph{date} dan \emph{woa}; terakhir tidak terdapat \emph{reasoning type} yang meningkat. Mirip dengan performa dalam metrik skor \emph{exact match} dan skor F1, parameter \emph{pure machine generation} memiliki skor yang lebih tinggi dibandingkan dengan parameter lainnya namun lebih rendah dibanding \emph{baseline}-nya; namun tetap, persentase nilai benarnya cenderung menurun dibandingkan \emph{baseline} secara tidak signifikan kecuali dengan beberapa kasus dengan menggunakan model \emph{IndoBERT-base}. 

\end{enumerate}

%---------------------------------------------------------------
\section{Saran}
\label{6.2}
%---------------------------------------------------------------
Pada sub-bab ini, akan dijelaskan mengenai saran dari penulis untuk penelitian selanjutnya. Berikut ini adalah saran dari penulis untuk pengembangan penelitian berikutnya:

\begin{enumerate}
    
    \item \textbf{Melakukan proses \emph{hyperparameter tuning} dengan lebih baik}. Pada penelitian ini, penulis tidak sempat untuk melakukan proses \emph{hyperparameter tuning} karena keterbatasan sumber daya (mesin komputasi dan waktu) pada \emph{training sequence classification}, \emph{training question answering baseline}, dan \emph{training question answering intermediate-task transfer learning}. Belum tentu, \emph{hyperparameter} yang penulis gunakan pada penelitian ini merupakan \emph{hyperparameter} yang terbaik. Oleh karena itu, saran penulis untuk penelitian selanjutnya, penelitian selanjutnya dapat melakukan proses \emph{hyperparameter tuning} dengan lebih baik, contohnya dengan menggunakan teknik \texttt{GridSearch}.
    
    \item \textbf{Meningkatkan kualitas tipe perubahan format kalimat}. Pada penelitian ini, penulis tidak terlalu memperhatikan kualitas tipe perubahan format, belum ada anotasi dari manusia untuk membuktikan keterbacaan dari tipe perubahan format kalimat yang telah penulis rancang. Sampai saat ini, setidaknya bagi penulis, kalimat yang dirancang sudah cukup terbaca, maka bisa dijadikan salah satu format template tipe perubahan format kalimat. Oleh karena itu, saran penulis untuk penelitian selanjutnya, penelitian selanjutnya dapat lebih memperhatikan kualitas tipe perubahan format kalimat, salah satu caranya adalah dengan membuat anotasi manusia yang dapat dievaluasi berdasarkan skor \emph{cohen kappa}-nya; bila sudah dievaluasi, maka tipe perubahan format kalimat bisa dimodifikasi atau bahkan dirancang ulang.
    
    \item \textbf{Eksplorasi parameter yang belum sempat diuji}. Pada penelitian ini, penulis tidak melakukan eksplorasi beberapa parameter pada metode \emph{task recasting} sebagai verifikator, seperti parameter: jumlah iterasi pencarian maksimum, variasi pengambilan jawaban akhir, dan \emph{threshold} batas tolerir pengambilan jawaban. Penulis tidak sempat eksplorasi untuk menguji parameter-parameter tersebut dikarenakan oleh keterbatasan sumber daya (mesin komputasi dan waktu). Oleh karena itu, saran penulis untuk penelitian selanjutnya, penelitian selanjutnya dapat mencoba untuk eksplorasi parameter-parameter tersebut, penelitian selanjutnya bisa saja hanya mengeksplorasi dan menguji parameter-parameter yang telah dibuat tersebut, karena kodenya sudah penulis rancang dan sudah bisa berjalan dengan lancar, sehingga penelitian selanjutnya bisa hanya benar-benar menjalankan kode yang sudah dirancang dan melakukan evaluasi dan analisis dari hasil yang telah didapatkan.

    \item \textbf{Kombinasi parameter eksperimen pada metode \emph{task recasting} sebagai verifikator}. Pada penelitian ini, penulis tidak melakukan kombinasi parameter eksperimen pada metode \emph{task recasting} sebagai verifikator. Penulis hanya melakukan evaluasi dan analisis terhadap satu parameter saja, bukan terhadap hubungan antara satu parameter dengan parameter lainnya, contohnya seperti: hubungan antara parameter jumlah iterasi pencarian maksimum dan \emph{threshold} batas tolerir pengambilan jawaban. Penulis tidak sempat melakukan kombinasi parameter eksperimen tersebut dikarenakan oleh keterbatasan sumber daya (mesin komputasi dan waktu). Oleh karena itu, saran penulis untuk penelitian selanjutnya, penelitian selanjutnya dapat mencoba untuk melakukan kombinasi parameter dan melakukan evaluasi dan analisis terhadap hasil yang telah didapatkan untuk mencari hubungan antar parameter yang telah dirancang, penelitian selanjutnya bisa saja hanya melakukan kombinasi parameter dan melakukan evaluasi dan analisis terhadap hasil yang telah didapatkan untuk mencari hubungan antar parameter yang telah dirancang, karena kodenya sudah penulis rancang dan sudah bisa berjalan dengan lancar, sehingga penelitian selanjutnya bisa hanya benar-benar menjalankan kode yang sudah dirancang dan melakukan evaluasi dan analisis dari hasil yang telah didapatkan.
    
    \item \textbf{Eksplorasi model dan \emph{dataset} sistem tanya jawab yang lain}. Pada penelitian ini, penulis hanya menggunakan tiga model dan tiga \emph{dataset} sistem tanya jawab sebagai bahan eksperimen penelitian ini. Bisa saja dengan berjalannya waktu, akan ada model atau \emph{dataset} sistem tanya jawab baru yang menjadi tolak ukur (\emph{benchmark}) yang lebih reliabel daripada model dan \emph{dataset} sistem tanya jawab yang penulis gunakan pada penelitian ini. Oleh karena itu, saran penulis untuk penelitian selanjutnya, penelitian selanjutnya dapat mencoba eksplorasi model dan \emph{dataset} sistem tanya jawab yang lain yang setidaknya lebih baru (\emph{novelty}), untuk menguji generalisasi dari peningkatan performa yang didapatkan dari penelitian ini.
    
    \item \textbf{Eksplorasi metode pemanfaatan NLI 
    untuk sistem tanya jawab lainnya}. Pada penelitian ini, penulis hanya menggunakan dua metode saja, yaitu: \emph{intermediate-task transfer learning} dan \emph{task recasting} sebagai verifikator saja. Kemungkinan besar, masih ada metode lain untuk memanfaatkan NLI pada sistem tanya jawab, mungkin saja bisa seperti: \emph{task recasting} sebagai penghasil jawaban, bukan sekadar sebagai verifikator saja. Oleh karena itu, saran penulis untuk penelitian selanjutnya, penelitian selanjutnya dapat mencoba eksplorasi metode-metode lain pemanfaatan NLI pada sistem tanya jawab, agar peningkatan performa sistem tanya jawab bisa lebih signifikan dibandingkan dengan penelitian ini.

    \item \textbf{Memahami alasan mengapa metode \emph{intermediate-task transfer learning} berhasil meningkatkan performa sistem tanya jawab}. Pada penelitian ini, penulis tidak menjelaskan alasan pasti mengapa metode \emph{intermediate-task transfer learning} berhasil meningkatkan performa sistem tanya jawab (\emph{model explainability}). Penelitian ini hanya sebatas bereksperimen apakah metode \emph{intermediate-task transfer learning} dapat meningkatkan performa sistem tanya jawab? Dan juga, apa karakteristik pasangan konteks-pertanyaan-jawaban apa saja yang bisa meningkat tingkat kebenarannya karena pemanfaatan NLI ini. Oleh karena itu, saran penulis untuk penelitian selanjutnya, penelitian selanjutnya dapat mencoba menjelaskan alasan mengapa dan bagaimana metode \emph{intermediate-task transfer learning} berhasil meningkatkan performa sistem tanya jawab.

    \item \textbf{Memahami alasan mengapa metode \emph{task recasting} sebagai verifikator tidak berhasil meningkatkan performa sistem tanya jawab}. Pada penelitian ini, penulis tidak menjelaskan alasan pasti mengapa metode \emph{task recasting} sebagai verifikator tidak berhasil meningkatkan performa sistem tanya jawab. Penelitian ini hanya sebatas bereksperimen apakah metode \emph{task recasting} sebagai verifikator dapat meningkatkan performa sistem tanya jawab? Dan juga, apa karakteristik pasangan konteks-pertanyaan-jawaban apa saja yang bisa meningkat tingkat kebenarannya karena pemanfaatan NLI ini. Oleh karena itu, saran penulis untuk penelitian selanjutnya, penelitian selanjutnya dapat mencoba menjelaskan alasan mengapa dan bagaimana metode \emph{task recasting} sebagai verifikator tidak berhasil meningkatkan performa sistem tanya jawab.
    
\end{enumerate}