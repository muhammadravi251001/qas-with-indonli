%-----------------------------------------------------------------------------%
\chapter{\babEmpat}
\label{bab:4}
%-----------------------------------------------------------------------------%
Bab keempat ini menjelaskan tentang implementasi teknis yang penulis lakukan dalam penelitian ini. Sub-bab 4.1 menjelaskan mengenai \emph{training} \emph{sequence classification task}. Sub-bab 4.2 menjelaskan mengenai  \emph{training} \emph{baseline} model \emph{question answering task}. Sub-bab 4.3 menjelaskan mengenai metode \emph{intermediate-task transfer learning}. Sub-bab 4.4 lalu menjelaskan mengenai metode \emph{task recasting} dengan IndoNLI sebagai verifikator.

%-----------------------------------------------------------------------------%
\section{\emph{Training} \emph{Sequence Classification Task}}
%-----------------------------------------------------------------------------%
Pada sub-bab ini, akan dijelaskan mengenai \emph{training} model pada tugas \emph{sequence classification} dalam belajar \emph{natural language inference} yang penulis lakukan pada pada penelitian ini. 

%-----------------------------------------------------------------------------%
\subsection{Pengambilan Parameter Untuk \emph{Training Sequence Classification Task}}
%-----------------------------------------------------------------------------%
Pengambilan parameter untuk \emph{training sequence classification task} menggunakan bantuan \emph{library} dari \texttt{argparse}. Penulis gunakan \texttt{argparse} agar dapat menjalankan eksperimen via \emph{terminal} bukan dengan satu-satu menjalankan via \emph{notebook}. Parameter yang dapat digunakan dalam \emph{training sequence classification task} ini meliputi: nama model, nama \emph{dataset}, jumlah \emph{epoch}, jumlah sampel data, jumlah \emph{learn rate}, jumlah \emph{seed}, jumlah \emph{batch size}, jumlah \emph{gradient accumulation}, dan token akun Hugging Face agar dapat otomatis \emph{push} ke akun Hugging Face-nya. Untuk pilihan nilai dari masing-masing parameternya, penulis sertakan di tabel bawah ini.

\begin{table}[h!]
\centering
\begin{tabular}{|P{2.0in}|P{4.0in}|}
 \hline
 Parameter & Pilihan Nilai \\ [0.5ex] 
 \hline
 Nama model & \texttt{indobert-base-uncased}, \texttt{indobert-large-p2}, \texttt{xlm-roberta-large} \\ 
 Nama data & IndoNLI-\emph{basic}, IndoNLI-\emph{translated}, IndoNLI-\emph{augmented} \\
 Jumlah \emph{epoch} & Isi dengan \emph{integer} berapapun \\
 Jumlah sampel & Isi dengan \emph{integer} berapapun, atau dengan \emph{string} \texttt{max} \\
 Jumlah \emph{learn rate} & Isi dengan \emph{float} berapapun \\ 
 Jumlah \emph{seed} & Isi dengan \emph{integer} berapapun \\ 
 Jumlah \emph{batch size} & Isi dengan \emph{integer} berapapun \\ 
 Jumlah \emph{gradient accumulation} & Isi dengan \emph{integer} berapapun \\ 
 \emph{Token} & Isi dengan \emph{string} \emph{token} yang tertera pada Hugging Face \\[1ex] 
 \hline
\end{tabular}
\caption{Tabel parameter dan pilihan nilai pada \emph{training sequence classification} IndoNLI}
\end{table}

%-----------------------------------------------------------------------------%
\subsection{Pemilihan \emph{Hyperparameter} Untuk \emph{Sequence Classification Task}}
%-----------------------------------------------------------------------------%
Selain dari \emph{hyperparameter} yang dapat diatur pada pengambilan parameter sebelumnya, terdapat beberapa \emph{hyperparameter} permanen untuk penelitian ini, berikut \emph{hyperparameter} yang tidak bisa diubah-ubah via \texttt{argparse}.

\begin{table}[h]
\centering
\begin{tabular}{||c | c||} 
 \hline\hline
 \emph{Hyperparameter} & Nilai \\ [0.5ex] 
 \hline\hline
 MAX LENGTH & 512 \\ 
 STRIDE & 128 \\
 LOGGING STEPS & 50 \\
 WARMUP RATIO & 0.0 \\
 WEIGHT DECAY & 0.0 \\ 
 EVAL STEPS RATIO & 0.5 \\ [1ex] 
 \hline\hline
\end{tabular}
\caption{Tabel \emph{hyperparameter} pada \emph{training sequence classification} IndoNLI}
\end{table}

%-----------------------------------------------------------------------------%
\subsection{Mengimpor \emph{Dataset} IndoNLI}
%-----------------------------------------------------------------------------%
Pada tahap ini, akan dijalankan pengambilan \emph{dataset} IndoNLI dari Hugging Face maupun GitHub dan penyamaan format \texttt{DatasetDict}. Tujuan dilakukan hal tersebut agar dapat lebih mempermudah eksperimen kedepannya. Untuk \emph{dataset} IndoNLI-\emph{basic}, penulis hanya mengambil via Hugging Face saja dengan fungsi \texttt{load\char`_dataset("indonli")}. 

Lalu, untuk \emph{dataset} IndoNLI-\emph{translated}, penulis mengambil via pranala: \href{https://huggingface.co/datasets/muhammadravi251001/translated-indo-nli}{\texttt{huggingface.co/datasets/muhammadravi251001/translated-indo-nli}} dan melakukan penyamaan format sehingga sama dengan \emph{dataset} IndoNLI-\emph{basic}, penyamaan format tersebut meliputi: mengubah nama kolom (\emph{column renaming}), mengganti nilai label yang sebelumnya merupakan \emph{string} menjadi \emph{integer} ID, menghapus label yang tidak diketahui (\emph{unknown}), dan mengubah tipe data menjadi \texttt{DatasetDict}. 

Terakhir, untuk \emph{dataset} IndoNLI-\emph{translated}, penulis mengambil via pranala: \href{https://huggingface.co/datasets/muhammadravi251001/augmented-indo-nli}{\texttt{huggingface.co/datasets/muhammadravi251001/augmented-indo-nli}}, penyamaan format meliputi: menghapus label yang tidak diketahui (\emph{unknown}) dan mengubah tipe data menjadi \texttt{DatasetDict}.

%-----------------------------------------------------------------------------%
\subsection{Proses \emph{Preprocess} dan Tokenisasi \emph{Dataset} IndoNLI}
%-----------------------------------------------------------------------------%
Pada tahap ini, akan dijalankan  \emph{preprocess} dan tokenisasi \emph{dataset} IndoNLI. Tokenisasi dijalankan dengan melakukan tokenisasi pada bagian \texttt{premise} dan \texttt{hypothesis} saja, dengan menggunakan \emph{hyperparameter} yang sebelumnya sudah ditentukan. \emph{Preprocess} dijalankan dengan beberapa parameter tambahan, seperti: \texttt{truncation=True} dan \texttt{return\char`_token\char`_type\char`_ids=True}. Parameter \texttt{truncation} berfungsi untuk memotong (\emph{truncate}) karakter sesuai parameter \texttt{MAX LENGTH} yang dijelaskan sebelumnya dan parameter \texttt{return\char`_token\char`_type\char`_ids} digunakan untuk mengembalikan \texttt{TOKEN\char`_IDS} yang berguna untuk membedakan antara \texttt{premise} dan \texttt{hypothesis}-nya, agak berbeda sedikit dengan model \texttt{xlm-roberta-large}, karena model tersebut tidak mengenal konsep \texttt{return\char`_token\char`_type\char`_ids}, maka cara untuk membedakan antara \texttt{premise} dan \texttt{hypothesis}-nya dengan menggunakan fungsi \texttt{index} bawaan Python dengan mencari ID = 2 (\texttt{</s>}) pada \texttt{input\char`_ids} sebagai pemisahnnya. 

Kemudian, untuk proses tokenisasi penulis menggunakan fungsi \texttt{map} bawaan dari \emph{library} \texttt{datasets}, dengan tambahan parameter \texttt{batched=True} dan \texttt{remove\char`_columns=['premise', 'hypothesis']}. Parameter \texttt{batched} berfungsi untuk memecah (\emph{batch}) \emph{dataset} agar dapat diproses per-\emph{batch} demi efisiensi penggunaan memori dan \texttt{remove\char`_columns} digunakan untuk menghapus kolom yang tidak digunakan dalam proses \emph{training} hal tersebut ditujukan untuk agar \emph{dataset} lebih terfokus kepada hal-hal yang penting saja, seperti \texttt{label} dan data hasil tokenisasi dari \texttt{premise} dan   \texttt{hypothesis} yang sudah tersimpan di variabel \texttt{input\char`_ids} saja disamping untuk efisiensi penggunaan memori.

Terakhir, penulis mengubah format kolom \texttt{input\char`_ids} dan \texttt{token\char`_type\char`_ids} keluaran dari tokenisasi dengan fungsi \texttt{set\char`_format} agar hasil tokenisasi berformat \texttt{torch}; format \texttt{torch} digunakan untuk menyuplai variabel ke \texttt{device} GPU yang penulis gunakan, setelah itu, penulis memecah hasil tokenisasi tersebut ke dua \emph{dataset}, yaitu: \emph{dataset train} dan \emph{dataset validation}, yang disimpan dalam bentuk \texttt{DatasetDict}.

%-----------------------------------------------------------------------------%
\subsection{Mengimpor Model \emph{Sequence Classification}}
%-----------------------------------------------------------------------------%
Pada tahapan ini, penulis menyuplai \texttt{pretrained\char`_model\char`_name\char`_or\char`_path} sesuai dengan parameter yang telah dipilih via \texttt{argparse} sebelumnya dan penulis menyuplai banyak label sebanyak 3, karena hasil label dari persoalan NLI di IndoNLI memiliki tiga label akhir, yaitu: \emph{entailment}, \emph{neutral}, \emph{contradiction}. Hal tersebut digunakan agar hasil dari klasifier akhir model yang telah dipilih menghasilkan tiga \emph{unit} saja sesuai dengan kebutuhan \emph{task} yang sedang dilakukan, yaitu: \emph{sequence classification task}. Pendefinisian model \emph{sequence classification} ini menggunakan modul \texttt{AutoModelForSequenceClassification}.

Kemudian, tidak lupa juga menyuplai \texttt{id2label} dan \texttt{label2id}. Dimana, isi dari \texttt{id2label} adalah \emph{mapping} dari \emph{integer} ID ke tiga label yang masih berformat \emph{string} dan sebaliknya; isi dari \texttt{label2id} adalah \emph{mapping} dari tiga label yang masih berformat \emph{string} ke \emph{integer} ID. Terakhir, penulis juga memindahkan model yang sudah dibuat tersebut ke \texttt{device} GPU yang penulis pilih dengan fungsi \texttt{.to(device)}.

%-----------------------------------------------------------------------------%
\subsection{Perancangan Metrik Komputasi Untuk Penilaian \emph{Sequence Classification Task}}
%-----------------------------------------------------------------------------%
Pada perancangan metrik komputasi \emph{sequence classification task}, penulis menggunakan \emph{library} dari \texttt{evaluate} untuk menggunakan metrik akurasi dan skor F1, dimana skor F1 penulis atur ke \texttt{average="weighted"} karena tipe \emph{average weighted} dapat menghitung metrik setiap label dengan memperhatikan \emph{label imbalance}. Perhitungan metrik akurasi dan skor F1 dilakukan secara bersamaan dengan fungsi \texttt{load} bawaan dari \emph{library} \texttt{evaluate} dengan parameter \texttt{'accuracy'} dan \texttt{'f1'}. Hasil prediksi dari model didapatkan dari hasil fungsi \texttt{np.argmax} terhadap properti \texttt{predictions} dengan parameter \texttt{axis=1}; dan \emph{golden truth} didapatkan dari properti \texttt{label\char`_ids}.

%-----------------------------------------------------------------------------%
\subsection{Perancangan Penamaan Eksperimen \emph{Sequence Classification Task}}
%-----------------------------------------------------------------------------%
Pada tahap ini, penulis merancang penamaan eksperimen agar dapat melakukan evaluasi \& analisis terkait eksperimen dengan lebih mudah, rapih, dan teratur. Pada penamaan eksperimen \emph{sequence classification task} ini, penulis memastikan untuk memberikan nama yang memenuhi berisi: nama model, nama \emph{dataset} yang digunakan, jumlah \emph{learn rate}. Penamaan tersebut berguna untuk melakukan penyimpanan eksperimen ke lokal dan saat \emph{push} ke repositori Hugging Face. 

Untuk pengarsipan eksperimen ke lokal, penulis memasukan ke dalam satu folder besar yang didalamnya berisi empat folder-folder kecil; nama folder besar tersebut merupakan gabungan dari \emph{prefix} \texttt{IndoNLI}, nama \emph{dataset} yang digunakan, nama model, jumlah \emph{learn rate}, dan juga waktu saat mulai menjalankan \emph{training}. Kemudian, folder-folder kecilnya terdiri dari folder \emph{checkpoint}, \emph{model}, \emph{output}, \emph{metric result}. Dimana, folder \emph{checkpoint} digunakan untuk menyimpan \emph{checkpoint} saat \emph{training} \emph{sequence classification task}; kemudian, folder \emph{model} digunakan untuk menyimpan \emph{model} akhir setelah \emph{training} \emph{sequence classification task}; lalu, folder \emph{output} digunakan untuk menyimpan \emph{output} akhir hasil dari prediksi model yang sudah dilatih tersebut terhadap data \emph{validation}; terakhir, folder \emph{metric result} berisi terkait perhitungan metrik dari model yang sudah dilatih tersebut terhadap data \emph{validation}.

Untuk nama repositori pada Hugging Face memiliki beberapa syarat penamaan, antara lain: memiliki \emph{prefix} "\emph{fine-tuned} \texttt{IndoNLI}", nama \emph{dataset} yang digunakan, nama model, dan jumlah \emph{learn rate}, tanpa waktu saat mulai menjalankan \emph{training}, dan juga dibatasi hingga 96 karakter saja mengikuti aturan penamaan repositori dari Hugging Face.

%-----------------------------------------------------------------------------%
\subsection{Perancangan Argumen Latih (\emph{Training Arguments}) \emph{Sequence Classification}}
%-----------------------------------------------------------------------------%
Pada tahap ini, penulis merancang \emph{training arguments} dengan modul \texttt{TrainingArguments} agar jalannya eksperimen sesuai parameter yang telah dipilih sebelumnya, seperti: jumlah \emph{epoch}, jumlah \emph{learn rate}, jumlah \emph{seed}, jumlah \emph{batch size}, jumlah \emph{gradient accumulation}, \emph{token}; dan juga \emph{hyperparameter} permanen, seperti:  \texttt{LOGGING STEPS}, \texttt{WEIGHT DECAY}, \texttt{WARMUP RATIO}. 

\texttt{STEP} disesuaikan dengan rumus: \texttt{BATCH SIZE $\times$ GRADIENT ACCUMULATION $\times$ EVAL STEPS RATIO} ditujukan agar model melakukan evaluasi setiap \texttt{EVAL STEPS RATIO} agar dapat melakukan \emph{early callback} nantinya untuk efisiensi \emph{training}. Pemilihan \emph{best model} dipilih ke metrik skor F1, karena metrik F1 dapat mengatasi permasalahan \emph{label imbalance}.

Pada bagian ini juga dilakukan penyimpanan terkait data (\emph{data-ops}) yang juga disuplai kepada parameter \texttt{TrainingArguments}, seperti: direktori \emph{checkpoint}, \emph{logging platform} yang otomatis diatur ke \texttt{tensorboard}, strategi \emph{logging}, strategi penyimpanan, dan strategi evaluasi yang otomatis diatur ke \texttt{steps}, Kecenderungan penulis untuk menggunakan \texttt{steps} pada bagian ini dikarenakan nantinya penulis akan menggunakan parameter \texttt{load\char`_best\char`_model\char`_at\char`_end} sebagai \texttt{True}, dan dimana strategi penyimpanan dan strategi evaluasi harus diatur ke \texttt{steps} sesuai dengan aturan dari modul \texttt{TrainingArguments}.

Kemudian, pada sisi memori saat melakukan \emph{training}, penulis menyuplai parameter \texttt{dataloader\char`_num\char`_workers=cpu\char`_count()} agar dapat menggunakan subproses (paralelisme) yang digunakan untuk memuat data sesuai dengan banyaknya CPU pada sistem; dan juga penulis menyuplai parameter \texttt{push\char`_to\char`_hub=True} untuk otomatis \emph{push} ke repositori Hugging Face saat menjalankan \emph{training}, sesuai dengan nama repositori yang telah dijelaskan di sub-bab sebelumnya, dan suplai parameter \texttt{load\char`_best\char`_model\char`_at\char`_end=True} agar model yang nanti diambil merupakan hasil model yang terbaik dari sepanjang proses \emph{training}.

%-----------------------------------------------------------------------------%
\subsection{Melakukan \emph{Training} dan Prediksi Jawaban \emph{Sequence Classification}}
%-----------------------------------------------------------------------------%
Pada tahap ini, dilakukan \emph{training} dengan menggunakan data \emph{train} dan data \emph{validation} sebagai parameter \emph{training}-nya. Penulis juga melakukan \emph{early callback} dengan nilai \emph{patience} sebesar 3, yang artinya model akan berhenti \emph{training} bila tiga hasil evaluasi setelahnya memiliki nilai metrik yang lebih kecil dibanding sebelumnya; hal tersebut dilakukan untuk efisiensi waktu dan \emph{resource} \emph{training}-nya. 

Sehingga, pada tahap ini, penulis menyuplai beberapa parameter pada modul \texttt{Trainer}, antara lain: model yang digunakan, \emph{training arguments} yang sebelumnya sudah didefinisikan, \emph{train\_dataset} yang diatur ke data \emph{train}-nya, \emph{validation\_dataset} yang diatur ke data \emph{validation}-nya, \emph{tokenizer} yang digunakan, \emph{data\_collator} yang digunakan, metrik komputasi yang sebelumnya sudah dirancang, dan \emph{callbacks} dimana diatur ke \emph{early callback} dengan \emph{patience} sebesar 3. Kemudian, terakhir, dilakukan prediksi terhadap data \emph{validation}, dengan menggunakan fungsi \texttt{predict}.

%-----------------------------------------------------------------------------%
\subsection{Representasi Prediksi Jawaban \emph{Sequence Classification}}
%-----------------------------------------------------------------------------%
Pada tahap ini, penulis mengubah \texttt{PredictionOutput} hasil dari prediksi model menjadi sebuah \texttt{DataFrame} yang dapat dibaca secara jelas oleh manusia. Tahapan ini berguna untuk evaluasi dan analisis kedepannya. Pada tahap ini, penulis mengekstrak \texttt{premise}, \texttt{hypothesis}, \texttt{prediction label}, \texttt{golden label} dari \texttt{PredictionOutput} hasil dari prediksi model dan diubah dalam bentuk \texttt{DataFrame}. 

Proses pemisahan antara \texttt{premise} dan \texttt{hypothesis} menggunakan properti \texttt{token\char`_type\char`_ids}, dimana bila \texttt{token\char`_type\char`_ids} bernilai 0, maka \texttt{input\char`_ids} yang bersangkutan merupakan sebuah bagian dari \texttt{premise}, sebaliknya bila \texttt{token\char`_type\char`_ids} bernilai 1, maka \texttt{input\char`_ids} yang bersangkutan merupakan sebuah bagian dari \texttt{hypothesis}; hal tersebut sesuai dengan urutan \emph{preprocess} dan tokenisasi dimana urutannya \texttt{premise} lalu \texttt{hypothesis}. Namun agak berbeda sedikit dengan model \texttt{xlm-roberta-large}, karena model tersebut tidak mengenal konsep \texttt{return\char`_token\char`_type\char`_ids}, maka cara untuk membedakan antara \texttt{premise} dan \texttt{hypothesis}-nya dengan menggunakan fungsi \texttt{index} bawaan Python dengan mencari ID = 2 (\texttt{</s>}) pada \texttt{input\char`_ids} sebagai pemisahnnya. 

%-----------------------------------------------------------------------------%
\subsection{Melakukan \emph{push} \emph{sequence classification} ke akun Hugging Face}
%-----------------------------------------------------------------------------%
Pada tahapan ini, sederhananya, penulis hanya melakukan \emph{push} hasil eksperimen, meliputi: model, evaluasi, dan keluaran dari eksperimen ke akun Hugging Face yang telah disuplai \texttt{TOKEN}-nya pada bagian parameter sebelumnya. Proses \emph{push} menggunakan API khusus Hugging Face, yaitu: \texttt{HfApi} dimana pengunggahan dilakukan dengan fungsi \texttt{upload\char`_folder}, kemudian hanya untuk folder \emph{output} dan folder \emph{metric result} saja yang diunggah ke repositori Hugging Face karena hanya folder-folder tersebut saja yang dirasa berguna untuk evaluasi dan analisis kedepannya. Untuk folder \emph{model} sudah otomatis diunggah saat \emph{training} karena penggunaan parameter \texttt{push\char`_to\char`_hub=True} pada pendefinisian \emph{TrainingArguments} sebelumnya.

%-----------------------------------------------------------------------------%
\section{\emph{Training} \emph{Baseline} Model \emph{Question Answering Task}}
%-----------------------------------------------------------------------------%
Pada sub-bab ini, akan dijelaskan mengenai \emph{training} model pada tugas \emph{question answering task} dalam belajar tiga \emph{dataset} sistem tanya jawab yang penulis lakukan pada pada penelitian ini.

%-----------------------------------------------------------------------------%
\subsection{Pengambilan Parameter Untuk \emph{Training Baseline Question Answering Task}}
%-----------------------------------------------------------------------------%
Pengambilan parameter untuk \emph{training question answering task} menggunakan bantuan \emph{library} dari \texttt{argparse}. Penulis gunakan \texttt{argparse} agar dapat menjalankan eksperimen via \emph{terminal} bukan dengan satu-satu menjalankan via \emph{notebook}. Parameter yang dapat digunakan dalam \emph{training question answering task} ini meliputi: nama model, nama \emph{dataset}, jumlah \emph{epoch}, jumlah sampel data, jumlah \emph{learn rate}, jumlah \emph{seed}, jumlah \emph{batch size}, jumlah \emph{gradient accumulation}, pilihan apakah mau melakukan \emph{intermediate-task transfer learning}, pilihan apakah mau melakukan \emph{freezing layer}, dan token akun Hugging Face agar dapat otomatis \emph{push} ke akun Hugging Face-nya. Untuk pilihan nilai dari masing-masing parameternya, penulis sertakan di tabel bawah ini.

\begin{table}[h!]
\centering
\begin{tabular}{|P{2.0in}|P{4.0in}|}
 \hline
 Parameter & Pilihan Nilai \\ [0.5ex] 
 \hline
 Nama model & \texttt{indobert-base-uncased}, \texttt{indobert-large-p2}, \texttt{xlmr-large} \\ 
 Nama data & SQuAD-ID, TyDI-QA-ID, IDK-MRC \\
 Jumlah \emph{epoch} & Isi dengan \emph{integer} berapapun \\
 Jumlah sampel & Isi dengan \emph{integer} berapapun, atau dengan \emph{string} \texttt{max} \\
 Jumlah \emph{learn rate} & Isi dengan \emph{float} berapapun \\ 
 Jumlah \emph{seed} & Isi dengan \emph{integer} berapapun \\ 
 Jumlah \emph{batch size} & Isi dengan \emph{integer} berapapun \\ 
 Jumlah \emph{gradient accumulation} & Isi dengan \emph{integer} berapapun \\ 
 \emph{Token} & Isi dengan \emph{string} \emph{token} yang tertera pada Hugging Face \\
 \emph{With ITTL} & \texttt{True} atau \texttt{False} \\
 \emph{With Freezing Layer} & \texttt{True} atau \texttt{False} \\ [1ex] 
 \hline
\end{tabular}
\caption{Tabel parameter dan pilihan nilai pada \emph{training question answering} \emph{baseline} model \emph{question answer task}. Catatan: ITTL pada tabel tersebut merupakan singkatan dari \emph{Intermediate-Task Transfer Learning}.}
\end{table}

Namun, pada bagian \emph{training question answering baseline} ini, parameter \emph{With ITTL} akan diatur sebagai \texttt{False} dan parameter \emph{With Freezing Layer} juga akan diatur sebagai \texttt{False}. Untuk kedua parameter tersebut akan dapat bisa diatur sebagai \texttt{True} pada bagian selanjutnya: \emph{training question answering intermediate-task transfer learning}, yang terdapat pada sub-bab selanjutnya.

%-----------------------------------------------------------------------------%
\subsection{Pemilihan \emph{Hyperparameter} Untuk \emph{Baseline Question Answering Task}}
%-----------------------------------------------------------------------------%
Selain dari \emph{hyperparameter} yang dapat diatur pada pengambilan parameter di atas, terdapat beberapa \emph{hyperparameter} permanen untuk penelitian ini, berikut \emph{hyperparameter} yang tidak bisa diubah-ubah via \texttt{argparse}.

\begin{table}[h]
\centering
\begin{tabular}{||c | c||} 
 \hline\hline
 \emph{Hyperparameter} & Nilai \\ [0.5ex] 
 \hline\hline
 MAX LENGTH & 512 \\ 
 STRIDE & 128 \\
 LOGGING STEPS & 50 \\
 WARMUP RATIO & 0.0 \\
 WEIGHT DECAY & 0.0 \\ 
 EVAL STEPS RATIO & 0.5 \\ [1ex] 
 \hline\hline
\end{tabular}
\caption{Tabel \emph{hyperparameter} pada \emph{training question answering} \emph{baseline} sistem tanya jawab}
\end{table}

%-----------------------------------------------------------------------------%
\subsection{Mengimpor \emph{Dataset} Sistem Tanya Jawab}
%-----------------------------------------------------------------------------%
Pada tahap ini, akan dijalankan pengambilan semua \emph{dataset} sistem tanya jawab yang akan dieksperimenkan dari \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} dan penyamaan format \texttt{DatasetDict}. Tujuan dilakukan hal tersebut agar dapat lebih mempermudah eksperimen kedepannya. Untuk \emph{dataset} SQuAD-ID, penulis hanya mengambil via \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} dengan bantuan modul \texttt{NusantaraConfigHelper()} dengan fungsi \texttt{load\char`_dataset} dengan nama \emph{dataset}-nya adalah: \texttt{squad\char`_id}. 

\emph{Preprocess} yang penulis lakukan untuk \emph{dataset} SQuAD-ID meliputi: melakukan format ulang kolom \emph{context}, \emph{question}, \emph{answer}, \emph{answer\_start}, dan \emph{answer\_end}, dimana  \emph{answer\_start} dan \emph{answer\_end} merupakan bagian dari \emph{dictionary answer}; kemudian, penulis melakukan pemecahan \emph{dataset} menjadi tiga bagian, yaitu: data \emph{train}, data \emph{validation}, dan data \emph{test}. Pembagian tersebut dilakukan secara manual, karena pada \emph{library} \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} tidak menyediakan data \emph{test}. Untuk mencapai perbandingan yang seimbang dengan data \emph{validation} (perbandingan 8:1:1), maka untuk data \emph{train} penulis pecah menjadi dua, menjadi data \emph{train} dan data \emph{validation}, dan data \emph{validation} yang sebelumnya didapatkan dari \emph{library} \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} diubah menjadi data \emph{test}-nya. Pemecahan (\emph{splitting}) tersebut mempertahankan perbandingan 8:1:1 antara data \emph{train}, data \emph{validation}, dan data \emph{test} dan juga tetap mempertahankan persebaran jenis pertanyaan diantara ketiga bagian data tersebut; kemudian, mengubah ketiga bagian data tersebut menjadi format \texttt{Dataset}, sehingga ketiganya bisa digabung dalam format \texttt{DatasetDict}.

Lalu, untuk \emph{dataset} TyDI-QA-ID, penulis hanya mengambil via \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} dengan bantuan modul \texttt{NusantaraConfigHelper()} dengan fungsi \texttt{load\char`_dataset} dengan nama \emph{dataset}-nya adalah: \texttt{tydiqa\char`_id}. \emph{Preprocess} yang penulis lakukan untuk \emph{dataset} TyDI-QA-ID meliputi: membuat kolom \emph{answer\_end} dengan menambahkan nilai dari \emph{answer\_start} dengan panjang \emph{answer}, hal ini bertujuan untuk mempermudah tokenisasi nantinya; lalu, melakukan format ulang kolom \emph{context}, \emph{question}, \emph{answer}, \emph{answer\_start}, dan \emph{answer\_end}, dimana  \emph{answer\_start} dan \emph{answer\_end} merupakan bagian dari \emph{dictionary answer}; kemudian, penulis melakukan pemecahan \emph{dataset} menjadi tiga bagian, yaitu: data \emph{train}, data \emph{validation}, dan data \emph{test}. Pembagian tersebut dilakukan secara otomatis, karena pada \emph{library} \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} telah menyediakan ketiga bagian data tersebut; kemudian, mengubah ketiga bagian data tersebut menjadi format \texttt{Dataset}, sehingga ketiganya bisa digabung dalam format \texttt{DatasetDict}.

Terakhir, untuk \emph{dataset} IDK-MRC, penulis hanya mengambil via \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} dengan bantuan modul \texttt{NusantaraConfigHelper()} dengan fungsi \texttt{load\char`_dataset} dengan nama \emph{dataset}-nya adalah: \texttt{idk\char`_mrc}. \emph{Preprocess} yang penulis lakukan untuk \emph{dataset} IDK-MRC mirip dengan \emph{preprocess} yang dilakukan pada \emph{dataset} TyDI-QA-ID, yaitu meliputi: membuat kolom \emph{answer\_end} dengan menambahkan nilai dari \emph{answer\_start} dengan panjang \emph{answer}, hal ini bertujuan untuk mempermudah tokenisasi nantinya; lalu, melakukan format ulang kolom \emph{context}, \emph{question}, \emph{answer}, \emph{answer\_start}, dan \emph{answer\_end}, dimana  \emph{answer\_start} dan \emph{answer\_end} merupakan bagian dari \emph{dictionary answer}; kemudian, penulis melakukan pemecahan \emph{dataset} menjadi tiga bagian, yaitu: data \emph{train}, data \emph{validation}, dan data \emph{test}. Pembagian tersebut dilakukan secara otomatis, karena pada \emph{library} \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} telah menyediakan ketiga bagian data tersebut; kemudian, mengubah ketiga bagian data tersebut menjadi format \texttt{Dataset} sehingga ketiganya bisa digabung dalam format \texttt{DatasetDict}.

%-----------------------------------------------------------------------------%
\subsection{Proses \emph{Preprocess} dan Tokenisasi \emph{Dataset} Sistem Tanya Jawab}
%-----------------------------------------------------------------------------%
Pada tahap ini, akan dijalankan  \emph{preprocess} dan tokenisasi \emph{dataset} sistem tanya jawab. Tokenisasi dijalankan dengan melakukan tokenisasi pada bagian \texttt{question} dan \texttt{context} saja, dengan menggunakan \emph{hyperparameter} yang sebelumnya sudah ditentukan. \emph{Preprocess} dijalankan dengan beberapa parameter tambahan, seperti: \texttt{truncation=True}, \texttt{return\char`_token\char`_type\char`_ids=True}, \texttt{return\char`_overflowing\char`_tokens=True}, \texttt{return\char`_offsets\char`_mapping=True}, \texttt{padding="max\char`_length"}, \texttt{return\char`_tensors='np'}.Parameter \texttt{truncation} berfungsi untuk memotong (\emph{truncate}) karakter sesuai parameter \texttt{MAX LENGTH} yang dijelaskan sebelumnya, lalu parameter \texttt{return\char`_token\char`_type\char`_ids} digunakan untuk mengembalikan \texttt{TOKEN\char`_IDS} yang berguna untuk membedakan antara \texttt{premise} dan \texttt{hypothesis}-nya. agak berbeda sedikit dengan model \texttt{xlm-roberta-large}, karena model tersebut tidak mengenal konsep \texttt{return\char`_token\char`_type\char`_ids}, maka cara untuk membedakan antara \texttt{premise} dan \texttt{hypothesis}-nya dengan menggunakan fungsi \texttt{index} bawaan Python dengan mencari ID = 2 (\texttt{</s>}) pada \texttt{input\char`_ids} sebagai pemisahnnya. 

Kemudian, parameter \texttt{return\char`_overflowing\char`_tokens} berfungsi untuk mendapatkan token-token yang berlebihan dari \texttt{MAX LENGTH} yang telah ditentukan (\emph{overflowing}), lalu, parameter \texttt{return\char`_offsets\char`_mapping} berfungsi untuk mengembalikan index (dalam level \emph{char}) dari suatu ID pada \texttt{input\char`_ids}, kemudian, parameter \texttt{padding} berfungsi untuk melakukan "pengisian" (\emph{pad}) untuk menyesuaikan panjang \texttt{input\char`_ids}-nya, dalam konteks \texttt{padding='max\char`_length'}, maka \texttt{padding} dilakukan sampai ID sama panjang dengan \texttt{MAX LENGTH}-nya; terakhir, parameter \texttt{return\char`_tensors} berfungsi untuk mengembalikan keluaran dalam bentuk \emph{tensor} agar mempermudah perubahan ke format \texttt{torch} nantinya. Sederhananya, pada tahap \emph{preprocess} ini, penulis menyuplai \texttt{answer\char`_start\char`_position} dan \texttt{answer\char`_end\char`_position} dengan menggunakan properti \texttt{offset\char`_mapping}, \texttt{overflow\char`_to\char`_sample\char`_mapping}, dan fungsi \texttt{sequence\char`_ids}.

Kemudian, untuk proses tokenisasi penulis menggunakan fungsi \texttt{map} bawaan dari \emph{library} \texttt{datasets}, dengan tambahan parameter \texttt{batched=True} dan \texttt{remove\char`_columns=['context', 'question', 'answer', 'offset\char`_mapping', 'overflow\char`_to\char`_sample\char`_mapping']}. Parameter \texttt{batched} berfungsi untuk memecah (\emph{batch}) \emph{dataset} agar dapat diproses per-\emph{batch} demi efisiensi penggunaan memori dan \texttt{remove\char`_columns} digunakan untuk menghapus kolom yang tidak digunakan dalam proses \emph{training} hal tersebut ditujukan untuk agar \emph{dataset} lebih terfokus kepada hal-hal yang penting saja, seperti \texttt{answer\char`_start\char`_position}, \texttt{answer\char`_end\char`_position} dan data hasil tokenisasi dari \texttt{context} dan   \texttt{question} yang sudah tersimpan di variabel \texttt{input\char`_ids} saja disamping untuk efisiensi penggunaan memori.

Terakhir, penulis mengubah format kolom \texttt{input\char`_ids} dan \texttt{token\char`_type\char`_ids} keluaran dari tokenisasi dengan fungsi \texttt{set\char`_format} agar hasil tokenisasi berformat \texttt{torch}; format \texttt{torch} digunakan untuk menyuplai variabel ke \texttt{device} GPU yang penulis gunakan, setelah itu, penulis memecah hasil tokenisasi tersebut ke tiga \emph{dataset}, yaitu: \emph{dataset train}, \emph{dataset validation}, dan \emph{dataset test}; yang disimpan dalam bentuk \texttt{DatasetDict}.

%-----------------------------------------------------------------------------%
\subsection{Mengimpor Model \emph{Question Answering}}
%-----------------------------------------------------------------------------%
Pada tahapan ini, penulis menyuplai \texttt{pretrained\char`_model\char`_name\char`_or\char`_path} sesuai dengan parameter yang telah dipilih via \texttt{argparse} sebelumnya dan penulis menyuplai banyak label sebanyak 2, karena pada \emph{question answering task} membutuhkan dua label, yaitu: \texttt{answer\char`_start\char`_position} dan \texttt{answer\char`_end\char`_position}. Hal tersebut digunakan agar hasil dari klasifier akhir model yang telah dipilih menghasilkan dua \emph{unit} saja sesuai dengan kebutuhan \emph{task} yang sedang dilakukan, yaitu: \emph{question answering task}. Pendefinisian model \emph{question answering} ini menggunakan modul \texttt{AutoModelForQuestionAnswering}. Terakhir, penulis juga memindahkan model yang sudah dibuat tersebut ke \texttt{device} GPU yang penulis pilih dengan fungsi \texttt{.to(device)}.

%-----------------------------------------------------------------------------%
\subsection{Perancangan Metrik Komputasi Untuk Penilaian \emph{Baseline Question Answering Task}}
%-----------------------------------------------------------------------------%
Pada perancangan metrik komputasi \emph{question answering task}, penulis melakukan kalkulasi skor \emph{exact match} dan skor F1 secara manual, tanpa menggunakan \emph{library} apapun, termasuk \emph{library} \texttt{evaluate}. Perhitungan metrik skor \emph{exact match} dan skor F1 dilakukan secara bersamaan. Perhitungan skor \emph{exact match} hanya dengan melakukan perbandingan antara jawaban prediksi dengan jawaban \emph{golden truth} dalam bentuk \emph{string}, jika sama persis maka skor \emph{exact match} akan ditambah dengan 1. 

Kemudian, perhitungan skor F1 lebih rumit dibandingkan perhitungan skor \emph{exact match}, berikut alurnya: melakukan normalisasi teks (menghapus kata-kata spesifik, menghapus spasi berlebih, menghapus tanda baca, mengganti huruf kapital dengan huruf kecil) jawaban prediksi dan jawaban \emph{golden truth}, lalu, setiap jawaban prediksi dan jawaban \emph{golden truth} akan dipecah menjadi token, pada token tersebutlah akan dihitung nilai \emph{confusion matrix}-nya (\emph{true positive}, \emph{true negative}, \emph{false positive}, dan \emph{false negative}), sehingga mendapatkan skor F1-nya, pada akhirnya, hasil metrik skor \emph{exact match} dan skor F1 akan dirata-ratakan sebagai metrik komputasi akhirnya. Hasil prediksi dari model didapatkan dari hasil fungsi \texttt{np.argmax} terhadap properti \texttt{predictions} dengan parameter \texttt{axis=2}; dan \emph{golden truth} didapatkan dari properti \texttt{label\char`_ids}. 

%-----------------------------------------------------------------------------%
\subsection{Perancangan Penamaan Eksperimen \emph{Baseline Question Answering Task}}
%-----------------------------------------------------------------------------%
Pada tahap ini, penulis merancang penamaan eksperimen agar dapat melakukan evaluasi \& analisis terkait eksperimen dengan lebih mudah, rapih, dan teratur. Pada penamaan eksperimen \emph{question answering task} ini, penulis memastikan untuk memberikan nama yang memenuhi berisi: nama model, nama \emph{dataset} yang digunakan, jumlah \emph{learn rate}. Penamaan tersebut berguna untuk melakukan penyimpanan eksperimen ke lokal dan saat \emph{push} ke repositori Hugging Face. 

Untuk pengarsipan eksperimen ke lokal, penulis memasukan ke dalam satu folder besar yang didalamnya berisi empat folder-folder kecil; nama folder besar tersebut merupakan gabungan dari \emph{prefix} \texttt{DatasetQAS}, nama \emph{dataset} yang digunakan, nama model, jumlah \emph{learn rate}, dan juga waktu saat mulai menjalankan \emph{training}. Kemudian, folder-folder kecilnya terdiri dari folder \emph{checkpoint}, \emph{model}, \emph{output}, \emph{metric result}. Dimana, folder \emph{checkpoint} digunakan untuk menyimpan \emph{checkpoint} saat \emph{training} \emph{question answering task}; kemudian, folder \emph{model} digunakan untuk menyimpan \emph{model} akhir setelah \emph{training} \emph{question answering task}; lalu, folder \emph{output} digunakan untuk menyimpan \emph{output} akhir hasil dari prediksi model yang sudah dilatih tersebut terhadap data \emph{validation}; terakhir, folder \emph{metric result} berisi terkait perhitungan metrik dari model yang sudah dilatih tersebut terhadap data \emph{test}. 

Untuk nama repositori pada Hugging Face memiliki beberapa syarat penamaan, antara lain: memiliki \emph{prefix} "\emph{fine-tuned} \texttt{DatasetQAS}", nama \emph{dataset} yang digunakan, nama model, dan jumlah \emph{learn rate}, tanpa waktu saat mulai menjalankan \emph{training}, dan juga dibatasi hingga 96 karakter saja mengikuti aturan penamaan repositori dari Hugging Face. Karena bagian ini merupakan \emph{training question answering baseline}, maka ada nama tambahan yang disimpan di lokal maupun pada repositori Hugging Face, yaitu: \emph{without-ITTL} dan \emph{without-freeze}.

%-----------------------------------------------------------------------------%
\subsection{Perancangan Argumen Latih (\emph{Training Arguments})}
%-----------------------------------------------------------------------------%
Pada tahap ini, penulis merancang \emph{training arguments} dengan modul \texttt{TrainingArguments} agar jalannya eksperimen sesuai parameter yang telah dipilih sebelumnya, seperti: jumlah \emph{epoch}, jumlah \emph{learn rate}, jumlah \emph{seed}, jumlah \emph{batch size}, jumlah \emph{gradient accumulation}, \emph{token}; dan juga \emph{hyperparameter} permanen, seperti:  \texttt{LOGGING STEPS}, \texttt{WEIGHT DECAY}, \texttt{WARMUP RATIO}. 

\texttt{STEP} disesuaikan dengan rumus: \texttt{BATCH SIZE $\times$ GRADIENT ACCUMULATION $\times$ EVAL STEPS RATIO} ditujukan agar model melakukan evaluasi setiap \texttt{EVAL STEPS RATIO} agar dapat melakukan \emph{early callback} nantinya untuk efisiensi \emph{training}. Pemilihan \emph{best model} dipilih ke metrik skor F1, karena metrik F1 dapat mengatasi permasalahan \emph{label imbalance}.

Pada bagian ini juga dilakukan penyimpanan terkait data (\emph{data-ops}) yang juga disuplai kepada parameter \texttt{TrainingArguments}, seperti: direktori \emph{checkpoint}, \emph{logging platform} yang otomatis diatur ke \texttt{tensorboard}, strategi \emph{logging}, strategi penyimpanan, dan strategi evaluasi yang otomatis diatur ke \texttt{steps}, Kecenderungan penulis untuk menggunakan \texttt{steps} pada bagian ini dikarenakan nantinya penulis akan menggunakan parameter \texttt{load\char`_best\char`_model\char`_at\char`_end} sebagai \texttt{True}, dan dimana strategi penyimpanan dan strategi evaluasi harus diatur ke \texttt{steps} sesuai dengan aturan dari modul \texttt{TrainingArguments}.

Kemudian, pada sisi memori saat melakukan \emph{training}, penulis menyuplai parameter \texttt{dataloader\char`_num\char`_workers=cpu\char`_count()} agar dapat menggunakan subproses (paralelisme) yang digunakan untuk memuat data sesuai dengan banyaknya CPU pada sistem; dan juga penulis menyuplai parameter \texttt{push\char`_to\char`_hub=True} untuk otomatis \emph{push} ke repositori Hugging Face saat menjalankan \emph{training}, sesuai dengan nama repositori yang telah dijelaskan di sub-bab sebelumnya, dan suplai parameter \texttt{load\char`_best\char`_model\char`_at\char`_end=True} agar model yang nanti diambil merupakan hasil model yang terbaik dari sepanjang proses \emph{training}.

%-----------------------------------------------------------------------------%
\subsection{Melakukan \emph{Training} dan Prediksi Jawaban \emph{Baseline Question Answering}}
%-----------------------------------------------------------------------------%
Pada tahap ini, dilakukan \emph{training} dengan menggunakan data \emph{train} dan data \emph{validation} sebagai parameter \emph{training}-nya. Penulis juga melakukan \emph{early callback} dengan nilai \emph{patience} sebesar 3, yang artinya model akan berhenti \emph{training} bila tiga hasil evaluasi setelahnya memiliki nilai metrik yang lebih kecil dibanding sebelumnya; hal tersebut dilakukan untuk efisiensi waktu dan \emph{resource} \emph{training}-nya. 

Sehingga, pada tahap ini, penulis menyuplai beberapa parameter pada modul \texttt{Trainer}, antara lain: model yang digunakan, \emph{training arguments} yang sebelumnya sudah didefinisikan, \emph{train\_dataset} yang diatur ke data \emph{train}-nya, \emph{validation\_dataset} yang diatur ke data \emph{validation}-nya, \emph{tokenizer} yang digunakan, \emph{data\_collator} yang digunakan, metrik komputasi yang sebelumnya sudah dirancang, dan \emph{callbacks} dimana diatur ke \emph{early callback} dengan \emph{patience} sebesar 3. Kemudian, terakhir, dilakukan prediksi terhadap data \emph{test}, dengan menggunakan fungsi \texttt{predict}.

%-----------------------------------------------------------------------------%
\subsection{Representasi Prediksi Jawaban Untuk Evaluasi dan Analisis}
%-----------------------------------------------------------------------------%
Pada tahap ini, penulis mengubah \texttt{PredictionOutput} hasil dari prediksi model menjadi sebuah \texttt{DataFrame} yang dapat dibaca secara jelas oleh manusia. Tahapan ini berguna untuk evaluasi dan analisis kedepannya. Pada tahap ini, penulis mengekstrak \texttt{context}, \texttt{question}, \texttt{prediction answer}, \texttt{golden answer} dari \texttt{PredictionOutput} hasil dari prediksi model dan diubah dalam bentuk \texttt{DataFrame}. 

Proses pemisahan antara \texttt{question} dan \texttt{context} menggunakan properti \texttt{token\char`_type\char`_ids}, dimana bila \texttt{token\char`_type\char`_ids} bernilai 0, maka \texttt{input\char`_ids} yang bersangkutan merupakan sebuah bagian dari \texttt{question}, sebaliknya bila \texttt{token\char`_type\char`_ids} bernilai 1, maka \texttt{input\char`_ids} yang bersangkutan merupakan sebuah bagian dari \texttt{question}; hal tersebut sesuai dengan urutan \emph{preprocess} dan tokenisasi dimana urutannya \texttt{question} lalu \texttt{question}. Namun agak berbeda sedikit dengan model \texttt{xlm-roberta-large}, karena model tersebut tidak mengenal konsep \texttt{return\char`_token\char`_type\char`_ids}, maka cara untuk membedakan antara \texttt{question} dan \texttt{context}-nya dengan menggunakan fungsi \texttt{index} bawaan Python dengan mencari ID = 2 (\texttt{</s>}) pada \texttt{input\char`_ids} sebagai pemisahnnya. 

%-----------------------------------------------------------------------------%
\subsection{Melakukan \emph{Push} ke Akun Hugging Face}
%-----------------------------------------------------------------------------%
Pada tahapan ini, sederhananya, penulis hanya melakukan \emph{push} hasil eksperimen, meliputi: model, evaluasi, dan keluaran dari eksperimen ke akun Hugging Face yang telah disuplai \texttt{TOKEN}-nya pada bagian parameter sebelumnya. Proses \emph{push} menggunakan API khusus Hugging Face, yaitu: \texttt{HfApi} dimana pengunggahan dilakukan dengan fungsi \texttt{upload\char`_folder}, kemudian hanya untuk folder \emph{output} dan folder \emph{metric result} saja yang diunggah ke repositori Hugging Face karena hanya folder-folder tersebut saja yang dirasa berguna untuk evaluasi dan analisis kedepannya. Untuk folder \emph{model} sudah otomatis diunggah saat \emph{training} karena penggunaan parameter \texttt{push\char`_to\char`_hub=True} pada pendefinisian \emph{TrainingArguments} sebelumnya.

%-----------------------------------------------------------------------------%
\section{Metode \emph{Intermediate-Task Transfer Learning}}
%-----------------------------------------------------------------------------%
Pada sub-bab ini, akan dijelaskan mengenai \emph{training} model pada tugas \emph{question answering task} dalam belajar tiga \emph{dataset} sistem tanya jawab dengan metode \emph{intermediate-task transfer learning} yang penulis lakukan pada pada penelitian ini. Secara keseluruhan, sub-bab ini cenderung mirip dengan sub-bab \emph{training} \emph{baseline} model \emph{question answering task}, namun ada beberapa perbedaan mendasar diantara kedua sub-bab ini.

%-----------------------------------------------------------------------------%
\subsection{Pengambilan Parameter Untuk \emph{Training Intermediate-Task Transfer Learning Question Answering Task}}
%-----------------------------------------------------------------------------%
Pengambilan parameter untuk \emph{training question answering task} menggunakan bantuan \emph{library} dari \texttt{argparse}. Penulis gunakan \texttt{argparse} agar dapat menjalankan eksperimen via \emph{terminal} bukan dengan satu-satu menjalankan via \emph{notebook}. Parameter yang dapat digunakan dalam \emph{training question answering task} ini meliputi: nama model, nama \emph{dataset}, jumlah \emph{epoch}, jumlah sampel data, jumlah \emph{learn rate}, jumlah \emph{seed}, jumlah \emph{batch size}, jumlah \emph{gradient accumulation}, pilihan apakah mau melakukan \emph{intermediate-task transfer learning}, pilihan apakah mau melakukan \emph{freezing layer}, dan token akun Hugging Face agar dapat otomatis \emph{push} ke akun Hugging Face-nya. Untuk pilihan nilai dari masing-masing parameternya, penulis sertakan di tabel bawah ini.

\begin{table}[h!]
\centering
\begin{tabular}{|P{2.0in}|P{4.0in}|}
 \hline
 Parameter & Pilihan Nilai \\ [0.5ex] 
 \hline
 Nama model & \texttt{indobert-base-uncased}, \texttt{indobert-large-p2}, \texttt{xlm-roberta-large} \\ 
 Nama data & SQuAD-ID, TyDI-QA-ID, IDK-MRC \\
 Jumlah \emph{epoch} & Isi dengan \emph{integer} berapapun \\
 Jumlah sampel & Isi dengan \emph{integer} berapapun, atau dengan \emph{string} \texttt{max} \\
 Jumlah \emph{learn rate} & Isi dengan \emph{float} berapapun \\ 
 Jumlah \emph{seed} & Isi dengan \emph{integer} berapapun \\ 
 Jumlah \emph{batch size} & Isi dengan \emph{integer} berapapun \\ 
 Jumlah \emph{gradient accumulation} & Isi dengan \emph{integer} berapapun \\ 
 \emph{Token} & Isi dengan \emph{string} \emph{token} yang tertera pada Hugging Face \\
 \emph{With ITTL} & \texttt{True} atau \texttt{False} \\
 \emph{With Freezing Layer} & \texttt{True} atau \texttt{False} \\ [1ex] 
 \hline
\end{tabular}
\caption{Tabel parameter dan pilihan nilai pada \emph{training question answering} \emph{intermediate-task transfer learning} model \emph{question answer task}. Catatan: ITTL pada tabel tersebut merupakan singkatan dari \emph{Intermediate-Task Transfer Learning}.}
\end{table}

Pada bagian \emph{training question answering intermediate-task transfer learning} ini, parameter \emph{With ITTL} akan diatur sebagai \texttt{True} dan parameter \emph{With Freezing Layer} boleh diatur sebagai \texttt{True} ataupun \texttt{False}. Parameter \emph{With Freezing Layer} boleh diubah secara opsional, untuk memberikan alternatif metode \emph{training}.

%-----------------------------------------------------------------------------%
\subsection{Pemilihan \emph{Hyperparameter} Untuk \emph{Intermediate-Task Transfer Learning Question Answering Task}}
%-----------------------------------------------------------------------------%
Selain dari \emph{hyperparameter} yang dapat diatur pada pengambilan parameter di atas, terdapat beberapa \emph{hyperparameter} permanen untuk penelitian ini, berikut \emph{hyperparameter} yang tidak bisa diubah-ubah via \texttt{argparse}.

\begin{table}[h]
\centering
\begin{tabular}{||c | c||} 
 \hline\hline
 \emph{Hyperparameter} & Nilai \\ [0.5ex] 
 \hline\hline
 MAX LENGTH & 512 \\ 
 STRIDE & 128 \\
 LOGGING STEPS & 50 \\
 WARMUP RATIO & 0.0 \\
 WEIGHT DECAY & 0.0 \\ 
 EVAL STEPS RATIO & 0.5 \\ [1ex] 
 \hline\hline
\end{tabular}
\caption{Tabel \emph{hyperparameter} pada \emph{training question answering} \emph{intermediate-task transfer learning} sistem tanya jawab}
\end{table}

%-----------------------------------------------------------------------------%
\subsection{Mengimpor \emph{Dataset} Sistem Tanya Jawab}
%-----------------------------------------------------------------------------%
Pada tahap ini, akan dijalankan pengambilan semua \emph{dataset} sistem tanya jawab yang akan dieksperimenkan dari \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} dan penyamaan format \texttt{DatasetDict}. Tujuan dilakukan hal tersebut agar dapat lebih mempermudah eksperimen kedepannya. Untuk \emph{dataset} SQuAD-ID, penulis hanya mengambil via \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} dengan bantuan modul \texttt{NusantaraConfigHelper()} dengan fungsi \texttt{load\char`_dataset} dengan nama \emph{dataset}-nya adalah: \texttt{squad\char`_id}. 

\emph{Preprocess} yang penulis lakukan untuk \emph{dataset} SQuAD-ID meliputi: melakukan format ulang kolom \emph{context}, \emph{question}, \emph{answer}, \emph{answer\_start}, dan \emph{answer\_end}, dimana  \emph{answer\_start} dan \emph{answer\_end} merupakan bagian dari \emph{dictionary answer}; kemudian, penulis melakukan pemecahan \emph{dataset} menjadi tiga bagian, yaitu: data \emph{train}, data \emph{validation}, dan data \emph{test}. Pembagian tersebut dilakukan secara manual, karena pada \emph{library} \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} tidak menyediakan data \emph{test}. Untuk mencapai perbandingan yang seimbang dengan data \emph{validation} (perbandingan 8:1:1), maka untuk data \emph{train} penulis pecah menjadi dua, menjadi data \emph{train} dan data \emph{validation}, dan data \emph{validation} yang sebelumnya didapatkan dari \emph{library} \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} diubah menjadi data \emph{test}-nya. Pemecahan (\emph{splitting}) tersebut mempertahankan perbandingan 8:1:1 antara data \emph{train}, data \emph{validation}, dan data \emph{test} dan juga tetap mempertahankan persebaran jenis pertanyaan diantara ketiga bagian data tersebut; kemudian, mengubah ketiga bagian data tersebut menjadi format \texttt{Dataset}, sehingga ketiganya bisa digabung dalam format \texttt{DatasetDict}.

Lalu, untuk \emph{dataset} TyDI-QA-ID, penulis hanya mengambil via \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} dengan bantuan modul \texttt{NusantaraConfigHelper()} dengan fungsi \texttt{load\char`_dataset} dengan nama \emph{dataset}-nya adalah: \texttt{tydiqa\char`_id}. \emph{Preprocess} yang penulis lakukan untuk \emph{dataset} TyDI-QA-ID meliputi: membuat kolom \emph{answer\_end} dengan menambahkan nilai dari \emph{answer\_start} dengan panjang \emph{answer}, hal ini bertujuan untuk mempermudah tokenisasi nantinya; lalu, melakukan format ulang kolom \emph{context}, \emph{question}, \emph{answer}, \emph{answer\_start}, dan \emph{answer\_end}, dimana  \emph{answer\_start} dan \emph{answer\_end} merupakan bagian dari \emph{dictionary answer}; kemudian, penulis melakukan pemecahan \emph{dataset} menjadi tiga bagian, yaitu: data \emph{train}, data \emph{validation}, dan data \emph{test}. Pembagian tersebut dilakukan secara otomatis, karena pada \emph{library} \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} telah menyediakan ketiga bagian data tersebut; kemudian, mengubah ketiga bagian data tersebut menjadi format \texttt{Dataset}, sehingga ketiganya bisa digabung dalam format \texttt{DatasetDict}.

Terakhir, untuk \emph{dataset} IDK-MRC, penulis hanya mengambil via \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} dengan bantuan modul \texttt{NusantaraConfigHelper()} dengan fungsi \texttt{load\char`_dataset} dengan nama \emph{dataset}-nya adalah: \texttt{idk\char`_mrc}. \emph{Preprocess} yang penulis lakukan untuk \emph{dataset} IDK-MRC mirip dengan \emph{preprocess} yang dilakukan pada \emph{dataset} TyDI-QA-ID, yaitu meliputi: membuat kolom \emph{answer\_end} dengan menambahkan nilai dari \emph{answer\_start} dengan panjang \emph{answer}, hal ini bertujuan untuk mempermudah tokenisasi nantinya; lalu, melakukan format ulang kolom \emph{context}, \emph{question}, \emph{answer}, \emph{answer\_start}, dan \emph{answer\_end}, dimana  \emph{answer\_start} dan \emph{answer\_end} merupakan bagian dari \emph{dictionary answer}; kemudian, penulis melakukan pemecahan \emph{dataset} menjadi tiga bagian, yaitu: data \emph{train}, data \emph{validation}, dan data \emph{test}. Pembagian tersebut dilakukan secara otomatis, karena pada \emph{library} \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} telah menyediakan ketiga bagian data tersebut; kemudian, mengubah ketiga bagian data tersebut menjadi format \texttt{Dataset} sehingga ketiganya bisa digabung dalam format \texttt{DatasetDict}.

%-----------------------------------------------------------------------------%
\subsection{Proses \emph{Preprocess} dan Tokenisasi \emph{Dataset} Sistem Tanya Jawab}
%-----------------------------------------------------------------------------%
Pada tahap ini, akan dijalankan  \emph{preprocess} dan tokenisasi \emph{dataset} sistem tanya jawab. Tokenisasi dijalankan dengan melakukan tokenisasi pada bagian \texttt{question} dan \texttt{context} saja, dengan menggunakan \emph{hyperparameter} yang sebelumnya sudah ditentukan. \emph{Preprocess} dijalankan dengan beberapa parameter tambahan, seperti: \texttt{truncation=True}, \texttt{return\char`_token\char`_type\char`_ids=True}, \texttt{return\char`_overflowing\char`_tokens=True}, \texttt{return\char`_offsets\char`_mapping=True}, \texttt{padding="max\char`_length"}, \texttt{return\char`_tensors='np'}.Parameter \texttt{truncation} berfungsi untuk memotong (\emph{truncate}) karakter sesuai parameter \texttt{MAX LENGTH} yang dijelaskan sebelumnya, lalu parameter \texttt{return\char`_token\char`_type\char`_ids} digunakan untuk mengembalikan \texttt{TOKEN\char`_IDS} yang berguna untuk membedakan antara \texttt{premise} dan \texttt{hypothesis}-nya. agak berbeda sedikit dengan model \texttt{xlm-roberta-large}, karena model tersebut tidak mengenal konsep \texttt{return\char`_token\char`_type\char`_ids}, maka cara untuk membedakan antara \texttt{premise} dan \texttt{hypothesis}-nya dengan menggunakan fungsi \texttt{index} bawaan Python dengan mencari ID = 2 (\texttt{</s>}) pada \texttt{input\char`_ids} sebagai pemisahnnya. 

Kemudian, parameter \texttt{return\char`_overflowing\char`_tokens} berfungsi untuk mendapatkan token-token yang berlebihan dari \texttt{MAX LENGTH} yang telah ditentukan (\emph{overflowing}), lalu, parameter \texttt{return\char`_offsets\char`_mapping} berfungsi untuk mengembalikan index (dalam level \emph{char}) dari suatu ID pada \texttt{input\char`_ids}, kemudian, parameter \texttt{padding} berfungsi untuk melakukan "pengisian" (\emph{pad}) untuk menyesuaikan panjang \texttt{input\char`_ids}-nya, dalam konteks \texttt{padding='max\char`_length'}, maka \texttt{padding} dilakukan sampai ID sama panjang dengan \texttt{MAX LENGTH}-nya; terakhir, parameter \texttt{return\char`_tensors} berfungsi untuk mengembalikan keluaran dalam bentuk \emph{tensor} agar mempermudah perubahan ke format \texttt{torch} nantinya. Sederhananya, pada tahap \emph{preprocess} ini, penulis menyuplai \texttt{answer\char`_start\char`_position} dan \texttt{answer\char`_end\char`_position} dengan menggunakan properti \texttt{offset\char`_mapping}, \texttt{overflow\char`_to\char`_sample\char`_mapping}, dan fungsi \texttt{sequence\char`_ids}.

Kemudian, untuk proses tokenisasi penulis menggunakan fungsi \texttt{map} bawaan dari \emph{library} \texttt{datasets}, dengan tambahan parameter \texttt{batched=True} dan \texttt{remove\char`_columns=['context', 'question', 'answer', 'offset\char`_mapping', 'overflow\char`_to\char`_sample\char`_mapping']}. Parameter \texttt{batched} berfungsi untuk memecah (\emph{batch}) \emph{dataset} agar dapat diproses per-\emph{batch} demi efisiensi penggunaan memori dan \texttt{remove\char`_columns} digunakan untuk menghapus kolom yang tidak digunakan dalam proses \emph{training} hal tersebut ditujukan untuk agar \emph{dataset} lebih terfokus kepada hal-hal yang penting saja, seperti \texttt{answer\char`_start\char`_position}, \texttt{answer\char`_end\char`_position} dan data hasil tokenisasi dari \texttt{context} dan   \texttt{question} yang sudah tersimpan di variabel \texttt{input\char`_ids} saja disamping untuk efisiensi penggunaan memori.

Terakhir, penulis mengubah format kolom \texttt{input\char`_ids} dan \texttt{token\char`_type\char`_ids} keluaran dari tokenisasi dengan fungsi \texttt{set\char`_format} agar hasil tokenisasi berformat \texttt{torch}; format \texttt{torch} digunakan untuk menyuplai variabel ke \texttt{device} GPU yang penulis gunakan, setelah itu, penulis memecah hasil tokenisasi tersebut ke tiga \emph{dataset}, yaitu: \emph{dataset train}, \emph{dataset validation}, dan \emph{dataset test}; yang disimpan dalam bentuk \texttt{DatasetDict}.

%-----------------------------------------------------------------------------%
\subsection{Mengimpor Model \emph{Question Answering}}
%-----------------------------------------------------------------------------%
Pada tahapan ini, penulis menyuplai \texttt{pretrained\char`_model\char`_name\char`_or\char`_path} sesuai dengan parameter yang telah dipilih via \texttt{argparse} sebelumnya dan penulis menyuplai banyak label sebanyak 2, karena pada \emph{question answering task} membutuhkan dua label, yaitu: \texttt{answer\char`_start\char`_position} dan \texttt{answer\char`_end\char`_position}. Hal tersebut digunakan agar hasil dari klasifier akhir model yang telah dipilih menghasilkan dua \emph{unit} saja sesuai dengan kebutuhan \emph{task} yang sedang dilakukan, yaitu: \emph{question answering task}. Pendefinisian model \emph{question answering} ini menggunakan modul \texttt{AutoModelForQuestionAnswering}. Terakhir, penulis juga memindahkan model yang sudah dibuat tersebut ke \texttt{device} GPU yang penulis pilih dengan fungsi \texttt{.to(device)}.

%-----------------------------------------------------------------------------%
\subsection{Proses Pemberian Bobot Dari Model \emph{Sequence Classification Task}}
%-----------------------------------------------------------------------------%

\begin{lstlisting}[language=Python, caption=Proses pemberian bobot dari model \emph{sequence classification task}]
model_qa = AutoModelForQuestionAnswering.from_pretrained(MODEL_QA_NAME, num_labels=2)

id2label = {0: 'entailment', 1: 'neutral', 2: 'contradiction'}
label2id = {'entailment': 0, 'neutral': 1, 'contradiction': 2}

model_sc = AutoModelForSequenceClassification.from_pretrained(
    MODEL_SC_NAME, num_labels=3, 
    id2label=id2label, label2id=label2id)

filtered_dict = {k: v for k, v in model_sc.state_dict().items() \
    if k in model_qa.state_dict()}

model_qa.state_dict().update(filtered_dict)
model_qa.load_state_dict(model_qa.state_dict())
\end{lstlisting}

Pada tahap ini, akan dilakukan \emph{transfer learning} dengan cara mengambil model \emph{sequence classification task} sebelumnya dengan cara yang sama persis dengan proses mengimpor model \emph{sequence classification} pada sub-bab \emph{training} \emph{sequence classification task}; dan melakukan \emph{update} \texttt{state dict} model \emph{question answering task} dengan \texttt{state dict} model \emph{sequence classification task}. \texttt{State dict} merupakan bobot (dalam bentuk \emph{tensor}) hasil \emph{training} pada setiap \emph{layer}-nya. Kemudian, untuk model \emph{sequence classification task} yang dipilih adalah model yang menghasilkan skor F1 terbaik pada \emph{sequence classification task}-nya, yaitu pada model \href{https://huggingface.co/muhammadravi251001/fine-tuned-IndoNLI-Augmented-with-xlm-roberta-large-LR-1e-05}{XLM-RoBERTa dengan \emph{dataset} \emph{augmented} IndoNLI}.

%-----------------------------------------------------------------------------%
\subsection{Proses \emph{Freezing Layer} (Opsional)}
%-----------------------------------------------------------------------------%

\begin{lstlisting}[language=Python, caption=Proses \emph{freezing layer} (opsional)]
if FREEZE == True:
    for name, param in model_qa.named_parameters():
        if 'qa_outputs' not in name:
            param._trainable = False
\end{lstlisting}

Pada tahap ini, akan dijalankan proses \emph{freezing layer} sesuai nilai yang disuplai pada pengambilan parameter sebelumnya. Sederhananya, kita dapat melakukan \emph{freezing layer} dengan "mematikan" properti \texttt{trainable} dengan mengubahnya menjadi \texttt{False}. Setiap \emph{layer} memiliki namanya yang masing-masing unik, dan untuk \emph{layer} \emph{classifier} memiliki nama: \texttt{qa\char`_outputs}, jadi dengan menjalankan kode di atas, kita hanya akan "mematikan" properti \texttt{trainable} pada semua \emph{layer} kecuali \emph{layer} \emph{classifier}-nya (ada di \emph{layer} terakhir), yaitu: \emph{layer} \texttt{qa\char`_outputs}.

%-----------------------------------------------------------------------------%
\subsection{Perancangan Metrik Komputasi Untuk Penilaian \emph{Intermediate-Task Transfer Learning Question Answering Task}}
%-----------------------------------------------------------------------------%
Pada perancangan metrik komputasi \emph{question answering task}, penulis melakukan kalkulasi skor \emph{exact match} dan skor F1 secara manual, tanpa menggunakan \emph{library} apapun, termasuk \emph{library} \texttt{evaluate}. Perhitungan metrik skor \emph{exact match} dan skor F1 dilakukan secara bersamaan. Perhitungan skor \emph{exact match} hanya dengan melakukan perbandingan antara jawaban prediksi dengan jawaban \emph{golden truth} dalam bentuk \emph{string}, jika sama persis maka skor \emph{exact match} akan ditambah dengan 1. 

Kemudian, perhitungan skor F1 lebih rumit dibandingkan perhitungan skor \emph{exact match}, berikut alurnya: melakukan normalisasi teks (menghapus kata-kata spesifik, menghapus spasi berlebih, menghapus tanda baca, mengganti huruf kapital dengan huruf kecil) jawaban prediksi dan jawaban \emph{golden truth}, lalu, setiap jawaban prediksi dan jawaban \emph{golden truth} akan dipecah menjadi token, pada token tersebutlah akan dihitung nilai \emph{confusion matrix}-nya (\emph{true positive}, \emph{true negative}, \emph{false positive}, dan \emph{false negative}), sehingga mendapatkan skor F1-nya, pada akhirnya, hasil metrik skor \emph{exact match} dan skor F1 akan dirata-ratakan sebagai metrik komputasi akhirnya. Hasil prediksi dari model didapatkan dari hasil fungsi \texttt{np.argmax} terhadap properti \texttt{predictions} dengan parameter \texttt{axis=2}; dan \emph{golden truth} didapatkan dari properti \texttt{label\char`_ids}. 

%-----------------------------------------------------------------------------%
\subsection{Perancangan Penamaan Eksperimen \emph{Intermediate-Task Transfer Learning Question Answering Task}}
%-----------------------------------------------------------------------------%
Pada tahap ini, penulis merancang penamaan eksperimen agar dapat melakukan evaluasi \& analisis terkait eksperimen dengan lebih mudah, rapih, dan teratur. Pada penamaan eksperimen \emph{question answering task} ini, penulis memastikan untuk memberikan nama yang memenuhi berisi: nama model, nama \emph{dataset} yang digunakan, jumlah \emph{learn rate}. Penamaan tersebut berguna untuk melakukan penyimpanan eksperimen ke lokal dan saat \emph{push} ke repositori Hugging Face. 

Untuk pengarsipan eksperimen ke lokal, penulis memasukan ke dalam satu folder besar yang didalamnya berisi empat folder-folder kecil; nama folder besar tersebut merupakan gabungan dari \emph{prefix} \texttt{DatasetQAS}, nama \emph{dataset} yang digunakan, nama model, jumlah \emph{learn rate}, dan juga waktu saat mulai menjalankan \emph{training}. Kemudian, folder-folder kecilnya terdiri dari folder \emph{checkpoint}, \emph{model}, \emph{output}, \emph{metric result}. Dimana, folder \emph{checkpoint} digunakan untuk menyimpan \emph{checkpoint} saat \emph{training} \emph{question answering task}; kemudian, folder \emph{model} digunakan untuk menyimpan \emph{model} akhir setelah \emph{training} \emph{question answering task}; lalu, folder \emph{output} digunakan untuk menyimpan \emph{output} akhir hasil dari prediksi model yang sudah dilatih tersebut terhadap data \emph{validation}; terakhir, folder \emph{metric result} berisi terkait perhitungan metrik dari model yang sudah dilatih tersebut terhadap data \emph{test}. 

Untuk nama repositori pada Hugging Face memiliki beberapa syarat penamaan, antara lain: memiliki \emph{prefix} "\emph{fine-tuned} \texttt{DatasetQAS}", nama \emph{dataset} yang digunakan, nama model, dan jumlah \emph{learn rate}, tanpa waktu saat mulai menjalankan \emph{training}, dan juga dibatasi hingga 96 karakter saja mengikuti aturan penamaan repositori dari Hugging Face. Karena bagian ini merupakan \emph{training question answering intermediate-task transfer learning}, maka ada nama tambahan yang disimpan di lokal maupun pada repositori Hugging Face, yaitu: \emph{with-ITTL} dan apabila parameter \emph{With Freezing Layer} diatur sebagai \texttt{True}, maka ada tambahan nama: \emph{with-freeze}; sebaliknya, apabila parameter \emph{With Freezing Layer} diatur sebagai \texttt{False}, maka ada tambahan nama: \emph{without-freeze}.

%-----------------------------------------------------------------------------%
\subsection{Perancangan Argumen Latih (\emph{Training Arguments})}
%-----------------------------------------------------------------------------%
Pada tahap ini, penulis merancang \emph{training arguments} dengan modul \texttt{TrainingArguments} agar jalannya eksperimen sesuai parameter yang telah dipilih sebelumnya, seperti: jumlah \emph{epoch}, jumlah \emph{learn rate}, jumlah \emph{seed}, jumlah \emph{batch size}, jumlah \emph{gradient accumulation}, \emph{token}; dan juga \emph{hyperparameter} permanen, seperti:  \texttt{LOGGING STEPS}, \texttt{WEIGHT DECAY}, \texttt{WARMUP RATIO}. 

\texttt{STEP} disesuaikan dengan rumus: \texttt{BATCH SIZE $\times$ GRADIENT ACCUMULATION $\times$ EVAL STEPS RATIO} ditujukan agar model melakukan evaluasi setiap \texttt{EVAL STEPS RATIO} agar dapat melakukan \emph{early callback} nantinya untuk efisiensi \emph{training}. Pemilihan \emph{best model} dipilih ke metrik skor F1, karena metrik F1 dapat mengatasi permasalahan \emph{label imbalance}.

Pada bagian ini juga dilakukan penyimpanan terkait data (\emph{data-ops}) yang juga disuplai kepada parameter \texttt{TrainingArguments}, seperti: direktori \emph{checkpoint}, \emph{logging platform} yang otomatis diatur ke \texttt{tensorboard}, strategi \emph{logging}, strategi penyimpanan, dan strategi evaluasi yang otomatis diatur ke \texttt{steps}, Kecenderungan penulis untuk menggunakan \texttt{steps} pada bagian ini dikarenakan nantinya penulis akan menggunakan parameter \texttt{load\char`_best\char`_model\char`_at\char`_end} sebagai \texttt{True}, dan dimana strategi penyimpanan dan strategi evaluasi harus diatur ke \texttt{steps} sesuai dengan aturan dari modul \texttt{TrainingArguments}.

Kemudian, pada sisi memori saat melakukan \emph{training}, penulis menyuplai parameter \texttt{dataloader\char`_num\char`_workers=cpu\char`_count()} agar dapat menggunakan subproses (paralelisme) yang digunakan untuk memuat data sesuai dengan banyaknya CPU pada sistem; dan juga penulis menyuplai parameter \texttt{push\char`_to\char`_hub=True} untuk otomatis \emph{push} ke repositori Hugging Face saat menjalankan \emph{training}, sesuai dengan nama repositori yang telah dijelaskan di sub-bab sebelumnya, dan suplai parameter \texttt{load\char`_best\char`_model\char`_at\char`_end=True} agar model yang nanti diambil merupakan hasil model yang terbaik dari sepanjang proses \emph{training}.

%-----------------------------------------------------------------------------%
\subsection{Melakukan \emph{Training} dan Prediksi Jawaban \emph{Intermediate-Task Transfer Learning Question Answering}}
%-----------------------------------------------------------------------------%
Pada tahap ini, dilakukan \emph{training} dengan menggunakan data \emph{train} dan data \emph{validation} sebagai parameter \emph{training}-nya. Penulis juga melakukan \emph{early callback} dengan nilai \emph{patience} sebesar 3, yang artinya model akan berhenti \emph{training} bila tiga hasil evaluasi setelahnya memiliki nilai metrik yang lebih kecil dibanding sebelumnya; hal tersebut dilakukan untuk efisiensi waktu dan \emph{resource} \emph{training}-nya. 

Sehingga, pada tahap ini, penulis menyuplai beberapa parameter pada modul \texttt{Trainer}, antara lain: model yang digunakan, \emph{training arguments} yang sebelumnya sudah didefinisikan, \emph{train\_dataset} yang diatur ke data \emph{train}-nya, \emph{validation\_dataset} yang diatur ke data \emph{validation}-nya, \emph{tokenizer} yang digunakan, \emph{data\_collator} yang digunakan, metrik komputasi yang sebelumnya sudah dirancang, dan \emph{callbacks} dimana diatur ke \emph{early callback} dengan \emph{patience} sebesar 3. Kemudian, terakhir, dilakukan prediksi terhadap data \emph{test}, dengan menggunakan fungsi \texttt{predict}.

%-----------------------------------------------------------------------------%
\subsection{Representasi Prediksi Jawaban Untuk Evaluasi dan Analisis}
%-----------------------------------------------------------------------------%
Pada tahap ini, penulis mengubah \texttt{PredictionOutput} hasil dari prediksi model menjadi sebuah \texttt{DataFrame} yang dapat dibaca secara jelas oleh manusia. Tahapan ini berguna untuk evaluasi dan analisis kedepannya. Pada tahap ini, penulis mengekstrak \texttt{context}, \texttt{question}, \texttt{prediction answer}, \texttt{golden answer} dari \texttt{PredictionOutput} hasil dari prediksi model dan diubah dalam bentuk \texttt{DataFrame}. 

Proses pemisahan antara \texttt{question} dan \texttt{context} menggunakan properti \texttt{token\char`_type\char`_ids}, dimana bila \texttt{token\char`_type\char`_ids} bernilai 0, maka \texttt{input\char`_ids} yang bersangkutan merupakan sebuah bagian dari \texttt{question}, sebaliknya bila \texttt{token\char`_type\char`_ids} bernilai 1, maka \texttt{input\char`_ids} yang bersangkutan merupakan sebuah bagian dari \texttt{question}; hal tersebut sesuai dengan urutan \emph{preprocess} dan tokenisasi dimana urutannya \texttt{question} lalu \texttt{question}. Namun agak berbeda sedikit dengan model \texttt{xlm-roberta-large}, karena model tersebut tidak mengenal konsep \texttt{return\char`_token\char`_type\char`_ids}, maka cara untuk membedakan antara \texttt{question} dan \texttt{context}-nya dengan menggunakan fungsi \texttt{index} bawaan Python dengan mencari ID = 2 (\texttt{</s>}) pada \texttt{input\char`_ids} sebagai pemisahnnya. 

%-----------------------------------------------------------------------------%
\subsection{Melakukan \emph{Push} ke Akun Hugging Face}
%-----------------------------------------------------------------------------%
Pada tahapan ini, sederhananya, penulis hanya melakukan \emph{push} hasil eksperimen, meliputi: model, evaluasi, dan keluaran dari eksperimen ke akun Hugging Face yang telah disuplai \texttt{TOKEN}-nya pada bagian parameter sebelumnya. Proses \emph{push} menggunakan API khusus Hugging Face, yaitu: \texttt{HfApi} dimana pengunggahan dilakukan dengan fungsi \texttt{upload\char`_folder}, kemudian hanya untuk folder \emph{output} dan folder \emph{metric result} saja yang diunggah ke repositori Hugging Face karena hanya folder-folder tersebut saja yang dirasa berguna untuk evaluasi dan analisis kedepannya. Untuk folder \emph{model} sudah otomatis diunggah saat \emph{training} karena penggunaan parameter \texttt{push\char`_to\char`_hub=True} pada pendefinisian \emph{TrainingArguments} sebelumnya.

%-----------------------------------------------------------------------------%
\section{Metode \emph{Task Recasting} Dengan IndoNLI Sebagai Verifikator}
%-----------------------------------------------------------------------------%
Pada sub-bab ini, akan dijelaskan mengenai \emph{training} model pada tugas \emph{question answering task} dalam belajar tiga \emph{dataset} sistem tanya jawab dengan metode \emph{task recasting} dengan IndoNLI sebagai verifikator yang penulis lakukan pada pada penelitian ini. Secara keseluruhan, sub-bab ini cenderung mirip dengan sub-bab \emph{training} \emph{baseline} model \emph{question answering task}, namun ada beberapa perbedaan mendasar diantara kedua sub-bab ini.

%-----------------------------------------------------------------------------%
\subsection{Pengambilan Parameter Untuk Verifikasi \emph{Question Answering Task}}
%-----------------------------------------------------------------------------%
Pengambilan parameter untuk verifikasi \emph{question answering task} menggunakan bantuan \emph{library} dari \texttt{argparse}. Penulis gunakan \texttt{argparse} agar dapat menjalankan eksperimen via \emph{terminal} bukan dengan satu-satu menjalankan via \emph{notebook}. Parameter yang dapat digunakan dalam verifikasi \emph{question answering task} ini meliputi: nama model, nama \emph{dataset}, jumlah iterasi maksimum pencarian jawaban, tipe \emph{filtering}, tipe \emph{smoothing}, tipe variasi, nilai \emph{threshold}, dan token akun Hugging Face agar dapat otomatis \emph{push} ke akun Hugging Face-nya. Untuk pilihan nilai dari masing-masing parameternya, penulis sertakan di tabel bawah ini.

\begin{table}[h!]
\centering
\begin{tabular}{|P{2.0in}|P{4.0in}|}
 \hline
 Parameter & Pilihan Nilai \\ [0.5ex] 
 \hline
 Nama model & \texttt{indobert-base-uncased}, \texttt{indobert-large-p2}, \texttt{xlm-roberta-large} \\ 
 Nama data & SQuAD-ID, TyDI-QA-ID, IDK-MRC \\
 Jumlah iterasi maksimal pencarian & Isi dengan \emph{integer} berapapun \\
 Tipe \texttt{filtering} & \texttt{entailment\char`_only} atau \texttt{entailment\char`_or\char`_neutral} \\
 Tipe perubahan format kalimat & \texttt{[replace\_first, replace\_question\_word, add\_adalah, just\_concat\_answer\_and\_question, rule\_based, machine\_generation\_with\_rule\_based, pure\_machine\_generation, machine\_generation\_with\_translation]} \\
 Variasi & [1, 2, 3] \\
 \emph{Threshold} & Isi dengan \emph{float} berapapun \\
 \emph{Token} & Isi dengan \emph{string} \emph{token} yang tertera pada Hugging Face \\[1ex] 
 \hline
\end{tabular}
\caption{Tabel parameter dan pilihan nilai pada verifikasi \emph{question answering} model \emph{question answer task}. Catatan: Jumlah iterasi maksimal pencarian bisa disebut sebagai \texttt{MSI}, tipe \emph{filtering} bisa disebut sebagai \texttt{Type QAS}, tipe perubahan format kalimat bisa disebut sebagai \texttt{Type Smoothing}.}
\end{table}

%-----------------------------------------------------------------------------%
\subsection{Pemilihan \emph{Hyperparameter} Untuk Verifikasi \emph{Question Answering Task}}
%-----------------------------------------------------------------------------%
Selain dari \emph{hyperparameter} yang dapat diatur pada pengambilan parameter di atas, terdapat beberapa \emph{hyperparameter} permanen untuk penelitian ini, berikut \emph{hyperparameter} yang tidak bisa diubah-ubah via \texttt{argparse}.

\begin{table}[h]
\centering
\begin{tabular}{||c | c||} 
 \hline\hline
 \emph{Hyperparameter} & Nilai \\ [0.5ex] 
 \hline\hline
 MAX LENGTH & 512 \\ 
 STRIDE & 128 \\
 LOGGING STEPS & 50 \\
 WARMUP RATIO & 0.0 \\
 WEIGHT DECAY & 0.0 \\ 
 EVAL STEPS RATIO & 0.5 \\ [1ex] 
 \hline\hline
\end{tabular}
\caption{Tabel \emph{hyperparameter} pada \emph{training question answering} sistem tanya jawab}
\end{table}

%-----------------------------------------------------------------------------%
\subsection{Mengimpor \emph{Dataset} Sistem Tanya Jawab}
%-----------------------------------------------------------------------------%
Pada tahap ini, akan dijalankan pengambilan semua \emph{dataset} sistem tanya jawab yang akan dieksperimenkan dari \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} dan penyamaan format \texttt{DatasetDict}. Tujuan dilakukan hal tersebut agar dapat lebih mempermudah eksperimen kedepannya. Untuk \emph{dataset} SQuAD-ID, penulis hanya mengambil via \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} dengan bantuan modul \texttt{NusantaraConfigHelper()} dengan fungsi \texttt{load\char`_dataset} dengan nama \emph{dataset}-nya adalah: \texttt{squad\char`_id}. 

\emph{Preprocess} yang penulis lakukan untuk \emph{dataset} SQuAD-ID meliputi: melakukan format ulang kolom \emph{context}, \emph{question}, \emph{answer}, \emph{answer\_start}, dan \emph{answer\_end}, dimana  \emph{answer\_start} dan \emph{answer\_end} merupakan bagian dari \emph{dictionary answer}; kemudian, penulis melakukan pemecahan \emph{dataset} menjadi tiga bagian, yaitu: data \emph{train}, data \emph{validation}, dan data \emph{test}. Pembagian tersebut dilakukan secara manual, karena pada \emph{library} \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} tidak menyediakan data \emph{test}. Untuk mencapai perbandingan yang seimbang dengan data \emph{validation} (perbandingan 8:1:1), maka untuk data \emph{train} penulis pecah menjadi dua, menjadi data \emph{train} dan data \emph{validation}, dan data \emph{validation} yang sebelumnya didapatkan dari \emph{library} \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} diubah menjadi data \emph{test}-nya. Pemecahan (\emph{splitting}) tersebut mempertahankan perbandingan 8:1:1 antara data \emph{train}, data \emph{validation}, dan data \emph{test} dan juga tetap mempertahankan persebaran jenis pertanyaan diantara ketiga bagian data tersebut; kemudian, mengubah ketiga bagian data tersebut menjadi format \texttt{Dataset}, sehingga ketiganya bisa digabung dalam format \texttt{DatasetDict}.

Lalu, untuk \emph{dataset} TyDI-QA-ID, penulis hanya mengambil via \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} dengan bantuan modul \texttt{NusantaraConfigHelper()} dengan fungsi \texttt{load\char`_dataset} dengan nama \emph{dataset}-nya adalah: \texttt{tydiqa\char`_id}. \emph{Preprocess} yang penulis lakukan untuk \emph{dataset} TyDI-QA-ID meliputi: membuat kolom \emph{answer\_end} dengan menambahkan nilai dari \emph{answer\_start} dengan panjang \emph{answer}, hal ini bertujuan untuk mempermudah tokenisasi nantinya; lalu, melakukan format ulang kolom \emph{context}, \emph{question}, \emph{answer}, \emph{answer\_start}, dan \emph{answer\_end}, dimana  \emph{answer\_start} dan \emph{answer\_end} merupakan bagian dari \emph{dictionary answer}; kemudian, penulis melakukan pemecahan \emph{dataset} menjadi tiga bagian, yaitu: data \emph{train}, data \emph{validation}, dan data \emph{test}. Pembagian tersebut dilakukan secara otomatis, karena pada \emph{library} \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} telah menyediakan ketiga bagian data tersebut; kemudian, mengubah ketiga bagian data tersebut menjadi format \texttt{Dataset}, sehingga ketiganya bisa digabung dalam format \texttt{DatasetDict}.

Terakhir, untuk \emph{dataset} IDK-MRC, penulis hanya mengambil via \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} dengan bantuan modul \texttt{NusantaraConfigHelper()} dengan fungsi \texttt{load\char`_dataset} dengan nama \emph{dataset}-nya adalah: \texttt{idk\char`_mrc}. \emph{Preprocess} yang penulis lakukan untuk \emph{dataset} IDK-MRC mirip dengan \emph{preprocess} yang dilakukan pada \emph{dataset} TyDI-QA-ID, yaitu meliputi: membuat kolom \emph{answer\_end} dengan menambahkan nilai dari \emph{answer\_start} dengan panjang \emph{answer}, hal ini bertujuan untuk mempermudah tokenisasi nantinya; lalu, melakukan format ulang kolom \emph{context}, \emph{question}, \emph{answer}, \emph{answer\_start}, dan \emph{answer\_end}, dimana  \emph{answer\_start} dan \emph{answer\_end} merupakan bagian dari \emph{dictionary answer}; kemudian, penulis melakukan pemecahan \emph{dataset} menjadi tiga bagian, yaitu: data \emph{train}, data \emph{validation}, dan data \emph{test}. Pembagian tersebut dilakukan secara otomatis, karena pada \emph{library} \href{https://github.com/IndoNLP/nusa-crowd/tree/master/nusacrowd/nusa_datasets/}{\texttt{nusacrowd}} telah menyediakan ketiga bagian data tersebut; kemudian, mengubah ketiga bagian data tersebut menjadi format \texttt{Dataset} sehingga ketiganya bisa digabung dalam format \texttt{DatasetDict}.

%-----------------------------------------------------------------------------%
\subsection{Proses \emph{Preprocess} dan Tokenisasi \emph{Dataset} Sistem Tanya Jawab}
%-----------------------------------------------------------------------------%
Pada tahap ini, akan dijalankan  \emph{preprocess} dan tokenisasi \emph{dataset} sistem tanya jawab. Tokenisasi dijalankan dengan melakukan tokenisasi pada bagian \texttt{question} dan \texttt{context} saja, dengan menggunakan \emph{hyperparameter} yang sebelumnya sudah ditentukan. \emph{Preprocess} dijalankan dengan beberapa parameter tambahan, seperti: \texttt{truncation=True}, \texttt{return\char`_token\char`_type\char`_ids=True}, \texttt{return\char`_overflowing\char`_tokens=True}, \texttt{return\char`_offsets\char`_mapping=True}, \texttt{padding="max\char`_length"}, \texttt{return\char`_tensors='np'}.Parameter \texttt{truncation} berfungsi untuk memotong (\emph{truncate}) karakter sesuai parameter \texttt{MAX LENGTH} yang dijelaskan sebelumnya, lalu parameter \texttt{return\char`_token\char`_type\char`_ids} digunakan untuk mengembalikan \texttt{TOKEN\char`_IDS} yang berguna untuk membedakan antara \texttt{premise} dan \texttt{hypothesis}-nya. agak berbeda sedikit dengan model \texttt{xlm-roberta-large}, karena model tersebut tidak mengenal konsep \texttt{return\char`_token\char`_type\char`_ids}, maka cara untuk membedakan antara \texttt{premise} dan \texttt{hypothesis}-nya dengan menggunakan fungsi \texttt{index} bawaan Python dengan mencari ID = 2 (\texttt{</s>}) pada \texttt{input\char`_ids} sebagai pemisahnnya. 

Kemudian, parameter \texttt{return\char`_overflowing\char`_tokens} berfungsi untuk mendapatkan token-token yang berlebihan dari \texttt{MAX LENGTH} yang telah ditentukan (\emph{overflowing}), lalu, parameter \texttt{return\char`_offsets\char`_mapping} berfungsi untuk mengembalikan index (dalam level \emph{char}) dari suatu ID pada \texttt{input\char`_ids}, kemudian, parameter \texttt{padding} berfungsi untuk melakukan "pengisian" (\emph{pad}) untuk menyesuaikan panjang \texttt{input\char`_ids}-nya, dalam konteks \texttt{padding='max\char`_length'}, maka \texttt{padding} dilakukan sampai ID sama panjang dengan \texttt{MAX LENGTH}-nya; terakhir, parameter \texttt{return\char`_tensors} berfungsi untuk mengembalikan keluaran dalam bentuk \emph{tensor} agar mempermudah perubahan ke format \texttt{torch} nantinya. Sederhananya, pada tahap \emph{preprocess} ini, penulis menyuplai \texttt{answer\char`_start\char`_position} dan \texttt{answer\char`_end\char`_position} dengan menggunakan properti \texttt{offset\char`_mapping}, \texttt{overflow\char`_to\char`_sample\char`_mapping}, dan fungsi \texttt{sequence\char`_ids}.

Kemudian, untuk proses tokenisasi penulis menggunakan fungsi \texttt{map} bawaan dari \emph{library} \texttt{datasets}, dengan tambahan parameter \texttt{batched=True} dan \texttt{remove\char`_columns=['context', 'question', 'answer', 'offset\char`_mapping', 'overflow\char`_to\char`_sample\char`_mapping']}. Parameter \texttt{batched} berfungsi untuk memecah (\emph{batch}) \emph{dataset} agar dapat diproses per-\emph{batch} demi efisiensi penggunaan memori dan \texttt{remove\char`_columns} digunakan untuk menghapus kolom yang tidak digunakan dalam proses \emph{training} hal tersebut ditujukan untuk agar \emph{dataset} lebih terfokus kepada hal-hal yang penting saja, seperti \texttt{answer\char`_start\char`_position}, \texttt{answer\char`_end\char`_position} dan data hasil tokenisasi dari \texttt{context} dan   \texttt{question} yang sudah tersimpan di variabel \texttt{input\char`_ids} saja disamping untuk efisiensi penggunaan memori.

Terakhir, penulis mengubah format kolom \texttt{input\char`_ids} dan \texttt{token\char`_type\char`_ids} keluaran dari tokenisasi dengan fungsi \texttt{set\char`_format} agar hasil tokenisasi berformat \texttt{torch}; format \texttt{torch} digunakan untuk menyuplai variabel ke \texttt{device} GPU yang penulis gunakan, setelah itu, penulis memecah hasil tokenisasi tersebut ke tiga \emph{dataset}, yaitu: \emph{dataset train}, \emph{dataset validation}, dan \emph{dataset test}; yang disimpan dalam bentuk \texttt{DatasetDict}.

%-----------------------------------------------------------------------------%
\subsection{Mengimpor Model \emph{Question Answering}}
%-----------------------------------------------------------------------------%
Pada tahapan ini, penulis menyuplai \texttt{pretrained\char`_model\char`_name\char`_or\char`_path} sesuai dengan parameter yang telah dipilih via \texttt{argparse} sebelumnya dan penulis menyuplai banyak label sebanyak 2, karena pada \emph{question answering task} membutuhkan dua label, yaitu: \texttt{answer\char`_start\char`_position} dan \texttt{answer\char`_end\char`_position}. Hal tersebut digunakan agar hasil dari klasifier akhir model yang telah dipilih menghasilkan dua \emph{unit} saja sesuai dengan kebutuhan \emph{task} yang sedang dilakukan, yaitu: \emph{question answering task}. 

Pendefinisian model \emph{question answering} ini menggunakan modul \texttt{AutoModelForQuestionAnswering}. Terakhir, penulis juga memindahkan model yang sudah dibuat tersebut ke \texttt{device} GPU yang penulis pilih dengan fungsi \texttt{.to(device)}. Parameter \texttt{pretrained\char`_model\char`_name\char`_or\char`_path} diisi dengan model-model yang sudah dilatih pada metode \emph{baseline question answering task} pada metode sebelumnya, karena fokus dari metode verifikasi ini bukan untuk melakukan \emph{training} ulang, namun verifikasi hasil dari model yang sudah dilatih (\emph{training}) sebelumnya.

%-----------------------------------------------------------------------------%
\subsection{Perancangan Metrik Komputasi Untuk Penilaian Verifikasi \emph{Question Answering Task}}
%-----------------------------------------------------------------------------%
Pada perancangan metrik komputasi \emph{question answering task}, penulis melakukan kalkulasi skor \emph{exact match} dan skor F1 secara manual, tanpa menggunakan \emph{library} apapun, termasuk \emph{library} \texttt{evaluate}. Perhitungan metrik skor \emph{exact match} dan skor F1 dilakukan secara bersamaan. Perhitungan skor \emph{exact match} hanya dengan melakukan perbandingan antara jawaban prediksi dengan jawaban \emph{golden truth} dalam bentuk \emph{string}, jika sama persis maka skor \emph{exact match} akan ditambah dengan 1. 

Kemudian, perhitungan skor F1 lebih rumit dibandingkan perhitungan skor \emph{exact match}, berikut alurnya: melakukan normalisasi teks (menghapus kata-kata spesifik, menghapus spasi berlebih, menghapus tanda baca, mengganti huruf kapital dengan huruf kecil) jawaban prediksi dan jawaban \emph{golden truth}, lalu, setiap jawaban prediksi dan jawaban \emph{golden truth} akan dipecah menjadi token, pada token tersebutlah akan dihitung nilai \emph{confusion matrix}-nya (\emph{true positive}, \emph{true negative}, \emph{false positive}, dan \emph{false negative}), sehingga mendapatkan skor F1-nya, pada akhirnya, hasil metrik skor \emph{exact match} dan skor F1 akan dirata-ratakan sebagai metrik komputasi akhirnya. Hasil prediksi dari model didapatkan dari hasil fungsi \texttt{np.argmax} terhadap properti \texttt{predictions} dengan parameter \texttt{axis=2}; dan \emph{golden truth} didapatkan dari properti \texttt{label\char`_ids}. 

%-----------------------------------------------------------------------------%
\subsection{Perancangan Penamaan Eksperimen Verifikasi \emph{Question Answering Task}}
%-----------------------------------------------------------------------------%
Pada tahap ini, penulis merancang penamaan eksperimen agar dapat melakukan evaluasi \& analisis terkait eksperimen dengan lebih mudah, rapih, dan teratur. Pada penamaan eksperimen \emph{question answering task} ini, penulis memastikan untuk memberikan nama yang memenuhi berisi: nama model, nama \emph{dataset} yang digunakan, jumlah iterasi maksimal, tipe \emph{filtering}, tipe perubahan format kalimat, variasi, dan \emph{threshold}. Penamaan tersebut berguna untuk melakukan penyimpanan eksperimen ke lokal dan saat \emph{push} ke repositori Hugging Face. 

Untuk pengarsipan eksperimen ke lokal, penulis memasukan ke dalam satu folder besar yang didalamnya berisi empat folder-folder kecil; nama folder besar tersebut merupakan gabungan dari \emph{prefix} \texttt{FilteringNLI}, nama \emph{dataset} yang digunakan, nama model, jumlah iterasi maksimal, tipe \emph{filtering}, tipe perubahan format kalimat, variasi, dan \emph{threshold}, dan juga waktu saat mulai menjalankan \emph{training}. Kemudian, folder-folder kecilnya terdiri dari folder \emph{checkpoint}, \emph{model}, \emph{output}, \emph{metric result}. Dimana, folder \emph{checkpoint} digunakan untuk menyimpan \emph{checkpoint} saat \emph{training} \emph{question answering task}; kemudian, folder \emph{model} digunakan untuk menyimpan \emph{model} akhir setelah \emph{training} \emph{question answering task}; lalu, folder \emph{output} digunakan untuk menyimpan \emph{output} akhir hasil dari prediksi model yang sudah dilatih tersebut terhadap data \emph{validation}; terakhir, folder \emph{metric result} berisi terkait perhitungan metrik dari model yang sudah dilatih tersebut terhadap data \emph{test}. 

Untuk nama repositori pada Hugging Face memiliki beberapa syarat penamaan, antara lain: memiliki \emph{prefix} "\emph{fine-tuned} \texttt{DatasetQAS}", nama \emph{dataset} yang digunakan, nama model, jumlah iterasi maksimal, tipe \emph{filtering}, tipe perubahan format kalimat, variasi, dan \emph{threshold}, tanpa waktu saat mulai menjalankan \emph{training}, dan juga dibatasi hingga 96 karakter saja mengikuti aturan penamaan repositori dari Hugging Face. Untuk menghindari nama eksperimen yang terlalu panjang pada lokal dan repositori Hugging Face, setiap parameter jumlah iterasi maksimal, tipe \emph{filtering}, tipe perubahan format kalimat, variasi, dan \emph{threshold} diubah menjadi suatu kode tersendiri, seperti, misal: tipe \emph{filtering} \texttt{entailment\char`_only} diubah menjadi \texttt{TQ1}, kemudian, tipe perubahan format kalimat \texttt{rule\char`based} diubah menjadi \texttt{TS5}.

%-----------------------------------------------------------------------------%
\subsection{Perancangan Argumen Latih (\emph{Training Arguments})}
%-----------------------------------------------------------------------------%
Pada tahap ini, penulis merancang \emph{training arguments} dengan modul \texttt{TrainingArguments} agar jalannya eksperimen sesuai dengan \emph{hyperparameter} permanen, seperti: \texttt{LOGGING STEPS}, \texttt{WEIGHT DECAY}, \texttt{WARMUP RATIO}. Pemilihan \emph{best model} dipilih ke metrik skor F1, karena metrik F1 dapat mengatasi permasalahan \emph{label imbalance}.

Pada bagian ini juga dilakukan penyimpanan terkait data (\emph{data-ops}) yang juga disuplai kepada parameter \texttt{TrainingArguments}, seperti: direktori \emph{checkpoint}, \emph{logging platform} yang otomatis diatur ke \texttt{tensorboard}, strategi \emph{logging}, strategi penyimpanan, dan strategi evaluasi yang otomatis diatur ke \texttt{steps}, Kecenderungan penulis untuk menggunakan \texttt{steps} pada bagian ini dikarenakan nantinya penulis akan menggunakan parameter \texttt{load\char`_best\char`_model\char`_at\char`_end} sebagai \texttt{True}, dan dimana strategi penyimpanan dan strategi evaluasi harus diatur ke \texttt{steps} sesuai dengan aturan dari modul \texttt{TrainingArguments}.

Kemudian, pada sisi memori saat melakukan \emph{training}, penulis menyuplai parameter \texttt{dataloader\char`_num\char`_workers=cpu\char`_count()} agar dapat menggunakan subproses (paralelisme) yang digunakan untuk memuat data sesuai dengan banyaknya CPU pada sistem; dan juga penulis menyuplai parameter \texttt{push\char`_to\char`_hub=True} untuk otomatis \emph{push} ke repositori Hugging Face saat menjalankan \emph{training}, sesuai dengan nama repositori yang telah dijelaskan di sub-bab sebelumnya, dan suplai parameter \texttt{load\char`_best\char`_model\char`_at\char`_end=True} agar model yang nanti diambil merupakan hasil model yang terbaik dari sepanjang proses \emph{training}.

Sederhananya, pada tahap ini pendefinisian argumen latih tidak sekompleks \texttt{TrainingArguments} metode sebelumnya, karena fokus dari metode verifikasi ini bukan untuk melakukan \emph{training} ulang, namun verifikasi hasil dari model yang sudah dilatih (\emph{training}) sebelumnya, seperti yang telah dijelaskan pada bagian sebelumnya.

%-----------------------------------------------------------------------------%
\subsection{Melakukan Prediksi Jawaban}
%-----------------------------------------------------------------------------%
Pada tahap ini, \emph{training} tidak dilakukan lagi, penulis hanya tinggal mengambil model dari Hugging Face. \texttt{Trainer} hanya dibutuhkan untuk prediksi terhadap data \emph{test} dengan fungsi \texttt{predict}. Namun, model yang diambil tersebut tetap harus berbentuk \texttt{Trainer}, oleh sebab itu, penulis tetap menyuplai model yang digunakan, \emph{training arguments} yang sebelumnya sudah didefinisikan, dan \emph{tokenizer} yang digunakan.

%-----------------------------------------------------------------------------%
\subsection{Melakukan \emph{Filtering} Jawaban}
%-----------------------------------------------------------------------------%
Pada tahap ini, penulis melakukan \emph{filtering} jawaban sesuai dengan parameter yang sebelumnya telah diberikan. \emph{Filtering} dilakukan pada \texttt{PredictionOutput} hasil dari prediksi model menjadi sebuah \texttt{DataFrame}. Kemudian, dalam bentuk \texttt{DataFrame}, dilakukan \emph{filtering} dengan beberapa parameter ini: 

\begin{itemize}
    \item Jumlah iterasi maksimum: berapa kali akan dilakukan iterasi pencarian kemungkinan pilihan jawaban terbesar bila jawaban tidak sesuai dengan label yang dipilih pada tipe \emph{filtering}.
    
    \item Tipe \emph{filtering}:
    \begin{itemize}
        \item Bila \texttt{entailment\char`_only} dipilih, maka prediksi jawaban hanya akan diterima dan dijadikan prediksi jawaban akhir bila label NLI-nya merupakan label \texttt{entailment}; dan akan melakukan iterasi pencarian kemungkinan pilihan jawaban terbesar bila mendapatkan label \texttt{contradiction} atau label \texttt{neutral}.
        
        \item Bila \texttt{entailment\char`_or\char`_neutral} dipilih, maka prediksi jawaban hanya akan diterima dan dijadikan prediksi jawaban akhir bila label NLI-nya merupakan label \texttt{entailment} atau label \texttt{neutral}; dan akan melakukan iterasi pencarian kemungkinan pilihan jawaban terbesar bila mendapatkan label \texttt{contradiction}. 
    \end{itemize}
    
    \item Tipe perubahan format kalimat:
    \begin{itemize}
        \item Bila memilih \texttt{replace\_first}, maka pasangan kalimat \texttt{question-answer} dan \texttt{context} akan diubah menjadi pasangan kalimat \texttt{premise-hypothesis} dengan mengubah \textbf{kata terdepan} dari \texttt{question} dengan \texttt{answer} dan menghapus tanda tanya sebagai \texttt{hypothesis}; dan \texttt{context} diubah menjadi \texttt{premise}.
        
        \item Bila memilih \texttt{replace\_question\_word}, maka pasangan kalimat \texttt{question-answer} dan \texttt{context} akan diubah menjadi pasangan kalimat \texttt{premise-hypothesis} dengan mengubah \textbf{kata tanya} dari \texttt{question} dengan \texttt{answer} dan menghapus tanda tanya sebagai \texttt{hypothesis}; dan \texttt{context} diubah menjadi \texttt{premise}.
        
        \item  Bila memilih \texttt{add\_adalah}, maka pasangan kalimat \texttt{question-answer} dan \texttt{context} akan diubah menjadi pasangan kalimat \texttt{premise-hypothesis} dengan \textbf{menghapus} \textbf{kata terdepan} dari \texttt{question}, menghapus tanda tanya, dan menambahkan \texttt{answer} diakhir \texttt{question} sebagai \texttt{hypothesis}; dan \texttt{context} diubah menjadi \texttt{premise}.
        
        \item Bila memilih \texttt{just\_concat\_answer\_and\_question}, maka pasangan kalimat \texttt{question-answer} dan \texttt{context} akan diubah menjadi pasangan kalimat \texttt{premise-hypothesis} dengan menambahkan \emph{string} \texttt{answer} setelah \texttt{question} sebagai \texttt{hypothesis}; dan \texttt{context} diubah menjadi \texttt{premise}.
        
        \item  Bila memilih \texttt{rule\_based}, maka pasangan kalimat \texttt{question-answer} dan \texttt{context} akan diubah menjadi pasangan kalimat \texttt{premise-hypothesis} dengan menyesuaikan template yang telah penulis rancang manual dengan melihat contoh-contoh data pada ketiga \emph{dataset} sistem tanya jawab yang digunakan untuk setiap tipe pertanyaan, hal tersebut sebagai \texttt{hypothesis}; dan \texttt{context} diubah menjadi \texttt{premise}.
        
        \item Bila memilih \texttt{machine\_generation\_with\_rule\_based}, maka pasangan kalimat \texttt{question-answer} dan \texttt{context} akan diubah menjadi pasangan kalimat \texttt{premise-hypothesis} dengan melakukan tipe perubahan format kalimat \textbf{\texttt{rule\_based}}, lalu dilakukan \emph{paraphrase} menggunakan model \emph{paraphraser} berbahasa Indonesia untuk "menghaluskan" kalimat, hal tersebut sebagai \texttt{hypothesis}; dan \texttt{context} diubah menjadi \texttt{premise}.
        
        \item  Bila memilih \texttt{pure\_machine\_generation}, maka pasangan kalimat \texttt{question-answer} dan \texttt{context} akan diubah menjadi pasangan kalimat \texttt{premise-hypothesis} dengan melakukan tipe perubahan format kalimat \textbf{\texttt{just\_concat\_answer\_and\_question}}, lalu dilakukan \emph{paraphrase} menggunakan model \emph{paraphraser} berbahasa Indonesia untuk "menghaluskan" kalimat agar dapat murni mendapatkan hasil yang lebih murni dari \emph{paraphraser}-nya, hal tersebut sebagai \texttt{hypothesis}; dan \texttt{context} diubah menjadi \texttt{premise}.
        
        \item Bila memilih \texttt{machine\_generation\_with\_translation}, maka pasangan kalimat \texttt{question-answer} dan \texttt{context} akan diubah menjadi pasangan kalimat \texttt{premise-hypothesis} dengan melakukan tipe perubahan format kalimat \textbf{\texttt{rule\_based}}, lalu dilakukan penerjemahan ke bahasa Inggris, kemudian dilakukan \emph{paraphrase} menggunakan model \emph{paraphraser} berbahasa Inggris untuk "menghaluskan" kalimat, terakhir, diterjemahkan lagi ke bahasa Indonesia, hal tersebut dilakukan karena lebih banyak model \emph{paraphraser} berbahasa Inggris yang jauh lebih baik daripada model \emph{paraphraser} berbahasa Indonesia; hal tersebut sebagai \texttt{hypothesis}; dan \texttt{context} diubah menjadi \texttt{premise}.
    \end{itemize}
    
    \item Variasi:
    \begin{itemize}
        \item Bila memilih variasi 1, maka \emph{filtering} akan dibasiskan dengan label dari hasil NLI-nya saja, bila labelnya sudah sesuai tipe \emph{filtering}, maka akan masuk sebagai jawaban prediksi akhir. Bila setelah jumlah iterasi maksimum yang sudah didefinisikan sebelumnya tetap tidak memenuhi label tipe \emph{filtering}, maka akan dijawab kosong, atau dalam kata lain model tidak dapat menjawab pertanyaan tersebut \emph{unanswerable}.
        
        \item Bila memilih variasi 2, maka \emph{filtering} akan dibasiskan dengan dengan label dan skor \emph{probability distribution} dari hasil NLI-nya, bila labelnya sudah sesuai tipe \emph{filtering} dan nilai skornya memenuhi \emph{threshold}, maka akan masuk sebagai jawaban prediksi akhir. Bila setelah jumlah iterasi maksimum yang sudah didefinisikan sebelumnya tetap tidak memenuhi label tipe \emph{filtering} dan nilai skornya masih belum memenuhi \emph{threshold}, maka akan dijawab kosong, atau dalam kata lain model tidak dapat menjawab pertanyaan tersebut \emph{unanswerable}.
        
        \item Bila memilih variasi 3, maka \emph{filtering} akan dibasiskan dengan dengan label dan skor \emph{probability distribution} dari hasil NLI-nya, bila labelnya sudah sesuai tipe \emph{filtering} dan nilai skornya memenuhi \emph{threshold}, maka akan masuk sebagai jawaban prediksi akhir. Bila setelah jumlah iterasi maksimum yang sudah didefinisikan sebelumnya tetap tidak memenuhi label tipe \emph{filtering} dan nilai skornya masih belum memenuhi \emph{threshold}, maka akan dijawab dengan skor \emph{probability distribution} yang terbesar dari iterasi pencarian jawaban yang telah dilakukan, hal ini tidak membuat model verifikasi otomatis menjawab kosong, atau dalam kata lain model masih ada kemungkinan untuk menjawab pertanyaan tersebut \emph{answerable} (bila skor \emph{probability distribution} yang terbesar bukan jawaban kosong). 
    \end{itemize}
    
    \item \emph{Threshold}: berapa batas yang masih ditolerir oleh model verifikasi, untuk menentukan \emph{confidence} yang tepat untuk suatu label yang didapatkan.
\end{itemize}

%-----------------------------------------------------------------------------%
\subsection{Representasi Prediksi Jawaban Untuk Evaluasi dan Analisis}
%-----------------------------------------------------------------------------%
Pada tahap ini, penulis mengekstrak \texttt{context}, \texttt{question}, \texttt{prediction answer}, \texttt{golden answer} dari \texttt{PredictionOutput} hasil dari prediksi model dan diubah dalam bentuk \texttt{DataFrame}. Tahapan ini berguna untuk evaluasi dan analisis kedepannya. Proses pemisahan antara \texttt{question} dan \texttt{context} menggunakan properti \texttt{token\char`_type\char`_ids}, dimana bila \texttt{token\char`_type\char`_ids} bernilai 0, maka \texttt{input\char`_ids} yang bersangkutan merupakan sebuah bagian dari \texttt{question}, sebaliknya bila \texttt{token\char`_type\char`_ids} bernilai 1, maka \texttt{input\char`_ids} yang bersangkutan merupakan sebuah bagian dari \texttt{question}; hal tersebut sesuai dengan urutan \emph{preprocess} dan tokenisasi dimana urutannya \texttt{question} lalu \texttt{question}. Namun agak berbeda sedikit dengan model \texttt{xlm-roberta-large}, karena model tersebut tidak mengenal konsep \texttt{return\char`_token\char`_type\char`_ids}, maka cara untuk membedakan antara \texttt{question} dan \texttt{context}-nya dengan menggunakan fungsi \texttt{index} bawaan Python dengan mencari ID = 2 (\texttt{</s>}) pada \texttt{input\char`_ids} sebagai pemisahnnya. 

%-----------------------------------------------------------------------------%
\subsection{Melakukan \emph{Push} ke Akun Hugging Face}
%-----------------------------------------------------------------------------%
Pada tahapan ini, sederhananya, penulis hanya melakukan \emph{push} hasil eksperimen, meliputi: model, evaluasi, dan keluaran dari eksperimen ke akun Hugging Face yang telah disuplai \texttt{TOKEN}-nya pada bagian parameter sebelumnya. Proses \emph{push} menggunakan API khusus Hugging Face, yaitu: \texttt{HfApi} dimana pengunggahan dilakukan dengan fungsi \texttt{upload\char`_folder}, kemudian hanya untuk folder \emph{output} dan folder \emph{metric result} saja yang diunggah ke repositori Hugging Face karena hanya folder-folder tersebut saja yang dirasa berguna untuk evaluasi dan analisis kedepannya. Penulis menggunakan \emph{statement} \texttt{try/except} agar dapat membuat repositori bila belum ada repositori yang diinginkan, tidak seperti eksperimen-eksperimen sebelumnya, hal ini harus dilakukan karena kita hanya mengambil model dari Hugging Face, bukan melakukan \emph{training} dari awal dengan parameter \texttt{push\char`_to\char`_hub=True}..