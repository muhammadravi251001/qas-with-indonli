%-----------------------------------------------------------------------------%
\chapter{\babLima}
\label{bab:5}
%-----------------------------------------------------------------------------%
Bab kelima ini menjelaskan tentang hasil dan analisis eksperimen yang penulis lakukan dalam penelitian ini. Sub-bab \ref{5.1} menjelaskan mengenai hasil dan analisis eksplorasi \emph{dataset} sistem tanya jawab yang penulis gunakan. Sub-bab \ref{5.2} menjelaskan mengenai hasil dan analisis eksperimen metode \emph{intermediate-task transfer learning}. Sub-bab \ref{5.3} menjelaskan mengenai hasil dan analisis eksperimen metode \emph{task recasting} dengan IndoNLI sebagai verifikator dengan parameter tipe \emph{filtering}. Sub-bab \ref{5.4} menjelaskan mengenai hasil dan analisis eksperimen metode \emph{task recasting} dengan IndoNLI sebagai verifikator dengan parameter tipe perubahan format kalimat.

%-----------------------------------------------------------------------------%
\section{Hasil Eksplorasi \emph{Dataset]} (EDA)}
\label{5.1}
%-----------------------------------------------------------------------------%
Pada sub-bab ini, akan dijelaskan mengenai hasil dari eksplorasi \emph{dataset} sistem tanya jawab yang penulis lakukan. Eksplorasi \emph{dataset} akan dibagi menjadi tiga bagian besar, yaitu: \emph{overview statistics}, \emph{length-based analysis}, dan \emph{type-based analysis}. Berikut hasil eksplorasi \emph{dataset}-nya.

%-----------------------------------------------------------------------------%
\subsection{Eksplorasi \emph{Dataset} SQuAD-ID}
%-----------------------------------------------------------------------------%

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Overview statistics}}
%-----------------------------------------------------------------------------%
Berikut, tabel ringkasan statistik dari \emph{dataset} SQuAD-ID (Tabel 5.1). Pada tabel, kolom \emph{All} bermakna gabungan dari data \emph{train} dan data \emph{dev}; kemudian, pada baris jumlah jawaban bagian kiri tanda positif itu jawaban yang \emph{answerable} dan bagian kanan tanda positif itu jawaban yang \emph{unanswerable}.

\begin{table}[H]\centering
\begin{tabular}{lrrrr}\toprule
\emph{Overview Statistics} &\emph{Train} &\emph{Dev} &\emph{All} \\
Jumlah artikel &19.033 &1.204 &20.237 \\
Jumlah konteks &130.319 &11.873 &142.192 \\
Jumlah pertanyaan &130.301 &11.871 &142.172 \\
Jumlah jawaban &130.310 + 9 &11.858 + 15 &142.168 + 24 \\
Rerata panjang konteks &107.38 &113.82 &107.92 \\
Rerata panjang pertanyaan &8.7 &8.79 &8.71 \\
Rerata panjang jawaban &2.97 &3.11 &2.98 \\
Ukuran kosakata &226.343 &20.642 &245.497 \\
\bottomrule
\end{tabular}
\caption{Tabel ringkasan statistik dari SQuAD-ID.}
\end{table}

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Length-based analysis}}
%-----------------------------------------------------------------------------%

Berikut, tabel analisis berbasis panjang kata dari \emph{dataset} SQuAD-ID (Tabel 5.2), untuk bagian pertanyaan dan jawaban.

\begin{table}[H]\centering
\begin{tabular}{lrrrrrrr}\toprule
\multirow{2}{*}{Panjang kata} &\multicolumn{3}{c}{Pertanyaan} &\multicolumn{3}{c}{Jawaban} \\\cmidrule{2-7}
&\emph{Train} &\emph{Dev} &\emph{All} &\emph{Train} &\emph{Dev} &\emph{All} \\\midrule
0 &- &- &- &9 &15 &24 \\
1-5 &17.332 &1.499 &18.831 &115.151 &10.277 &125.428 \\
6$-$10 &112.987 &10.374 &123.361 &15.159 &1.581 &16.740 \\
11-15 &0 &0 &0 &0 &0 &0 \\
16-20 &0 &0 &0 &0 &0 &0 \\
$>$20 &0 &0 &0 &0 &0 &0 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis panjang kata dari SQuAD-ID, untuk bagian pertanyaan dan jawaban.}
\end{table}

Kemudian, di bawah ini merupakan tabel analisis berbasis panjang kata dari \emph{dataset} SQuAD-ID (Tabel 5.3), untuk bagian konteks.

\begin{table}[H]\centering
\begin{tabular}{lrrrr}\toprule
\multirow{2}{*}{Panjang} &\multicolumn{3}{c}{Konteks} \\\cmidrule{2-4}
&\emph{Train} &\emph{Dev} &\emph{All} \\\midrule
$\leq100$ &68.521 &5.866 &74.387 \\
101-150 &61.798 &6.007 &67.805 \\
151-200 &0 &0 &0 \\
201-250 &0 &0 &0 \\
251-300 &0 &0 &0 \\
$>$300 &0 &0 &0 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis panjang kata dari SQuAD-ID, untuk bagian konteks.}
\end{table}

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Type-based analysis}}
%-----------------------------------------------------------------------------%
Berikut, tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} SQuAD-ID (Tabel 5.4), untuk bagian \emph{question type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe Pertanyaan &Jumlah \\\midrule
Apa &69.071 \\
Dimana &12.711 \\
Kapan &8.388 \\
Siapa &14.370 \\
Mengapa &2.075 \\
Bagaimana &3.312 \\
Berapa &19.908 \\
Lainnya &12.357 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari SQuAD-ID, untuk bagian \emph{question type}.}
\end{table}

Kemudian, di bawah ini merupakan tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} SQuAD-ID (Tabel 5.5), untuk bagian \emph{answer type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe Jawaban &Jumlah \\\midrule
\emph{Person} &  1.337\\
\emph{NORP} &  294\\
\emph{Facility} &  39\\
\emph{Organization} & 474 \\
\emph{GPE} &  1.066\\
\emph{Location} & 564\\
\emph{Product} &  1.085\\
\emph{Event} &  122\\

\emph{Work of Art} &  64\\
\emph{Law} &  98\\
\emph{Language} &  8\\
\emph{Date} &  819\\
\emph{Time} &  5\\
\emph{Percent} & 113\\
\emph{Money} &  214\\
\emph{Quantity} &  349\\

\emph{Ordinal} &  418\\
\emph{Cardinal} &  627\\
\emph{REG} &  137\\
\emph{Null} &  4.873\\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari SQuAD-ID, untuk bagian \emph{answer type}.}
\end{table}

Terakhir, di bawah ini merupakan tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} SQuAD-ID (Tabel 5.6), untuk bagian \emph{reasoning type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe \emph{Reasoning} &Jumlah \\\midrule
\emph{Word Matching} & 9\\
\emph{Paraphrase} & 17\\
\emph{Single-Sentence Reasoning} & 14\\
\emph{Multi-Sentence Reasoning} & 9\\
\emph{Ambiguous or Insufficient} & 51\\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari SQuAD-ID, untuk bagian \emph{reasoning type}.}
\end{table}

\subsection{Eksplorasi \emph{Dataset} TyDI-QA-ID}
%-----------------------------------------------------------------------------%

%-----------------------------------------------------------------------------%
%-----------------------------------------------------------------------------%
\subsubsection{\emph{Overview statistics}}
%-----------------------------------------------------------------------------%
Berikut, tabel ringkasan statistik dari \emph{dataset} TyDI-QA-ID (Tabel 5.7). Pada tabel, kolom \emph{All} bermakna gabungan dari data \emph{train} dan data \emph{dev}; kemudian, pada baris jumlah jawaban bagian kiri tanda positif itu jawaban yang \emph{answerable} dan bagian kanan tanda positif itu jawaban yang \emph{unanswerable}.

\begin{table}[H]\centering
\begin{tabular}{lrrrr}\toprule
\emph{Overview Statistics} &\emph{Train} &\emph{Dev} &\emph{All} \\
Jumlah artikel &4.844 &564 &5.408 & \\
Jumlah konteks &4.847 &565 &5.412 & \\
Jumlah pertanyaan &4.847 &565 &5.412 & \\
Jumlah jawaban &4.847 + 0 &5.65 + 0 &5.412 + 0 & \\
Rerata panjang konteks &78.73 &5.46 &4.91 & \\
Rerata panjang pertanyaan &78.32 &5.72 &5.31 & \\
Rerata panjang jawaban &78.69 &5.49 &4.95 & \\
Ukuran kosakata &12.201 &1.612 &13.724 & \\
\bottomrule
\end{tabular}
\caption{Tabel ringkasan statistik dari TyDI-QA-ID.}
\end{table}

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Length-based analysis}}
%-----------------------------------------------------------------------------%

Berikut, tabel analisis berbasis panjang kata dari \emph{dataset} TyDI-QA-ID (Tabel 5.8), untuk bagian pertanyaan dan jawaban.

\begin{table}[H]\centering
\begin{tabular}{lrrrrrrr}\toprule
\multirow{2}{*}{Panjang kata} &\multicolumn{3}{c}{Pertanyaan} &\multicolumn{3}{c}{Jawaban} \\\cmidrule{2-7}
&\emph{Train} &\emph{Dev} &\emph{All} &\emph{Train} &\emph{Dev} &\emph{All} \\\midrule
0 &- &- &- & & & \\
1-5 &2.759 &287 &3.046 &3.725 &419 &4.144 \\
6$-$10 &2.088 &278 &2.366 &1.122 &146 &1.268 \\
11-15 &0 &0 &0 &0 &0 &0 \\
16-20 &0 &0 &0 &0 &0 &0 \\
$>$20 &0 &0 &0 &0 &0 &0 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis panjang kata dari TyDI-QA-ID, untuk bagian pertanyaan dan jawaban.}
\end{table}

Kemudian, di bawah ini merupakan tabel analisis berbasis panjang kata dari \emph{dataset} TyDI-QA-ID (Tabel 5.9), untuk bagian konteks.

\begin{table}[H]\centering
\begin{tabular}{lrrrr}\toprule
\multirow{2}{*}{Panjang} &\multicolumn{3}{c}{Konteks} \\\cmidrule{2-4}
&\emph{Train} &\emph{Dev} &\emph{All} \\\midrule
$\leq100$ &3.721 &437 &4.158 \\
101-150 &1.126 &128 &1.254 \\
151-200 &0 &0 &0 \\
201-250 &0 &0 &0 \\
251-300 &0 &0 &0 \\
$>$300 &0 &0 &0 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis panjang kata dari TyDI-QA-ID, untuk bagian konteks.}
\end{table}

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Type-based analysis}}
%-----------------------------------------------------------------------------%
Berikut, tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} TyDI-QA-ID (Tabel 5.10), untuk bagian \emph{question type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe Pertanyaan &Jumlah \\\midrule
Apa &1.781 \\
Dimana &294 \\
Kapan &894 \\
Siapa &355 \\
Mengapa &23 \\
Bagaimana &24 \\
Berapa &900 \\
Lainnya &1.141 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari TyDI-QA-ID, untuk bagian \emph{question type}.}
\end{table}

Kemudian, di bawah ini merupakan tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} TyDI-QA-ID (Tabel 5.11), untuk bagian \emph{answer type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe Jawaban &Jumlah \\\midrule
\emph{Person} &  138\\
\emph{NORP} &  21\\
\emph{Facility} &  5\\
\emph{Organization} &  18\\
\emph{GPE} &  121\\
\emph{Location} & 35\\
\emph{Product} &  52\\
\emph{Event} &  3\\

\emph{Work of Art} &  12\\
\emph{Law} &  1\\
\emph{Language} &  8\\
\emph{Date} &  144\\
\emph{Time} &  0\\
\emph{Percent} & 1\\
\emph{Money} &  10\\
\emph{Quantity} &  79\\

\emph{Ordinal} &  38\\
\emph{Cardinal} &  53\\
\emph{REG} &  22\\
\emph{Null} &  180\\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari TyDI-QA-ID, untuk bagian \emph{answer type}.}
\end{table}

Terakhir, di bawah ini merupakan tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} TyDI-QA-ID (Tabel 5.12), untuk bagian \emph{reasoning type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe \emph{Reasoning} &Jumlah \\\midrule
\emph{Word Matching} & 9\\
\emph{Paraphrase} & 32\\
\emph{Single-Sentence Reasoning} & 17\\
\emph{Multi-Sentence Reasoning} & 22\\
\emph{Ambiguous or Insufficient} & 20\\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari TyDI-QA-ID, untuk bagian \emph{reasoning type}.}
\end{table}

%-----------------------------------------------------------------------------%
\subsection{Eksplorasi \emph{Dataset} IDK-MRC}
%-----------------------------------------------------------------------------%

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Overview statistics}}
%-----------------------------------------------------------------------------%
Berikut, tabel ringkasan statistik dari \emph{dataset} IDK-MRC (Tabel 5.13). Pada tabel, kolom \emph{All} bermakna gabungan dari data \emph{train} dan data \emph{dev}; kemudian, pada baris jumlah jawaban bagian kiri tanda positif itu jawaban yang \emph{answerable} dan bagian kanan tanda positif itu jawaban yang \emph{unanswerable}.

\begin{table}[H]\centering
\begin{tabular}{lrrrr}\toprule
\emph{Overview Statistics} &\emph{Train} &\emph{Dev} &\emph{All} \\
Jumlah artikel &3.528 &348 &3.876 \\
Jumlah konteks &9.332 &764 &10.096 \\
Jumlah pertanyaan &9.327 &763 &10.090 \\
Jumlah jawaban &5.042 + 4.290 &382 + 382 &5.424 + 4.672 \\
Rerata panjang konteks &79.81 &77.66 &79.65 \\
Rerata panjang pertanyaan &5.73 &6.18 &5.77 \\
Rerata panjang jawaban &2.59 &2.88 &2.61 \\
Ukuran kosakata &16.533 &1.474 &17.967 \\
\bottomrule
\end{tabular}
\caption{Tabel ringkasan statistik dari IDK-MRC.}
\end{table}

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Length-based analysis}}
%-----------------------------------------------------------------------------%

Berikut, tabel analisis berbasis panjang kata dari \emph{dataset} TyDI-QA-ID (Tabel 5.14), untuk bagian pertanyaan dan jawaban.

\begin{table}[H]\centering
\begin{tabular}{lrrrrrrr}\toprule
\multirow{2}{*}{Panjang kata} &\multicolumn{3}{c}{Pertanyaan} &\multicolumn{3}{c}{Jawaban} \\\cmidrule{2-7}
&\emph{Train} &\emph{Dev} &\emph{All} &\emph{Train} &\emph{Dev} &\emph{All} \\\midrule
0 &- &- &- &4.290 &382 &4.672 \\
1-5 &4.881 &338 &5.219 &3.882 &273 &4.155 \\
6$-$10 &4.451 &426 &4.877 &1.160 &109 &1.269 \\
11-15 &0 &0 &0 &0 &0 &0 \\
16-20 &0 &0 &0 &0 &0 &0 \\
$>$20 &0 &0 &0 &0 &0 &0 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis panjang kata dari IDK-MRC, untuk bagian pertanyaan dan jawaban.}
\end{table}

Kemudian, di bawah ini merupakan tabel analisis berbasis panjang kata dari \emph{dataset} IDK-MRC (Tabel 5.15), untuk bagian konteks.

\begin{table}[H]\centering
\begin{tabular}{lrrrr}\toprule
\multirow{2}{*}{Panjang} &\multicolumn{3}{c}{Konteks} \\\cmidrule{2-4}
&\emph{Train} &\emph{Dev} &\emph{All} \\\midrule
$\leq100$ &7.079 &589 &7.668 \\
101-150 &2.253 &175 &2.428 \\
151-200 &0 &0 &0 \\
201-250 &0 &0 &0 \\
251-300 &0 &0 &0 \\
$>$300 &0 &0 &0 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis panjang kata dari IDK-MRC, untuk bagian konteks.}
\end{table}

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Type-based analysis}}
%-----------------------------------------------------------------------------%
Berikut, tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} IDK-MRC (Tabel 5.16), untuk bagian \emph{question type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe Pertanyaan &Jumlah \\\midrule
Apa &3.267 \\
Dimana &568 \\
Kapan &1.757 \\
Siapa &958 \\
Mengapa &122 \\
Bagaimana &111 \\
Berapa &1.667 \\
Lainnya &1.646 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari IDK-MRC, untuk bagian \emph{question type}.}
\end{table}

Kemudian, di bawah ini merupakan tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} IDK-MRC (Tabel 5.17), untuk bagian \emph{answer type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe Jawaban &Jumlah \\\midrule
\emph{Person} &  63\\
\emph{NORP} &  9\\
\emph{Facility} &  2\\
\emph{Organization} & 9\\
\emph{GPE} &  60\\
\emph{Location} & 25\\
\emph{Product} &  30\\
\emph{Event} &  10\\

\emph{Work of Art} & 7\\
\emph{Law} &  1\\
\emph{Language} &  2\\
\emph{Date} & 84\\
\emph{Time} &  1\\
\emph{Percent} & 2\\
\emph{Money} &  3\\
\emph{Quantity} &  33\\

\emph{Ordinal} &  10\\
\emph{Cardinal} &  29\\
\emph{REG} &  14\\
\emph{Null} &  512\\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari IDK-MRC, untuk bagian \emph{answer type}.}
\end{table}

Terakhir, di bawah ini merupakan tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} IDK-MRC (Tabel 5.18), untuk bagian \emph{reasoning type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe \emph{Reasoning} &Jumlah \\\midrule
\emph{Word Matching} & 9\\
\emph{Paraphrase} & 10\\
\emph{Single-Sentence Reasoning} & 5\\
\emph{Multi-Sentence Reasoning} & 13\\
\emph{Ambiguous or Insufficient} & 62\\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari IDK-MRC, untuk bagian \emph{reasoning type}.}
\end{table}

%-----------------------------------------------------------------------------%
\subsection{Kesimpulan Eksplorasi \emph{Dataset}}
%-----------------------------------------------------------------------------%
Dari eksplorasi \emph{dataset} yang dilakukan sebelumnya, maka dapat ditarik beberapa pola keunikan, antara lain: \emph{dataset} SQuAD-ID memiliki data terbanyak dibandingkan \emph{dataset} TyDI-QA-ID dan IDK-MRC, lalu, \emph{dataset} IDK-MRC memiliki data jawaban yang \emph{unanswerable} terbanyak dibandingkan \emph{dataset} TyDI-QA-ID dan SQuAD-ID, kemudian, \emph{dataset} SQuAD-ID memiliki persentase tipe pertanyaan apa terbanyak dibandingkan \emph{dataset} TyDI-QA-ID dan IDK-MRC, lalu, \emph{dataset} TyDI-QA-ID memiliki \emph{answer type} \emph{person} terbanyak dibandingkan \emph{dataset} IDK-MRC dan SQuAD-ID, terakhir \emph{dataset} IDK-MRC memiliki tipe \emph{reasoning type} \emph{ambiguous or insufficient} terbanyak dibandingkan \emph{dataset} TyDI-QA-ID dan SQuAD-ID.

%-----------------------------------------------------------------------------%
\section{Hasil dan Analisis Performa Metode \emph{Intermediate-Task Transfer Learning}}
\label{5.2}
%-----------------------------------------------------------------------------%
Pada sub-bab ini, akan dijelaskan mengenai hasil dan analisis eksperimen metode \emph{intermediate-task transfer learning} yang penulis lakukan pada pada penelitian ini. Sebagai catatan, bahwa ITTL yang dimaksud di bab ini adalah singkatan dari \emph{intermediate-task transfer learning} dan ITTL + F merupakan singkatan dari \emph{intermediate-task transfer learning with freezing layer}. Kemudian, arti S-, T-, dan I- adalah singkatan dari SQuAD-ID, TyDI-QA-ID, dan IDK-MRC secara berurutan, hal tersebut dilakukan agar mempersingkat nama kolom pada tabel. Pada tabel di bawah ini, akan dipaparkan skor \emph{exact match} dan skor F1 pada metode \emph{intermediate-task transfer learning}.

\begin{table}[H]\centering
\begin{tabular}{llrrrrrr}
\toprule
         Model &   Metode &  S-EM &  S-F1 &  T-EM &  T-F1 &  I-EM &  I-F1 \\
\midrule
 IndoBERT-base & Baseline & 44.66 & 61.55 & 52.51 & 65.17 & 66.63 & 72.84 \\
 IndoBERT-base &     ITTL & 45.01 & 61.63 & 51.58 & 63.99 & 65.80 & 72.46 \\
 IndoBERT-base & ITTL + F & 45.19 & 61.95 & 51.81 & 64.70 & 67.33 & 73.44 \\
 \hline
IndoBERT-large & Baseline & 43.82 & 61.09 & 55.08 & 68.89 & 53.89 & 60.51 \\
IndoBERT-large &     ITTL & 44.23 & 61.09 & 55.54 & 69.11 & 53.18 & 60.53 \\
IndoBERT-large & ITTL + F & 43.90 & 61.05 & 57.29 & 70.72 & 59.55 & 66.20 \\
\hline
    XLMR-large & Baseline & 49.54 & 66.69 & 66.51 & 78.27 & 77.95 & 84.64 \\
    XLMR-large &     ITTL & 49.94 & 67.20 & 65.11 & 76.40 & 77.95 & 84.23 \\
    XLMR-large & ITTL + F & 50.41 & 67.64 & 66.51 & 77.59 & 78.30 & 85.14 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan skor \emph{exact match} dan skor F1 pada metode \emph{intermediate-task transfer learning}.}
\end{table}

Dapat dilihat pada tabel di atas, pada model \texttt{IndoBERT-base}, dua dari tiga \emph{dataset} yang diuji memperlihatkan naiknya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{intermediate-task transfer learning} maupun \emph{intermediate-task transfer learning with freezing layer}, walaupun kenaikan skor \emph{exact match} dan skor F1 tidak naik secara signifikan; kemudian, hasil skor keseluruhan model ini juga masih kurang baik, dapat dilihat pada skor F1 masih sekitar 61.63 hingga 73.44.

Kemudian, pada model \texttt{IndoBERT-large}, dapat dilihat tren yang lebih baik dari model \texttt{IndoBERT-base}, yaitu: tiga dari tiga \emph{dataset} yang diuji memperlihatkan naiknya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{intermediate-task transfer learning} maupun \emph{intermediate-task transfer learning with freezing layer}, namun dengan kenaikan skor yang cukup tinggi pada \emph{dataset} IDK-MRC, skor naik sekitar 6 poin pada metode \emph{intermediate-task transfer learning with freezing layer}. Model \texttt{IndoBERT-large} tidak secara pasti memiliki skor \emph{exact match} dan skor F1 yang lebih tinggi dibandingkan model \texttt{IndoBERT-base}, walaupun memiliki jumlah parameter yang lebih banyak dibandingkan model \texttt{IndoBERT-large}.

Terakhir, pada model \texttt{xlm-roberta-large}, mengikuti tren pada model \texttt{IndoBERT-large}, yaitu: tiga dari tiga \emph{dataset} yang diuji memperlihatkan naiknya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{intermediate-task transfer learning} maupun \emph{intermediate-task transfer learning with freezing layer}, namun kenaikan skor \emph{exact match} dan skor F1 tidak naik secara signifikan. Walaupun skor tidak naik secara signifikan, namun dapat dilihat pada tabel di atas, skor secara keseluruhan, model \texttt{xlm-roberta-large} memiliki skor \emph{exact match} dan skor F1 yang lebih tinggi dibanding kedua model sebelumnya.

Secara kecenderungan, metode \emph{intermediate-task transfer learning with freezing layer} memiliki skor yang lebih tinggi dibandingkan dengan metode \emph{intermediate-task transfer learning}. Maka, dapat disimpulkan, bahwa model terbaik untuk metode \emph{intermediate-task transfer learning} adalah: model \texttt{xlm-roberta-large} dengan metode \emph{intermediate-task transfer learning with freezing layer}, dengan skor \emph{exact match} dan skor F1 model dan metode tersebut mengungguli semua model dan metode lainnya. Namun, kenaikan paling signifikan terdapat pada model \texttt{IndoBERT-large} dengan metode \emph{intermediate-task transfer learning with freezing layer}, dapat dilihat skor \emph{exact match} naik sekitar 5.66 dan skor F1 naik sekitar 5.69. Hal tersebut membuat model dan metode ini memiliki kenaikan skor paling signifikan di antara model dan metode lainnya.

%-----------------------------------------------------------------------------%
\subsection{\emph{Question Type}}
%-----------------------------------------------------------------------------%
Pada model \texttt{IndoBERT-base}, tipe pertanyaan apa dan dimana naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan tipe pertanyaan siapa, bagaimana, berapa, dan lainnya naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan tipe pertanyaan kenapa selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Kemudian, pada model \texttt{IndoBERT-large}, tipe pertanyaan kapan, siapa, dan berapa naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan tipe pertanyaan apa, dimana, bagaimana, kenapa, dan lainnya naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, tidak ada tipe pertanyaan yang selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan persentase nilai benar pada model ini cukup signifikan, kenaikan tertinggi ada pada metode \emph{intermediate-task transfer learning with freezing layer} pada \emph{dataset} IDK-MRC dengan tipe pertanyaan berapa, persentase nilai benar naik sekitar 9.91\% dibandingkan tanpa menggunakan metode \emph{intermediate-task transfer learning}.

Terakhir, pada model \texttt{xlm-roberta-large}, tipe pertanyaan apa, kapan, dan bagaimana naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan tipe pertanyaan dimana dan siapa naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan tipe pertanyaan berapa selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{intermediate-task transfer learning} berhasil menjawab lebih banyak benarnya pada tipe pertanyaan apa dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk tipe pertanyaan kenapa selalu turun pada model \texttt{IndoBERT-large} dan tipe pertanyaan berapa pada model \texttt{xlm-roberta-large}. Selain tipe pertanyaan di atas, metode \emph{intermediate-task transfer learning} cenderung berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan kenaikannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-large}. 

%-----------------------------------------------------------------------------%
\subsection{Panjang Konteks}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang konteks pada metode \emph{intermediate-task transfer learning}. Catatan: arti dari $\leq$100 adalah panjang konteks di bawah 100, dan arti dari $\leq$150 adalah panjang konteks di antara 101 sampai 150 (101$-$150).

\begin{table}[H]\centering
\begin{tabular}{llrrrrrr}
\toprule
         Model &   Metode &  S-$\leq$100 &  S-$\leq$150 &  T-$\leq$100 &  T-$\leq$150 &  I-$\leq$100 &  I-$\leq$150 \\
\midrule
 IndoBERT-base & Baseline &                  45.03 &                  45.07 &                  57.82 &                  40.89 &                  68.94 &                  62.60 \\
 IndoBERT-base &     ITTL &                  45.54 &                  45.47 &                  57.65 &                  38.29 &                  67.75 &                  62.60 \\
 IndoBERT-base & ITTL + F &                  46.12 &                  45.27 &                  56.80 &                  40.89 &                  69.45 &                  63.74 \\
\hline
IndoBERT-large & Baseline &                  45.40 &                  43.96 &                  60.24 &                  43.98 &                  56.95 &                  47.29 \\
IndoBERT-large &     ITTL &                  45.29 &                  44.60 &                  60.74 &                  43.98 &                  54.75 &                  50.00 \\
IndoBERT-large & ITTL + F &                  45.31 &                  44.10 &                  62.27 &                  46.24 &                  62.71 &                  52.71 \\
\hline
    XLMR-large & Baseline &                  49.83 &                  49.92 &                  69.29 &                  57.14 &                  79.79 &                  71.79 \\
    XLMR-large &     ITTL &                  50.56 &                  50.05 &                  68.08 &                  55.10 &                  79.02 &                  74.87 \\
    XLMR-large & ITTL + F &                  50.09 &                  51.25 &                  70.20 &                  54.08 &                  80.25 &                  72.31 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang konteks pada metode \emph{intermediate-task transfer learning}.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang konteks $\leq100$ dan 101$-$150 naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Kemudian, pada model \texttt{IndoBERT-large}, panjang konteks 101$-$150 naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan panjang konteks $\leq100$ naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, tidak ada panjang konteks yang selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan persentase nilai benar pada model ini cukup signifikan, kenaikan tertinggi ada pada metode \emph{intermediate-task transfer learning with freezing layer} pada \emph{dataset} IDK-MRC dengan panjang konteks 101$-$150, persentase nilai benar naik sekitar 5.42\% dibandingkan tanpa menggunakan metode \emph{intermediate-task transfer learning}.

Kemudian, pada model \texttt{xlm-roberta-large}, panjang konteks $\leq100$ naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan panjang konteks 101$-$150 naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, tidak ada tipe pertanyaan yang selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{intermediate-task transfer learning} tidak berhasil menjawab lebih banyak benarnya pada sebagian panjang konteks dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Namun, metode \emph{intermediate-task transfer learning} cenderung berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan kenaikannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-large}.

%-----------------------------------------------------------------------------%
\subsection{Panjang Pertanyaan}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang pertanyaan pada metode \emph{intermediate-task transfer learning}. Catatan: arti dari $\leq$5 adalah panjang pertanyaan di bawah 5, dan arti dari $\leq$10 adalah panjang pertanyaan di antara 6 sampai 10 (6$-$10).

\begin{table}[H]\centering
\begin{tabular}{llrrrrrr}
\toprule
         Model &   Metode &  S-$\leq$5 &  S-$\leq$10 &  T-$\leq$5 &  T-$\leq$10 &  I-$\leq$5 &  I-$\leq$10 \\
\midrule
 IndoBERT-base & Baseline &                   43.89 &                    45.21 &                   56.70 &                    44.92 &                   64.45 &                    69.15 \\
 IndoBERT-base &     ITTL &                   43.82 &                    45.73 &                   56.88 &                    41.97 &                   64.45 &                    67.61 \\
 IndoBERT-base & ITTL + F &                   43.39 &                    45.90 &                   56.16 &                    43.93 &                   66.75 &                    68.49 \\
\hline
IndoBERT-large & Baseline &                   43.23 &                    44.71 &                   61.05 &                    44.59 &                   58.31 &                    50.33 \\
IndoBERT-large &     ITTL &                   45.13 &                    44.84 &                   59.78 &                    47.87 &                   58.57 &                    48.80 \\
IndoBERT-large & ITTL + F &                   43.02 &                    44.79 &                   61.59 &                    49.51 &                   64.71 &                    55.36 \\
\hline
    XLMR-large & Baseline &                   48.27 &                    50.11 &                   68.94 &                    62.00 &                   77.59 &                    78.28 \\
    XLMR-large &     ITTL &                   48.54 &                    50.55 &                   68.04 &                    59.67 &                   79.06 &                    77.15 \\
    XLMR-large & ITTL + F &                   49.20 &                    50.89 &                   69.84 &                    60.33 &                   77.34 &                    79.41 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang pertanyaan pada metode \emph{intermediate-task transfer learning}.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang pertanyaan $\leq$5 naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Kemudian, pada model \texttt{IndoBERT-large}, panjang pertanyaan $\leq$5 dan 6$-$10 naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji. Kenaikan persentase nilai benar pada model ini cukup signifikan, kenaikan tertinggi ada pada metode \emph{intermediate-task transfer learning with freezing layer} pada \emph{dataset} IDK-MRC dengan panjang pertanyaan $\leq$5, persentase nilai benar naik sekitar 6.40\% dibandingkan tanpa menggunakan metode \emph{intermediate-task transfer learning}.

Kemudian, pada model \texttt{xlm-roberta-large}, panjang pertanyaan $\leq$5 dan 6$-$10 naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{intermediate-task transfer learning} tidak berhasil menjawab lebih banyak benarnya pada sebagian panjang pertanyaan dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Namun, metode \emph{intermediate-task transfer learning} cenderung berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan kenaikannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-large}.

%-----------------------------------------------------------------------------%
\subsection{Panjang Jawaban \emph{Golden Truth}}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang jawaban \emph{golden truth} pada metode \emph{intermediate-task transfer learning}. Catatan: arti dari $\leq$5 adalah panjang jawaban \emph{golden truth} di bawah 5, dan arti dari $\leq$10 adalah panjang jawaban \emph{golden truth} di antara 6 sampai 10 (6$-$10).

\begin{table}[H]\centering
\begin{tabular}{llrrrrrr}
\toprule
         Model &   Metode &  S-$\leq$5 &  S-$\leq$10 &  T-$\leq$5 &  T-$\leq$10 &  I-$\leq$5 &  I-$\leq$10 \\
\midrule
 IndoBERT-base & Baseline &                48.85 &                 22.37 &                57.49 &                 39.92 &                71.51 &                 38.98 \\
 IndoBERT-base &     ITTL &                49.22 &                 23.24 &                56.51 &                 39.09 &                71.10 &                 35.59 \\
 IndoBERT-base & ITTL + F &                49.42 &                 22.72 &                56.03 &                 41.15 &                72.74 &                 36.44 \\
\hline
IndoBERT-large & Baseline &                48.24 &                 22.24 &                60.10 &                 42.80 &                55.48 &                 44.92 \\
IndoBERT-large &     ITTL &                48.58 &                 22.59 &                60.26 &                 43.62 &                55.48 &                 39.83 \\
IndoBERT-large & ITTL + F &                48.23 &                 22.65 &                62.38 &                 44.44 &                61.37 &                 49.15 \\
\hline
    XLMR-large & Baseline &                52.89 &                 28.54 &                70.29 &                 56.28 &                82.15 &                 50.88 \\
    XLMR-large &     ITTL &                53.51 &                 27.60 &                69.33 &                 53.68 &                82.43 &                 50.00 \\
    XLMR-large & ITTL + F &                53.97 &                 27.40 &                70.77 &                 54.98 &                82.97 &                 49.12 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang jawaban \emph{golden truth} pada metode \emph{intermediate-task transfer learning}.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang jawaban \emph{golden truth} $\leq$5 dan 6$-$10 naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Kemudian, pada model \texttt{IndoBERT-large}, panjang jawaban \emph{golden truth} $\leq$5 dan 6$-$10 naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji. Kenaikan persentase nilai benar pada model ini cukup signifikan, kenaikan tertinggi ada pada metode \emph{intermediate-task transfer learning with freezing layer} pada \emph{dataset} IDK-MRC dengan panjang jawaban \emph{golden truth} $\leq$5, persentase nilai benar naik sekitar 5.89\% dibandingkan tanpa menggunakan metode \emph{intermediate-task transfer learning}.

Kemudian, pada model \texttt{xlm-roberta-large}, panjang jawaban \emph{golden truth} $\leq$5 naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji. Sedangkan panjang jawaban \emph{golden truth} 6$-$10 selalu turun pada ketiga \emph{dataset} yang penulis uji. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{intermediate-task transfer learning} tidak berhasil menjawab lebih banyak benarnya pada sebagian panjang jawaban \emph{golden truth} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Namun, metode \emph{intermediate-task transfer learning} cenderung berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan kenaikannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-large}.

%-----------------------------------------------------------------------------%
\subsection{\emph{Answer Type}}
%-----------------------------------------------------------------------------%
Pada model \texttt{IndoBERT-base}, \emph{answer type} \emph{null} naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan \emph{answer type} \emph{facility}, \emph{organization}, \emph{GPE}, \emph{WoA}, dan \emph{date} naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{answer type} \emph{event}, \emph{law}, \emph{language}, \emph{time}, dan \emph{percent} selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Kemudian, pada model \texttt{IndoBERT-large}, \emph{answer type} NORP dan location naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan \emph{answer type} \emph{person}, \emph{GPE}, \emph{product}, \emph{money}, \emph{quantity},\emph{ordinal}, \emph{cardinal}, \emph{REG}, dan \emph{null} naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{answer type} \emph{law} dan \emph{time} selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan persentase nilai benar pada model ini cukup signifikan, kenaikan tertinggi ada pada metode \emph{intermediate-task transfer learning} pada \emph{dataset} TyDI-QA-ID dengan \emph{answer type} \emph{facility}, persentase nilai benar naik sekitar 80\% dibandingkan tanpa menggunakan metode \emph{intermediate-task transfer learning}.

Terakhir, pada model \texttt{xlm-roberta-large}, \emph{answer type} \emph{product}, \emph{date}, dan \emph{cardinal} naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan \emph{answer type} \emph{organization}, \emph{GPE}, \emph{WoA}, \emph{quantity}, \emph{ordinal}, \emph{REG}, dan \emph{null} naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{answer type} \emph{person}, \emph{law}, \emph{language,} \emph{time}, dan \emph{percent} selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{intermediate-task transfer learning} tidak berhasil menjawab lebih banyak benarnya pada sebagian \emph{answer type} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk \emph{answer type} \emph{law} dan \emph{time} mengalami penurunan pada setiap model dan \emph{dataset}. Selain \emph{answer type} di atas, metode \emph{intermediate-task transfer learning} cenderung berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan kenaikannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-large}. 

%-----------------------------------------------------------------------------%
\subsection{\emph{Reasoning Type}}
%-----------------------------------------------------------------------------%
Pada model \texttt{IndoBERT-base}, \emph{reasoning type} PP dan AoI naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} AoI selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Kemudian, pada model \texttt{IndoBERT-large}, \emph{reasoning type} WM, SSR dan AoI naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} PP selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan persentase nilai benar pada model ini cukup signifikan, kenaikan tertinggi ada pada metode \emph{intermediate-task transfer learning with freezing layer} pada \emph{dataset} IDK-MRC dengan \emph{reasoning type} AoI, persentase nilai benar naik sekitar 20\% dibandingkan tanpa menggunakan metode \emph{intermediate-task transfer learning}.

Terakhir, pada model \texttt{xlm-roberta-large}, \emph{reasoning type} PP dan MSR naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} AoI selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{intermediate-task transfer learning} tidak berhasil menjawab lebih banyak benarnya pada sebagian \emph{reasoning type} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk \emph{reasoning type} PP selalu turun pada model \texttt{IndoBERT-large} dan \emph{reasoning type} AoI pada model \texttt{xlm-roberta-large}. Selain tipe pertanyaan di atas, metode \emph{intermediate-task transfer learning} cenderung berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan kenaikannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-large}. 

%-----------------------------------------------------------------------------%
\section{Hasil dan Analisis Performa Metode \emph{Task Recasting} dengan IndoNLI Sebagai Verifikator Dengan Eksperimen Tipe \emph{Filtering}.}
\label{5.3}
%-----------------------------------------------------------------------------%
Pada sub-bab ini, akan dijelaskan mengenai hasil dan analisis eksperimen metode \emph{task recasting} dengan IndoNLI sebagai verifikator dengan eksperimen tipe \emph{filtering} yang penulis lakukan pada pada penelitian ini. Sebagai catatan, arti S-, T-, dan I- adalah singkatan dari SQuAD-ID, TyDI-QA-ID, dan IDK-MRC secara berurutan, hal tersebut dilakukan agar mempersingkat nama kolom pada tabel. Pada tabel di bawah ini, akan dipaparkan skor \emph{exact match} dan skor F1 pada metode \emph{task recasting} sebagai verifikator pada parameter tipe \emph{filtering}.

\begin{table}[H]\centering
\small
\begin{tabular}{llrrrrrr}
\toprule
         Model &                Metode atau Parameter &  S-EM &  S-F1 &  T-EM &  T-F1 &  I-EM &  I-F1 \\
\midrule
 IndoBERT-base &              Baseline & 44.66 & 61.55 & 52.51 & 65.17 & 66.63 & 72.84 \\
 IndoBERT-base &       Entailment Only & 33.48 & 46.51 & 22.29 & 33.04 & 63.21 & 68.70 \\
 IndoBERT-base & Entailment or Neutral & 41.39 & 57.68 & 22.29 & 32.86 & 63.21 & 68.67 \\
\hline
IndoBERT-large &              Baseline & 43.82 & 61.09 & 55.08 & 68.89 & 53.89 & 60.51 \\
IndoBERT-large &       Entailment Only & 33.31 & 46.41 & 50.18 & 62.78 & 55.66 & 62.01 \\
IndoBERT-large & Entailment or Neutral & 41.31 & 57.70 & 51.93 & 65.04 & 53.66 & 59.98 \\
\hline
    XLMR-large &              Baseline & 49.54 & 66.69 & 66.51 & 78.27 & 77.95 & 84.64 \\
    XLMR-large &       Entailment Only & 37.54 & 50.78 & 59.28 & 69.78 & 67.69 & 74.36 \\
    XLMR-large & Entailment or Neutral & 46.36 & 62.70 & 61.38 & 72.19 & 72.52 & 79.19 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan skor \emph{exact match} dan skor F1 pada metode \emph{task recasting} sebagai verifikator pada parameter tipe \emph{filtering}.}
\end{table}

Dapat dilihat pada tabel di atas, pada model \texttt{IndoBERT-base}, seluruh \emph{dataset} yang diuji memperlihatkan turunnya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{task recasting} sebagai verifikator pada parameter \emph{entailment only} maupun \emph{entailment or neutral}, penurunan skor \emph{exact match} dan skor F1 juga turun secara signifikan, dapat dilihat pada skor \emph{exact match} menurun hingga sekitar 30.22\% pada \emph{dataset} TyDI-QA-ID; kemudian, dapat dilihat bahwa, hasil skor keseluruhan model ini juga masih kurang baik, dapat dilihat pada skor F1 masih sekitar 46.51 hingga 68.70.

Kemudian, pada model \texttt{IndoBERT-large}, dapat dilihat tren yang lebih baik dari model \texttt{IndoBERT-base}, yaitu: ada satu dari tiga \emph{dataset} yang diuji memperlihatkan naiknya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{task recasting} sebagai verifikator pada parameter \emph{entailment only} maupun \emph{entailment or neutral}, yaitu pada \emph{dataset} IDK-MRC. Model \texttt{IndoBERT-large} secara kecenderungan memiliki skor \emph{exact match} dan skor F1 yang lebih tinggi dibandingkan model \texttt{IndoBERT-base}, dapat dilihat pada \emph{dataset} TyDI-QA-ID, hasil model \texttt{IndoBERT-large} lebih baik dengan dua parameter yang dipilih dibandingkan dengan model \texttt{IndoBERT-base} dan perubahan skor tersebut juga cenderung tidak terlalu signifikan.

Terakhir, pada model \texttt{xlm-roberta-large}, mengikuti tren pada model \texttt{IndoBERT-base}, yaitu: seluruh \emph{dataset} yang diuji memperlihatkan turunnya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{task recasting} sebagai verifikator pada parameter \emph{entailment only} maupun \emph{entailment or neutral}, penurunan skor \emph{exact match} dan skor F1 juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara kecenderungan, parameter \emph{entailment or neutral} memiliki skor yang lebih tinggi dibandingkan dengan parameter \emph{entailment only}. Maka, dapat disimpulkan, bahwa model terbaik untuk metode \emph{task recasting} sebagai verifikator adalah: model \texttt{xlm-roberta-large} dengan parameter \emph{entailment or neutral}, dengan skor \emph{exact match} dan skor F1 model dan metode tersebut setidaknya lebih baik dibandingkan model dan parameter lainnya. Namun, secara keseluruhan penggunaan metode \emph{task recasting} sebagai verifikator pada semua parameter tipe \emph{filtering}, memberikan penurunan performa dari sistem tanya jawab yang sedang diuji.

%-----------------------------------------------------------------------------%
\subsection{\emph{Question Type}}
%-----------------------------------------------------------------------------%
Pada model \texttt{IndoBERT-base}, tipe pertanyaan bagaimana naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan tipe pertanyaan apa, dimana, kapan, siapa, berapa, dan lainnya selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian tipe pertanyaan lainnya, dimana penurunannya paling banyak sekitar 28.88\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada tipe pertanyaan yang naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, namun, sebaran nilai kenaikan tipe pertanyaan lebih banyak dibandingkan model \emph{IndoBERT-base}, yaitu tipe pertanyaan kapan, bagaimana, kenapa, dan lainnya setidaknya naik pada satu dari tiga \emph{dataset} yang sedang diuji. Tipe pertanyaan apa, dimana, siapa, dan berapa selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, tipe pertanyaan bagaimana naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan tipe pertanyaan apa, dimana, kapan, siapa, berapa, dan lainnya selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} tidak berhasil menjawab lebih banyak benarnya pada semua tipe pertanyaan dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk tipe pertanyaan apa, dimana, siapa, dan berapa selalu turun pada setiap model yang diuji. Selain tipe pertanyaan di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{Panjang Konteks}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang konteks pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Catatan: arti dari $\leq$100 adalah panjang konteks di bawah 100, dan arti dari $\leq$150 adalah panjang konteks di antara 101 sampai 150 (101$-$150).

\begin{table}[H]\centering
\footnotesize
\begin{tabular}{llrrrrrr}
\toprule
         Model &                Metode atau Parameter &  S-$\leq$100 &  S-$\leq$150 &  T-$\leq$100 &  T-$\leq$150 &  I-$\leq$100 &  I-$\leq$150 \\
\midrule
 IndoBERT-base &              Baseline &                  45.03 &                  45.07 &                  57.82 &                  40.89 &                  68.94 &                  62.60 \\
 IndoBERT-base &       Entailment Only &                  34.14 &                  33.06 &                  25.00 &                  16.36 &                  64.51 &                  60.31 \\
 IndoBERT-base & Entailment or Neutral &                  42.22 &                  40.86 &                  25.17 &                  15.99 &                  65.53 &                  58.02 \\
\hline
IndoBERT-large &              Baseline &                  45.40 &                  43.96 &                  60.24 &                  43.98 &                  56.95 &                  47.29 \\
IndoBERT-large &       Entailment Only &                  33.76 &                  33.02 &                  54.31 &                  40.98 &                  61.02 &                  43.41 \\
IndoBERT-large & Entailment or Neutral &                  41.83 &                  40.96 &                  56.01 &                  42.86 &                  58.31 &                  43.02 \\
\hline
    XLMR-large &              Baseline &                  49.83 &                  49.92 &                  69.29 &                  57.14 &                  79.79 &                  71.79 \\
    XLMR-large &       Entailment Only &                  37.64 &                  37.45 &                  60.97 &                  53.57 &                  69.98 &                  60.00 \\
    XLMR-large & Entailment or Neutral &                  46.46 &                  46.25 &                  63.24 &                  55.10 &                  73.97 &                  67.69 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang konteks pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang konteks $\leq100$ dan 101$-$150 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian panjang konteks $\leq100$, dimana penurunannya paling banyak sekitar 32.82\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada panjang konteks yang naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, namun, sebaran nilai kenaikan panjang konteks lebih banyak dibandingkan model \emph{IndoBERT-base}, yaitu panjang konteks  $\leq100$ setidaknya naik pada satu dari tiga \emph{dataset} yang sedang diuji. Panjang konteks  101$-$150 selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, panjang konteks $\leq100$ dan 101$-$150 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} tidak berhasil menjawab lebih banyak benarnya pada semua panjang konteks dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk panjang konteks 101$-$150 selalu turun pada setiap model yang diuji. Selain panjang konteks di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{Panjang Pertanyaan}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang pertanyaan pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Catatan: arti dari $\leq$5 adalah panjang pertanyaan di bawah 5, dan arti dari $\leq$10 adalah panjang pertanyaan di antara 6 sampai 10 (6$-$10).

\begin{table}[H]\centering
\small
\begin{tabular}{llrrrrrr}
\toprule
         Model &                Metode atau Parameter &  S-$\leq$5 &  S-$\leq$10 &  T-$\leq$5 &  T-$\leq$10 &  I-$\leq$5 &  I-$\leq$10 \\
\midrule
 IndoBERT-base &              Baseline &                   43.89 &                    45.21 &                   56.70 &                    44.92 &                   64.45 &                    69.15 \\
 IndoBERT-base &       Entailment Only &                   34.28 &                    33.38 &                   26.99 &                    13.77 &                   61.38 &                    64.77 \\
 IndoBERT-base & Entailment or Neutral &                   41.41 &                    41.39 &                   26.81 &                    14.10 &                   60.87 &                    65.21 \\
\hline
IndoBERT-large &              Baseline &                   43.23 &                    44.71 &                   61.05 &                    44.59 &                   58.31 &                    50.33 \\
IndoBERT-large &       Entailment Only &                   33.57 &                    33.28 &                   55.80 &                    40.00 &                   57.80 &                    53.83 \\
IndoBERT-large & Entailment or Neutral &                   40.62 &                    41.40 &                   58.15 &                    40.66 &                   58.31 &                    49.67 \\
\hline
    XLMR-large &              Baseline &                   48.27 &                    50.11 &                   68.94 &                    62.00 &                   77.59 &                    78.28 \\
    XLMR-large &       Entailment Only &                   37.97 &                    37.48 &                   62.30 &                    53.67 &                   68.23 &                    67.19 \\
    XLMR-large & Entailment or Neutral &                   45.68 &                    46.45 &                   64.63 &                    55.33 &                   74.14 &                    71.04 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang pertanyaan pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang pertanyaan $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian panjang pertanyaan 6$-$10, dimana penurunannya paling banyak sekitar 31.15\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada panjang pertanyaan yang naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, namun, sebaran nilai kenaikan panjang pertanyaan lebih banyak dibandingkan model \emph{IndoBERT-base}, yaitu panjang pertanyaan  6$-$10 setidaknya naik pada satu dari tiga \emph{dataset} yang sedang diuji. Panjang konteks  $\leq$5 selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, panjang pertanyaan $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} tidak berhasil menjawab lebih banyak benarnya pada semua panjang pertanyaan dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk panjang pertanyaan $\leq$5 selalu turun pada setiap model yang diuji. Selain panjang pertanyaan di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{Panjang Jawaban \emph{Golden Truth}}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang jawaban \emph{golden truth} pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Catatan: arti dari $\leq$5 adalah panjang jawaban \emph{golden truth} di bawah 5, dan arti dari $\leq$10 adalah panjang jawaban \emph{golden truth} di antara 6 sampai 10 (6$-$10).

\begin{table}[H]\centering
\small
\begin{tabular}{llrrrrrr}
\toprule
         Model &                Metode atau Parameter &  S-$\leq$5 &  S-$\leq$10 &  T-$\leq$5 &  T-$\leq$10 &  I-$\leq$5 &  I-$\leq$10 \\
\midrule
 IndoBERT-base &              Baseline &                48.85 &                 22.37 &                57.49 &                 39.92 &                71.51 &                 38.98 \\
 IndoBERT-base &       Entailment Only &                36.41 &                 15.98 &                20.68 &                 26.34 &                67.67 &                 35.59 \\
 IndoBERT-base & Entailment or Neutral &                44.80 &                 21.02 &                20.85 &                 25.93 &                67.67 &                 35.59 \\
\hline
IndoBERT-large &              Baseline &                48.24 &                 22.24 &                60.10 &                 42.80 &                55.48 &                 44.92 \\
IndoBERT-large &       Entailment Only &                36.20 &                 15.94 &                53.26 &                 42.39 &                57.53 &                 44.07 \\
IndoBERT-large & Entailment or Neutral &                44.58 &                 21.59 &                55.70 &                 42.39 &                55.21 &                 44.07 \\
\hline
    XLMR-large &              Baseline &                52.89 &                 28.54 &                70.29 &                 56.28 &                82.15 &                 50.88 \\
    XLMR-large &       Entailment Only &                39.89 &                 20.99 &                61.50 &                 53.25 &                70.57 &                 49.12 \\
    XLMR-large & Entailment or Neutral &                49.03 &                 27.46 &                63.90 &                 54.55 &                76.16 &                 49.12 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang jawaban \emph{golden truth} pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang jawaban \emph{golden truth} $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian panjang jawaban \emph{golden truth} $\leq$5, dimana penurunannya paling banyak sekitar 36.81\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada panjang jawaban \emph{golden truth} yang naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, namun, sebaran nilai kenaikan panjang jawaban \emph{golden truth} lebih banyak dibandingkan model \emph{IndoBERT-base}, yaitu panjang jawaban \emph{golden truth}  $\leq$5 setidaknya naik pada satu dari tiga \emph{dataset} yang sedang diuji. Panjang konteks  6$-$10 selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, panjang jawaban \emph{golden truth} $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} tidak berhasil menjawab lebih banyak benarnya pada semua panjang jawaban \emph{golden truth} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk panjang jawaban \emph{golden truth} 6$-$10 selalu turun pada setiap model yang diuji. Selain panjang jawaban \emph{golden truth} di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{\emph{Answer Type}}
%-----------------------------------------------------------------------------%
Pada model \texttt{IndoBERT-base}, tidak ada \emph{answer type} yang naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan \emph{answer type} \emph{organization}, \emph{location}, \emph{WoA}, dan \emph{ordinal} naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{answer type} selain yang disebutkan di atas selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat dilihat pada \emph{dataset} TyDI-QA-ID dengan parameter \emph{entailment only} pada \emph{answer type} \emph{ordinal}, persentase nilai benarnya turun sebesar 51.43\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada \emph{answer type} yang naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan \emph{answer type} \emph{facility}, \emph{organization}, \emph{date}, dan \emph{null} naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{answer type} selain yang disebutkan di atas selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Penurunan persentase nilai benar pada model ini cenderung tidak berubah secara signifikan, namun uniknya kenaikannya dalam kasus \emph{dataset} TyDI-QA-ID pada \emph{answer type} \emph{facility} persentase nilai benarnya naik sekitar 80.0\%.

Terakhir, pada model \texttt{xlm-roberta-large}, semua \emph{answer type} selain yang disebutkan di atas selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Penurunan persentase nilai benar pada model ini cenderung tidak berubah secara signifikan.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} tidak berhasil menjawab lebih banyak benarnya pada sebagian \emph{answer type} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk \emph{answer type} \emph{person}, \emph{norp}, \emph{gpe}, \emph{prod}, \emph{event}, \emph{law}, \emph{lang}, \emph{time}, \emph{percent}, \emph{money}, \emph{quantity}, \emph{cardinal}, dan \emph{reg} mengalami penurunan pada setiap model dan \emph{dataset}. Selain \emph{answer type} di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} cenderung tidak berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-base}. 

%-----------------------------------------------------------------------------%
\subsection{\emph{Reasoning Type}}
%-----------------------------------------------------------------------------%
Pada model \texttt{IndoBERT-base}, tidak ada \emph{reasoning type} yang naik persentase nilai benarnya pada semua \emph{dataset} yang penulis uji, lalu, \emph{reasoning type} SSR berhasil naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} WM, PP, MSR, dan AoI selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat dilihat pada \emph{dataset} TyDI-QA-ID  dengan parameter \emph{entailment only} di bagian \emph{reasoning type} MSR, persentase nilai benarnya turun sebesar 36.36\%.

Kemudian, pada model \texttt{IndoBERT-large}, \emph{reasoning type} PP naik persentase nilai benarnya pada semua \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} WM, SSR, MSR, dan AoI selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Terakhir, pada model \texttt{xlm-roberta-large}, tidak ada \emph{reasoning type} yang naik persentase nilai benarnya pada semua \emph{dataset} yang penulis uji, lalu, \emph{reasoning type} WM berhasil naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} PP, SSR, MSR, dan AoI selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} tidak berhasil menjawab lebih banyak benarnya pada sebagian \emph{reasoning type} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk \emph{reasoning type} MSR dan AoI selalu turun pada setiap model dan \emph{dataset} yang penulis uji. Selain tipe pertanyaan di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} cenderung tidak berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-base}.

%-----------------------------------------------------------------------------%
\section{Hasil dan Analisis Performa Metode \emph{Task Recasting} dengan IndoNLI Sebagai Verifikator Dengan Eksperimen Tipe Perubahan Format Kalimat.}
\label{5.4}
%-----------------------------------------------------------------------------%
Pada sub-bab ini, akan dijelaskan mengenai hasil dan analisis eksperimen metode \emph{task recasting} dengan IndoNLI sebagai verifikator dengan eksperimen tipe perubahan format kalimat yang penulis lakukan pada pada penelitian ini. Sebagai catatan, arti S-, T-, dan I- adalah singkatan dari SQuAD-ID, TyDI-QA-ID, dan IDK-MRC secara berurutan, hal tersebut dilakukan agar mempersingkat nama kolom pada tabel dan RB pada \texttt{Machine Generation With RB} artinya adalah \texttt{Rule Base}. Pada tabel di bawah ini, akan dipaparkan skor \emph{exact match} dan skor F1 pada metode \emph{task recasting} sebagai verifikator pada parameter tipe perubahan format kalimat.

\begin{table}[H]\centering
\scriptsize
\begin{tabular}{llrrrrrr}
\toprule
         Model &                              Metode atau Parameter &  S-EM &  S-F1 &  T-EM &  T-F1 &  I-EM &  I-F1 \\
\midrule
 IndoBERT-base &                            Baseline & 44.66 & 61.55 & 52.51 & 65.17 & 66.63 & 72.84 \\
 IndoBERT-base &                       Replace First & 41.09 & 57.08 & 22.17 & 32.74 & 65.57 & 70.93 \\
 IndoBERT-base &               Replace Question Word & 41.50 & 57.57 & 22.17 & 32.72 & 65.09 & 70.46 \\
 IndoBERT-base &                          Add Adalah & 41.24 & 57.55 & 22.17 & 33.50 & 63.09 & 68.62 \\
 IndoBERT-base &     Just Concat Answer and Question & 39.91 & 55.77 & 21.94 & 33.13 & 65.21 & 70.56 \\
 IndoBERT-base &                           Rule Base & 41.39 & 57.68 & 22.29 & 32.86 & 63.21 & 68.67 \\
 IndoBERT-base &          Machine Generation With RB & 40.44 & 56.31 & 22.05 & 33.68 & 62.26 & 67.98 \\
 IndoBERT-base &             Pure Machine Generation & 39.87 & 55.28 & 22.75 & 34.37 & 64.62 & 70.26 \\
 IndoBERT-base & Machine Generation With Translation & 34.61 & 48.12 & 20.42 & 31.66 & 63.44 & 69.02 \\
\hline
IndoBERT-large &                            Baseline & 43.82 & 61.09 & 55.08 & 68.89 & 53.89 & 60.51 \\
IndoBERT-large &                       Replace First & 41.00 & 57.17 & 52.28 & 65.05 & 51.42 & 57.44 \\
IndoBERT-large &               Replace Question Word & 41.39 & 57.66 & 52.28 & 65.17 & 51.42 & 57.48 \\
IndoBERT-large &                          Add Adalah & 41.14 & 57.59 & 52.51 & 65.71 & 52.59 & 59.21 \\
IndoBERT-large &     Just Concat Answer and Question & 39.78 & 55.81 & 51.81 & 64.84 & 54.48 & 61.07 \\
IndoBERT-large &                           Rule Base & 41.31 & 57.70 & 51.93 & 65.04 & 53.66 & 59.98 \\
IndoBERT-large &          Machine Generation With RB & 40.07 & 56.17 & 52.04 & 66.05 & 44.93 & 51.89 \\
IndoBERT-large &             Pure Machine Generation & 39.77 & 55.62 & 52.74 & 66.31 & 45.87 & 53.02 \\
IndoBERT-large & Machine Generation With Translation & 34.93 & 48.93 & 49.71 & 63.12 & 48.00 & 54.53 \\
\hline
    XLMR-large &                            Baseline & 49.54 & 66.69 & 66.51 & 78.27 & 77.95 & 84.64 \\
    XLMR-large &                       Replace First & 45.88 & 62.12 & 61.96 & 72.51 & 73.70 & 80.45 \\
    XLMR-large &               Replace Question Word & 46.16 & 62.41 & 61.84 & 72.40 & 73.58 & 80.26 \\
    XLMR-large &                          Add Adalah & 46.20 & 62.61 & 62.31 & 73.41 & 70.99 & 77.61 \\
    XLMR-large &     Just Concat Answer and Question & 44.36 & 60.48 & 59.63 & 70.76 & 73.11 & 79.35 \\
    XLMR-large &                           Rule Base & 46.36 & 62.70 & 61.38 & 72.19 & 72.52 & 79.19 \\
    XLMR-large &          Machine Generation With RB & 45.34 & 61.42 & 61.96 & 73.78 & 72.29 & 79.07 \\
    XLMR-large &             Pure Machine Generation & 45.33 & 61.42 & 63.24 & 74.64 & 74.17 & 81.03 \\
    XLMR-large & Machine Generation With Translation & 40.05 & 54.72 & 59.28 & 70.85 & 72.17 & 79.09 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang konteks pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat.}
\end{table}

Dapat dilihat pada tabel di atas, pada model \texttt{IndoBERT-base}, seluruh \emph{dataset} yang diuji memperlihatkan turunnya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{task recasting} sebagai verifikator pada semua parameter tipe perubahan format kalimat, penurunan skor \emph{exact match} dan skor F1 juga turun secara signifikan, dapat dilihat pada skor \emph{exact match} menurun hingga sekitar 30.34\% pada \emph{dataset} TyDI-QA-ID; kemudian, dapat dilihat bahwa, hasil skor keseluruhan model ini juga masih kurang baik, dapat dilihat pada skor F1 masih sekitar 20.42 hingga 70.93.

Kemudian, pada model \texttt{IndoBERT-large}, dapat dilihat tren yang lebih baik dari model \texttt{IndoBERT-base}, yaitu: ada satu dari tiga \emph{dataset} yang diuji memperlihatkan naiknya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{task recasting} sebagai verifikator pada parameter \emph{just concat answer and question}, yaitu pada \emph{dataset} IDK-MRC. Model \texttt{IndoBERT-large} secara kecenderungan memiliki skor \emph{exact match} dan skor F1 yang lebih tinggi dibandingkan model \texttt{IndoBERT-base}, dapat dilihat pada \emph{dataset} TyDI-QA-ID, hasil model \texttt{IndoBERT-large} lebih baik dengan dua parameter yang dipilih dibandingkan dengan model \texttt{IndoBERT-base} dan perubahan skor tersebut juga cenderung tidak terlalu signifikan.

Terakhir, pada model \texttt{xlm-roberta-large}, mengikuti tren pada model \texttt{IndoBERT-base}, yaitu: seluruh \emph{dataset} yang diuji memperlihatkan turunnya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{task recasting} sebagai verifikator pada semua parameter tipe perubahan format kalimat, penurunan skor \emph{exact match} dan skor F1 juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara kecenderungan, parameter \emph{pure machine generation} dan parameter \emph{rule base} memiliki skor yang lebih tinggi dibandingkan dengan parameter lainnya. Maka, dapat disimpulkan, bahwa model terbaik untuk metode \emph{task recasting} sebagai verifikator adalah: model \texttt{xlm-roberta-large} dengan parameter \emph{pure machine generation}, dengan skor \emph{exact match} dan skor F1 model dan metode tersebut setidaknya lebih baik dibandingkan model dan parameter lainnya. Namun, secara keseluruhan penggunaan metode \emph{task recasting} sebagai verifikator pada semua parameter tipe perubahan format kalimat, memberikan penurunan performa dari sistem tanya jawab yang sedang diuji.

%-----------------------------------------------------------------------------%
\subsection{\emph{Question Type}}
%-----------------------------------------------------------------------------%
Pada model \texttt{IndoBERT-base}, tipe pertanyaan bagaimana naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan tipe pertanyaan apa, kapan, siapa, berapa, dan lainnya selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian tipe pertanyaan siapa, dimana penurunannya paling banyak sekitar 50.88\%.

Kemudian, pada model \texttt{IndoBERT-large}, tipe pertanyaan kenapa naik persentase nilai benarnya pada tiga dari tiga \emph{dataset} yang penulis uji, dan tipe pertanyaan bagaimana naik pada dua dari tiga \emph{dataset} yang sedang diuji. Tipe pertanyaan siapa dan berapa selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, tipe pertanyaan bagaimana dan kenapa naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan tipe pertanyaan apa, dimana, kapan, siapa, berapa, dan lainnya selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat tidak berhasil menjawab lebih banyak benarnya pada semua tipe pertanyaan dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk tipe pertanyaan siapa dan berapa selalu turun pada setiap model yang diuji. Selain tipe pertanyaan di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{Panjang Konteks}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang konteks pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Catatan: arti dari $\leq$100 adalah panjang konteks di bawah 100, dan arti dari $\leq$150 adalah panjang konteks di antara 101 sampai 150 (101$-$150).

\begin{table}[H]\centering
\scriptsize
\begin{tabular}{llrrrrrr}
\toprule
         Model &                              Metode atau Parameter &  S-$\leq$100 &  S-$\leq$150 &  T-$\leq$100 &  T-$\leq$150 &  I-$\leq$100 &  I-$\leq$150 \\
\midrule
 IndoBERT-base &                            Baseline &                  45.03 &                  45.07 &                  57.82 &                  40.89 &                  68.94 &                  62.60 \\
 IndoBERT-base &                       Replace First &                  41.92 &                  40.56 &                  25.34 &                  15.24 &                  68.43 &                  59.16 \\
 IndoBERT-base &               Replace Question Word &                  42.17 &                  41.07 &                  25.34 &                  15.24 &                  67.92 &                  58.78 \\
 IndoBERT-base &                          Add Adalah &                  42.37 &                  40.52 &                  25.17 &                  15.61 &                  64.85 &                  59.16 \\
 IndoBERT-base &     Just Concat Answer and Question &                  41.54 &                  38.86 &                  25.00 &                  15.24 &                  68.26 &                  58.40 \\
 IndoBERT-base &                           Rule Base &                  42.22 &                  40.86 &                  25.17 &                  15.99 &                  65.53 &                  58.02 \\
 IndoBERT-base &          Machine Generation With RB &                  41.60 &                  39.69 &                  25.17 &                  15.24 &                  63.99 &                  58.40 \\
 IndoBERT-base &             Pure Machine Generation &                  41.54 &                  38.79 &                  26.19 &                  15.24 &                  66.55 &                  60.31 \\
 IndoBERT-base & Machine Generation With Translation &                  37.29 &                  32.87 &                  24.15 &                  12.27 &                  65.53 &                  58.78 \\
\hline
IndoBERT-large &                            Baseline &                  45.40 &                  43.96 &                  60.24 &                  43.98 &                  56.95 &                  47.29 \\
IndoBERT-large &                       Replace First &                  41.98 &                  40.34 &                  57.36 &                  40.98 &                  56.10 &                  40.70 \\
IndoBERT-large &               Replace Question Word &                  42.08 &                  40.93 &                  57.36 &                  40.98 &                  55.93 &                  41.09 \\
IndoBERT-large &                          Add Adalah &                  41.90 &                  40.64 &                  57.02 &                  42.48 &                  56.95 &                  42.64 \\
IndoBERT-large &     Just Concat Answer and Question &                  40.99 &                  38.98 &                  57.19 &                  39.85 &                  59.49 &                  43.02 \\
IndoBERT-large &                           Rule Base &                  41.83 &                  40.96 &                  56.01 &                  42.86 &                  58.31 &                  43.02 \\
IndoBERT-large &          Machine Generation With RB &                  41.20 &                  39.31 &                  56.68 &                  41.73 &                  47.63 &                  38.76 \\
IndoBERT-large &             Pure Machine Generation &                  41.46 &                  38.65 &                  58.04 &                  40.98 &                  48.81 &                  39.15 \\
IndoBERT-large & Machine Generation With Translation &                  37.39 &                  33.30 &                  55.16 &                  37.59 &                  51.02 &                  41.09 \\
\hline
    XLMR-large &                            Baseline &                  49.83 &                  49.92 &                  69.29 &                  57.14 &                  79.79 &                  71.79 \\
    XLMR-large &                       Replace First &                  45.94 &                  45.82 &                  64.30 &                  54.08 &                  75.34 &                  68.21 \\
    XLMR-large &               Replace Question Word &                  45.90 &                  46.41 &                  64.30 &                  53.57 &                  75.19 &                  68.21 \\
    XLMR-large &                          Add Adalah &                  46.48 &                  45.94 &                  64.90 &                  53.57 &                  72.43 &                  66.15 \\
    XLMR-large &     Just Concat Answer and Question &                  45.15 &                  43.59 &                  62.33 &                  50.51 &                  75.96 &                  63.59 \\
    XLMR-large &                           Rule Base &                  46.46 &                  46.25 &                  63.24 &                  55.10 &                  73.97 &                  67.69 \\
    XLMR-large &          Machine Generation With RB &                  46.07 &                  44.62 &                  65.05 &                  51.53 &                  73.81 &                  67.18 \\
    XLMR-large &             Pure Machine Generation &                  46.02 &                  44.65 &                  66.41 &                  52.55 &                  75.96 &                  68.21 \\
    XLMR-large & Machine Generation With Translation &                  41.02 &                  39.11 &                  62.63 &                  47.96 &                  73.81 &                  66.67 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang konteks pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang konteks $\leq100$ dan 101$-$150 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian panjang konteks $\leq100$, dimana penurunannya paling banyak sekitar 33.67\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada panjang konteks yang naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, namun, sebaran nilai kenaikan panjang konteks lebih banyak dibandingkan model \emph{IndoBERT-base}, yaitu panjang konteks  $\leq100$ setidaknya naik pada satu dari tiga \emph{dataset} yang sedang diuji. Panjang konteks  101$-$150 selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, panjang konteks $\leq100$ dan 101$-$150 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat tidak berhasil menjawab lebih banyak benarnya pada semua panjang konteks dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk panjang konteks 101$-$150 selalu turun pada setiap model yang diuji. Selain panjang konteks di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{Panjang Pertanyaan}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang pertanyaan pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Catatan: arti dari $\leq$5 adalah panjang pertanyaan di bawah 5, dan arti dari $\leq$10 adalah panjang pertanyaan di antara 6 sampai 10 (6$-$10).

\begin{table}[H]\centering
\scriptsize
\begin{tabular}{llrrrrrr}
\toprule
         Model &                Metode atau Parameter &  S-$\leq$5 &  S-$\leq$10 &  T-$\leq$5 &  T-$\leq$10 &  I-$\leq$5 &  I-$\leq$10 \\
\midrule
 IndoBERT-base &                            Baseline &                   43.89 &                    45.21 &                   56.70 &                    44.92 &                   64.45 &                    69.15 \\
 IndoBERT-base &                       Replace First &                   41.48 &                    41.04 &                   26.99 &                    13.44 &                   61.89 &                    68.71 \\
 IndoBERT-base &               Replace Question Word &                   41.41 &                    41.52 &                   26.99 &                    13.44 &                   61.64 &                    68.05 \\
 IndoBERT-base &                          Add Adalah &                   41.70 &                    41.18 &                   26.63 &                    14.10 &                   60.36 &                    65.43 \\
 IndoBERT-base &     Just Concat Answer and Question &                   39.58 &                    39.96 &                   26.63 &                    13.44 &                   62.66 &                    67.40 \\
 IndoBERT-base &                           Rule Base &                   41.41 &                    41.39 &                   26.81 &                    14.10 &                   60.87 &                    65.21 \\
 IndoBERT-base &          Machine Generation With RB &                   39.72 &                    40.54 &                   26.45 &                    14.10 &                   61.64 &                    62.80 \\
 IndoBERT-base &             Pure Machine Generation &                   40.07 &                    39.84 &                   27.72 &                    13.77 &                   62.92 &                    66.08 \\
 IndoBERT-base & Machine Generation With Translation &                   36.61 &                    34.34 &                   24.64 &                    12.79 &                   59.34 &                    66.96 \\
\hline
IndoBERT-large &                            Baseline &                   43.23 &                    44.71 &                   61.05 &                    44.59 &                   58.31 &                    50.33 \\
IndoBERT-large &                       Replace First &                   41.04 &                    40.99 &                   58.70 &                    40.66 &                   57.03 &                    46.61 \\
IndoBERT-large &               Replace Question Word &                   40.97 &                    41.45 &                   58.70 &                    40.66 &                   57.03 &                    46.61 \\
IndoBERT-large &                          Add Adalah &                   40.90 &                    41.17 &                   58.70 &                    41.31 &                   56.52 &                    49.23 \\
IndoBERT-large &     Just Concat Answer and Question &                   39.21 &                    39.86 &                   58.15 &                    40.33 &                   57.80 &                    51.64 \\
IndoBERT-large &                           Rule Base &                   40.62 &                    41.40 &                   58.15 &                    40.66 &                   58.31 &                    49.67 \\
IndoBERT-large &          Machine Generation With RB &                   40.06 &                    40.07 &                   57.97 &                    41.31 &                   52.43 &                    38.51 \\
IndoBERT-large &             Pure Machine Generation &                   39.49 &                    39.81 &                   58.70 &                    41.97 &                   52.43 &                    40.26 \\
IndoBERT-large & Machine Generation With Translation &                   36.81 &                    34.68 &                   54.35 &                    41.31 &                   50.90 &                    45.51 \\
\hline
    XLMR-large &                            Baseline &                   48.27 &                    50.11 &                   68.94 &                    62.00 &                   77.59 &                    78.28 \\
    XLMR-large &                       Replace First &                   45.41 &                    45.95 &                   65.17 &                    56.00 &                   74.38 &                    73.08 \\
    XLMR-large &               Replace Question Word &                   45.08 &                    46.32 &                   65.17 &                    55.67 &                   74.38 &                    72.85 \\
    XLMR-large &                          Add Adalah &                   45.41 &                    46.32 &                   65.89 &                    55.67 &                   72.66 &                    69.46 \\
    XLMR-large &     Just Concat Answer and Question &                   42.95 &                    44.56 &                   62.84 &                    53.67 &                   72.91 &                    73.30 \\
    XLMR-large &                           Rule Base &                   45.68 &                    46.45 &                   64.63 &                    55.33 &                   74.14 &                    71.04 \\
    XLMR-large &          Machine Generation With RB &                   44.68 &                    45.43 &                   65.71 &                    55.00 &                   72.91 &                    71.72 \\
    XLMR-large &             Pure Machine Generation &                   44.48 &                    45.45 &                   66.79 &                    56.67 &                   74.14 &                    74.21 \\
    XLMR-large & Machine Generation With Translation &                   42.29 &                    39.73 &                   60.68 &                    56.67 &                   70.44 &                    73.76 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang pertanyaan pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang pertanyaan $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian panjang pertanyaan $\leq$5, dimana penurunannya paling banyak sekitar 30.06\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada panjang pertanyaan yang naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, namun, sebaran nilai kenaikan panjang pertanyaan lebih banyak dibandingkan model \emph{IndoBERT-base}, yaitu panjang pertanyaan 6$-$10 setidaknya naik pada satu dari tiga \emph{dataset} yang sedang diuji. Panjang konteks  $\leq$5 selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, panjang pertanyaan $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat tidak berhasil menjawab lebih banyak benarnya pada semua panjang pertanyaan dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk panjang pertanyaan $\leq$5 selalu turun pada setiap model yang diuji. Selain panjang pertanyaan di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{Panjang Jawaban \emph{Golden Truth}}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang jawaban \emph{golden truth} pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Catatan: arti dari $\leq$5 adalah panjang jawaban \emph{golden truth} di bawah 5, dan arti dari $\leq$10 adalah panjang jawaban \emph{golden truth} di antara 6 sampai 10 (6$-$10).

\begin{table}[H]\centering
\scriptsize
\begin{tabular}{llrrrrrr}
\toprule
         Model &                Metode atau Parameter &  S-$\leq$5 &  S-$\leq$10 &  T-$\leq$5 &  T-$\leq$10 &  I-$\leq$5 &  I-$\leq$10 \\
\midrule
 IndoBERT-base &                            Baseline &                48.85 &                 22.37 &                57.49 &                 39.92 &                71.51 &                 38.98 \\
 IndoBERT-base &                       Replace First &                44.57 &                 20.26 &                21.01 &                 25.10 &                70.41 &                 35.59 \\
 IndoBERT-base &               Replace Question Word &                45.00 &                 20.55 &                21.01 &                 25.10 &                69.86 &                 35.59 \\
 IndoBERT-base &                          Add Adalah &                44.63 &                 20.96 &                20.68 &                 25.93 &                67.40 &                 36.44 \\
 IndoBERT-base &     Just Concat Answer and Question &                43.19 &                 20.26 &                20.36 &                 25.93 &                69.86 &                 36.44 \\
 IndoBERT-base &                           Rule Base &                44.80 &                 21.02 &                20.85 &                 25.93 &                67.67 &                 35.59 \\
 IndoBERT-base &          Machine Generation With RB &                44.01 &                 19.09 &                21.34 &                 23.87 &                66.30 &                 37.29 \\
 IndoBERT-base &             Pure Machine Generation &                43.44 &                 18.50 &                21.66 &                 25.51 &                69.32 &                 35.59 \\
 IndoBERT-base & Machine Generation With Translation &                37.89 &                 14.93 &                19.06 &                 23.87 &                68.22 &                 33.90 \\
\hline
IndoBERT-large &                            Baseline &                48.24 &                 22.24 &                60.10 &                 42.80 &                55.48 &                 44.92 \\
IndoBERT-large &                       Replace First &                44.33 &                 20.94 &                56.51 &                 41.56 &                52.74 &                 43.22 \\
IndoBERT-large &               Replace Question Word &                44.74 &                 21.24 &                56.51 &                 41.56 &                52.74 &                 43.22 \\
IndoBERT-large &                          Add Adalah &                44.39 &                 21.59 &                56.35 &                 42.80 &                53.84 &                 44.92 \\
IndoBERT-large &     Just Concat Answer and Question &                42.86 &                 21.24 &                55.21 &                 43.21 &                55.89 &                 45.76 \\
IndoBERT-large &                           Rule Base &                44.58 &                 21.59 &                55.70 &                 42.39 &                55.21 &                 44.07 \\
IndoBERT-large &          Machine Generation With RB &                43.47 &                 19.59 &                56.35 &                 41.15 &                45.07 &                 44.07 \\
IndoBERT-large &             Pure Machine Generation &                43.20 &                 19.12 &                57.17 &                 41.56 &                46.30 &                 43.22 \\
IndoBERT-large & Machine Generation With Translation &                38.06 &                 16.12 &                53.91 &                 39.09 &                48.90 &                 42.37 \\
\hline
    XLMR-large &                            Baseline &                52.89 &                 28.54 &                70.29 &                 56.28 &                82.15 &                 50.88 \\
    XLMR-large &                       Replace First &                48.65 &                 26.32 &                65.50 &                 52.38 &                77.66 &                 48.25 \\
    XLMR-large &               Replace Question Word &                48.89 &                 26.86 &                65.34 &                 52.38 &                77.52 &                 48.25 \\
    XLMR-large &                          Add Adalah &                48.86 &                 27.40 &                65.02 &                 54.98 &                74.25 &                 50.00 \\
    XLMR-large &     Just Concat Answer and Question &                46.79 &                 27.13 &                61.50 &                 54.55 &                76.70 &                 50.00 \\
    XLMR-large &                           Rule Base &                49.03 &                 27.46 &                63.90 &                 54.55 &                76.16 &                 49.12 \\
    XLMR-large &          Machine Generation With RB &                48.12 &                 25.64 &                65.97 &                 51.08 &                76.16 &                 47.37 \\
    XLMR-large &             Pure Machine Generation &                48.05 &                 26.05 &                67.25 &                 52.38 &                78.07 &                 49.12 \\
    XLMR-large & Machine Generation With Translation &                42.84 &                 20.31 &                63.10 &                 48.92 &                75.75 &                 49.12 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang jawaban \emph{golden truth} pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat.}
\end{table}

base
NAIK:
STAGNAN:
TURUN: 5, 10

large
NAIK:
STAGNAN: 10 (2)
TURUN: 5

xlmr
NAIK:
STAGNAN:  
TURUN: 5, 10

Pada model \texttt{IndoBERT-base}, panjang jawaban \emph{golden truth} $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian panjang jawaban \emph{golden truth} $\leq$5, dimana penurunannya paling banyak sekitar 38.43\%.

Kemudian, pada model \texttt{IndoBERT-large}, panjang jawaban \emph{golden truth} 6$-$10 naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji. Panjang konteks  6$-$10 selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, panjang jawaban \emph{golden truth} $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat tidak berhasil menjawab lebih banyak benarnya pada semua panjang jawaban \emph{golden truth} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk panjang jawaban \emph{golden truth} $\leq$5 selalu turun pada setiap model yang diuji. Selain panjang jawaban \emph{golden truth} di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{\emph{Answer Type}}
%-----------------------------------------------------------------------------%
Pada model \texttt{IndoBERT-base}, tidak ada \emph{answer type} yang naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan \emph{answer type} \emph{facility}, \emph{organization}, \emph{location}, \emph{WoA}, \emph{ordinal}, dan \emph{cardinal} naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{answer type} selain yang disebutkan di atas selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat dilihat pada \emph{dataset} TyDI-QA-ID dengan parameter \emph{replace first} pada \emph{answer type} \emph{language}, persentase nilai benarnya turun sebesar 66.67\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada \emph{answer type} yang naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, namun \emph{answer type} \emph{date} naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang diuji, sedangkan \emph{answer type} \emph{facility}, \emph{organization}, \emph{event}, \emph{language}, \emph{date}, \emph{cardinal}, \emph{reg}, dan \emph{null} naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{answer type} selain yang disebutkan di atas selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Penurunan persentase nilai benar pada model ini cenderung tidak berubah secara signifikan.

Terakhir, pada model \texttt{xlm-roberta-large}, \emph{answer type} \emph{woa} naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang diuji, sedangkan semua \emph{answer type} selain yang disebutkan di atas selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Penurunan persentase nilai benar pada model ini cenderung tidak berubah secara signifikan, kecuali pada beberapa kasus khusus, seperti pada \emph{dataset} IDK-MRC bagian \emph{answer type} {language}, persentase nilai benarnya turun sebesar 50\%.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat tidak berhasil menjawab lebih banyak benarnya pada sebagian \emph{answer type} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk \emph{answer type} \emph{person}, \emph{norp}, \emph{gpe}, \emph{product}, \emph{time}, \emph{percent}, \emph{money}, dan \emph{quantity} mengalami penurunan pada setiap model dan \emph{dataset}. Selain \emph{answer type} di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat cenderung tidak berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-base}. 

%-----------------------------------------------------------------------------%
\subsection{\emph{Reasoning Type}}
%-----------------------------------------------------------------------------%
Pada model \texttt{IndoBERT-base}, tidak ada \emph{reasoning type} yang naik persentase nilai benarnya pada semua \emph{dataset} yang penulis uji, lalu, \emph{reasoning type} SSR dan AoI berhasil naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} WM, PP, dan MSR selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat dilihat pada \emph{dataset} TyDI-QA-ID  dengan parameter \emph{machine generation with translation} di bagian \emph{reasoning type} MSR, persentase nilai benarnya turun sebesar 40.91\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada \emph{reasoning type} yang naik persentase nilai benarnya pada semua \emph{dataset} yang penulis uji, lalu, \emph{reasoning type} WM dan MSR berhasil naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} PP, SSR, dan AoI selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Terakhir, pada model \texttt{xlm-roberta-large}, tidak ada \emph{reasoning type} yang naik persentase nilai benarnya pada semua \emph{dataset} yang penulis uji, lalu, \emph{reasoning type} WM, PP, dan MSR berhasil naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} SSR dan AoI selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat tidak berhasil menjawab lebih banyak benarnya pada sebagian \emph{reasoning type} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, tidak ada juga \emph{reasoning type} yang selalu turun pada setiap model dan \emph{dataset} yang penulis uji. Selain tipe pertanyaan di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat cenderung tidak berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-base}.