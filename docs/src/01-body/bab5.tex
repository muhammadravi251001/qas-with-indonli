%-----------------------------------------------------------------------------%
\chapter{\babLima}
\label{bab:5}
%-----------------------------------------------------------------------------%
Bab kelima ini menjelaskan tentang hasil dan analisis eksperimen yang penulis lakukan dalam penelitian ini. Sub-bab \ref{5.1} menjelaskan mengenai hasil dan analisis eksplorasi \emph{dataset} sistem tanya jawab yang penulis gunakan. Sub-bab \ref{5.2} menjelaskan mengenai hasil dari \emph{training sequence classification task}. Sub-bab \ref{5.3} menjelaskan mengenai hasil dan analisis eksperimen metode \emph{intermediate-task transfer learning}. Sub-bab \ref{5.4} menjelaskan mengenai hasil dan analisis eksperimen metode \emph{task recasting} dengan IndoNLI sebagai verifikator dengan parameter tipe \emph{filtering}. Sub-bab \ref{5.5} menjelaskan mengenai hasil dan analisis eksperimen metode \emph{task recasting} dengan IndoNLI sebagai verifikator dengan parameter tipe perubahan format kalimat.

%-----------------------------------------------------------------------------%
\section{Hasil Eksplorasi \emph{Dataset} (EDA)}
\label{5.1}
%-----------------------------------------------------------------------------%
Pada sub-bab ini, akan dijelaskan mengenai hasil dari eksplorasi \emph{dataset} sistem tanya jawab yang penulis lakukan. Eksplorasi \emph{dataset} akan dibagi menjadi tiga bagian besar, yaitu: \emph{overview statistics}, \emph{length-based analysis}, dan \emph{type-based analysis}. Berikut hasil eksplorasi \emph{dataset}-nya.

%-----------------------------------------------------------------------------%
\subsection{Eksplorasi \emph{Dataset} SQuAD-ID}
%-----------------------------------------------------------------------------%

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Overview statistics}}
%-----------------------------------------------------------------------------%
Berikut, tabel ringkasan statistik dari \emph{dataset} SQuAD-ID (Tabel 5.1). Pada tabel, kolom \emph{All} bermakna gabungan dari data \emph{train} dan data \emph{dev}; kemudian, pada baris jumlah jawaban bagian kiri tanda positif itu jawaban yang \emph{answerable} dan bagian kanan tanda positif itu jawaban yang \emph{unanswerable}.

\begin{table}[H]\centering
\begin{tabular}{lrrrr}\toprule
\emph{Overview Statistics} &\emph{Train} &\emph{Dev} &\emph{All} \\
Jumlah artikel &19.033 &1.204 &20.237 \\
Jumlah konteks &130.319 &11.873 &142.192 \\
Jumlah pertanyaan &130.301 &11.871 &142.172 \\
Jumlah jawaban &130.310 + 9 &11.858 + 15 &142.168 + 24 \\
Rerata panjang konteks &107.38 &113.82 &107.92 \\
Rerata panjang pertanyaan &8.7 &8.79 &8.71 \\
Rerata panjang jawaban &2.97 &3.11 &2.98 \\
Ukuran kosakata &226.343 &20.642 &245.497 \\
\bottomrule
\end{tabular}
\caption{Tabel ringkasan statistik dari SQuAD-ID.}
\end{table}

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Length-based analysis}}
%-----------------------------------------------------------------------------%

Berikut, tabel analisis berbasis panjang kata dari \emph{dataset} SQuAD-ID (Tabel 5.2), untuk bagian pertanyaan dan jawaban.

\begin{table}[H]\centering
\begin{tabular}{lrrrrrrr}\toprule
\multirow{2}{*}{Panjang kata} &\multicolumn{3}{c}{Pertanyaan} &\multicolumn{3}{c}{Jawaban} \\\cmidrule{2-7}
&\emph{Train} &\emph{Dev} &\emph{All} &\emph{Train} &\emph{Dev} &\emph{All} \\\midrule
0 &- &- &- &9 &15 &24 \\
1-5 &17.332 &1.499 &18.831 &115.151 &10.277 &125.428 \\
6$-$10 &112.987 &10.374 &123.361 &15.159 &1.581 &16.740 \\
11-15 &0 &0 &0 &0 &0 &0 \\
16-20 &0 &0 &0 &0 &0 &0 \\
$>$20 &0 &0 &0 &0 &0 &0 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis panjang kata dari SQuAD-ID, untuk bagian pertanyaan dan jawaban.}
\end{table}

Kemudian, di bawah ini merupakan tabel analisis berbasis panjang kata dari \emph{dataset} SQuAD-ID (Tabel 5.3), untuk bagian konteks.

\begin{table}[H]\centering
\begin{tabular}{lrrrr}\toprule
\multirow{2}{*}{Panjang} &\multicolumn{3}{c}{Konteks} \\\cmidrule{2-4}
&\emph{Train} &\emph{Dev} &\emph{All} \\\midrule
$\leq100$ &68.521 &5.866 &74.387 \\
101-150 &61.798 &6.007 &67.805 \\
151-200 &0 &0 &0 \\
201-250 &0 &0 &0 \\
251-300 &0 &0 &0 \\
$>$300 &0 &0 &0 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis panjang kata dari SQuAD-ID, untuk bagian konteks.}
\end{table}

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Type-based analysis}}
%-----------------------------------------------------------------------------%
Berikut, tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} SQuAD-ID (Tabel 5.4), untuk bagian \emph{question type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe Pertanyaan &Jumlah \\\midrule
Apa &69.071 \\
Dimana &12.711 \\
Kapan &8.388 \\
Siapa &14.370 \\
Mengapa &2.075 \\
Bagaimana &3.312 \\
Berapa &19.908 \\
Lainnya &12.357 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari SQuAD-ID, untuk bagian \emph{question type}.}
\end{table}

Kemudian, di bawah ini merupakan tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} SQuAD-ID (Tabel 5.5), untuk bagian \emph{answer type}.

\begin{table}[H]\centering
\begin{tabular}{lr|lr}
\toprule
Tipe Jawaban & Jumlah & Tipe Jawaban & Jumlah \\
\midrule
\emph{Person} & 138 & \emph{Work of Art} & 12 \\
\emph{NORP} & 21 & \emph{Law} & 1 \\
\emph{Facility} & 5 & \emph{Language} & 8 \\
\emph{Organization} & 18 & \emph{Date} & 144 \\
\emph{GPE} & 121 & \emph{Time} & 0 \\
\emph{Location} & 35 & \emph{Percent} & 1 \\
\emph{Product} & 52 & \emph{Money} & 10 \\
\emph{Event} & 3 & \emph{Quantity} & 79 \\
\emph{Ordinal} & 38 & \emph{Cardinal} & 53 \\
\emph{REG} & 22 & \emph{Null} & 180 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari SQuAD-ID, untuk bagian \emph{answer type}.}
\end{table}

Terakhir, di bawah ini merupakan tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} SQuAD-ID (Tabel 5.6), untuk bagian \emph{reasoning type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe \emph{Reasoning} &Jumlah \\\midrule
\emph{Word Matching} & 9\\
\emph{Paraphrase} & 17\\
\emph{Single-Sentence Reasoning} & 14\\
\emph{Multi-Sentence Reasoning} & 9\\
\emph{Ambiguous or Insufficient} & 51\\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari SQuAD-ID, untuk bagian \emph{reasoning type}.}
\end{table}

\subsection{Eksplorasi \emph{Dataset} TyDI-QA-ID}
%-----------------------------------------------------------------------------%

%-----------------------------------------------------------------------------%
%-----------------------------------------------------------------------------%
\subsubsection{\emph{Overview statistics}}
%-----------------------------------------------------------------------------%
Berikut, tabel ringkasan statistik dari \emph{dataset} TyDI-QA-ID (Tabel 5.7). Pada tabel, kolom \emph{All} bermakna gabungan dari data \emph{train} dan data \emph{dev}; kemudian, pada baris jumlah jawaban bagian kiri tanda positif itu jawaban yang \emph{answerable} dan bagian kanan tanda positif itu jawaban yang \emph{unanswerable}.

\begin{table}[H]\centering
\begin{tabular}{lrrrr}\toprule
\emph{Overview Statistics} &\emph{Train} &\emph{Dev} &\emph{All} \\
Jumlah artikel &4.844 &564 &5.408 & \\
Jumlah konteks &4.847 &565 &5.412 & \\
Jumlah pertanyaan &4.847 &565 &5.412 & \\
Jumlah jawaban &4.847 + 0 &5.65 + 0 &5.412 + 0 & \\
Rerata panjang konteks &78.73 &5.46 &4.91 & \\
Rerata panjang pertanyaan &78.32 &5.72 &5.31 & \\
Rerata panjang jawaban &78.69 &5.49 &4.95 & \\
Ukuran kosakata &12.201 &1.612 &13.724 & \\
\bottomrule
\end{tabular}
\caption{Tabel ringkasan statistik dari TyDI-QA-ID.}
\end{table}

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Length-based analysis}}
%-----------------------------------------------------------------------------%

Berikut, tabel analisis berbasis panjang kata dari \emph{dataset} TyDI-QA-ID (Tabel 5.8), untuk bagian pertanyaan dan jawaban.

\begin{table}[H]\centering
\begin{tabular}{lrrrrrrr}\toprule
\multirow{2}{*}{Panjang kata} &\multicolumn{3}{c}{Pertanyaan} &\multicolumn{3}{c}{Jawaban} \\\cmidrule{2-7}
&\emph{Train} &\emph{Dev} &\emph{All} &\emph{Train} &\emph{Dev} &\emph{All} \\\midrule
0 &- &- &- & & & \\
1-5 &2.759 &287 &3.046 &3.725 &419 &4.144 \\
6$-$10 &2.088 &278 &2.366 &1.122 &146 &1.268 \\
11-15 &0 &0 &0 &0 &0 &0 \\
16-20 &0 &0 &0 &0 &0 &0 \\
$>$20 &0 &0 &0 &0 &0 &0 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis panjang kata dari TyDI-QA-ID, untuk bagian pertanyaan dan jawaban.}
\end{table}

Kemudian, di bawah ini merupakan tabel analisis berbasis panjang kata dari \emph{dataset} TyDI-QA-ID (Tabel 5.9), untuk bagian konteks.

\begin{table}[H]\centering
\begin{tabular}{lrrrr}\toprule
\multirow{2}{*}{Panjang} &\multicolumn{3}{c}{Konteks} \\\cmidrule{2-4}
&\emph{Train} &\emph{Dev} &\emph{All} \\\midrule
$\leq100$ &3.721 &437 &4.158 \\
101-150 &1.126 &128 &1.254 \\
151-200 &0 &0 &0 \\
201-250 &0 &0 &0 \\
251-300 &0 &0 &0 \\
$>$300 &0 &0 &0 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis panjang kata dari TyDI-QA-ID, untuk bagian konteks.}
\end{table}

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Type-based analysis}}
%-----------------------------------------------------------------------------%
Berikut, tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} TyDI-QA-ID (Tabel 5.10), untuk bagian \emph{question type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe Pertanyaan &Jumlah \\\midrule
Apa &1.781 \\
Dimana &294 \\
Kapan &894 \\
Siapa &355 \\
Mengapa &23 \\
Bagaimana &24 \\
Berapa &900 \\
Lainnya &1.141 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari TyDI-QA-ID, untuk bagian \emph{question type}.}
\end{table}

Kemudian, di bawah ini merupakan tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} TyDI-QA-ID (Tabel 5.11), untuk bagian \emph{answer type}.

\begin{table}[H]\centering
\begin{tabular}{lr|lr}
\toprule
Tipe Jawaban & Jumlah & Tipe Jawaban & Jumlah \\
\midrule
\emph{Person} & 138 & \emph{Work of Art} & 12 \\
\emph{NORP} & 21 & \emph{Law} & 1 \\
\emph{Facility} & 5 & \emph{Language} & 8 \\
\emph{Organization} & 18 & \emph{Date} & 144 \\
\emph{GPE} & 121 & \emph{Time} & 0 \\
\emph{Location} & 35 & \emph{Percent} & 1 \\
\emph{Product} & 52 & \emph{Money} & 10 \\
\emph{Event} & 3 & \emph{Quantity} & 79 \\
\emph{Ordinal} & 38 & \emph{Cardinal} & 53 \\
\emph{REG} & 22 & \emph{Null} & 180 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari TyDI-QA-ID, untuk bagian \emph{answer type}.}
\end{table}

Terakhir, di bawah ini merupakan tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} TyDI-QA-ID (Tabel 5.12), untuk bagian \emph{reasoning type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe \emph{Reasoning} &Jumlah \\\midrule
\emph{Word Matching} & 9\\
\emph{Paraphrase} & 32\\
\emph{Single-Sentence Reasoning} & 17\\
\emph{Multi-Sentence Reasoning} & 22\\
\emph{Ambiguous or Insufficient} & 20\\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari TyDI-QA-ID, untuk bagian \emph{reasoning type}.}
\end{table}

%-----------------------------------------------------------------------------%
\subsection{Eksplorasi \emph{Dataset} IDK-MRC}
%-----------------------------------------------------------------------------%

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Overview statistics}}
%-----------------------------------------------------------------------------%
Berikut, tabel ringkasan statistik dari \emph{dataset} IDK-MRC (Tabel 5.13). Pada tabel, kolom \emph{All} bermakna gabungan dari data \emph{train} dan data \emph{dev}; kemudian, pada baris jumlah jawaban bagian kiri tanda positif itu jawaban yang \emph{answerable} dan bagian kanan tanda positif itu jawaban yang \emph{unanswerable}.

\begin{table}[H]\centering
\begin{tabular}{lrrrr}\toprule
\emph{Overview Statistics} &\emph{Train} &\emph{Dev} &\emph{All} \\
Jumlah artikel &3.528 &348 &3.876 \\
Jumlah konteks &9.332 &764 &10.096 \\
Jumlah pertanyaan &9.327 &763 &10.090 \\
Jumlah jawaban &5.042 + 4.290 &382 + 382 &5.424 + 4.672 \\
Rerata panjang konteks &79.81 &77.66 &79.65 \\
Rerata panjang pertanyaan &5.73 &6.18 &5.77 \\
Rerata panjang jawaban &2.59 &2.88 &2.61 \\
Ukuran kosakata &16.533 &1.474 &17.967 \\
\bottomrule
\end{tabular}
\caption{Tabel ringkasan statistik dari IDK-MRC.}
\end{table}

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Length-based analysis}}
%-----------------------------------------------------------------------------%

Berikut, tabel analisis berbasis panjang kata dari \emph{dataset} TyDI-QA-ID (Tabel 5.14), untuk bagian pertanyaan dan jawaban.

\begin{table}[H]\centering
\begin{tabular}{lrrrrrrr}\toprule
\multirow{2}{*}{Panjang kata} &\multicolumn{3}{c}{Pertanyaan} &\multicolumn{3}{c}{Jawaban} \\\cmidrule{2-7}
&\emph{Train} &\emph{Dev} &\emph{All} &\emph{Train} &\emph{Dev} &\emph{All} \\\midrule
0 &- &- &- &4.290 &382 &4.672 \\
1-5 &4.881 &338 &5.219 &3.882 &273 &4.155 \\
6$-$10 &4.451 &426 &4.877 &1.160 &109 &1.269 \\
11-15 &0 &0 &0 &0 &0 &0 \\
16-20 &0 &0 &0 &0 &0 &0 \\
$>$20 &0 &0 &0 &0 &0 &0 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis panjang kata dari IDK-MRC, untuk bagian pertanyaan dan jawaban.}
\end{table}

Kemudian, di bawah ini merupakan tabel analisis berbasis panjang kata dari \emph{dataset} IDK-MRC (Tabel 5.15), untuk bagian konteks.

\begin{table}[H]\centering
\begin{tabular}{lrrrr}\toprule
\multirow{2}{*}{Panjang} &\multicolumn{3}{c}{Konteks} \\\cmidrule{2-4}
&\emph{Train} &\emph{Dev} &\emph{All} \\\midrule
$\leq100$ &7.079 &589 &7.668 \\
101-150 &2.253 &175 &2.428 \\
151-200 &0 &0 &0 \\
201-250 &0 &0 &0 \\
251-300 &0 &0 &0 \\
$>$300 &0 &0 &0 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis panjang kata dari IDK-MRC, untuk bagian konteks.}
\end{table}

%-----------------------------------------------------------------------------%
\subsubsection{\emph{Type-based analysis}}
%-----------------------------------------------------------------------------%
Berikut, tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} IDK-MRC (Tabel 5.16), untuk bagian \emph{question type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe Pertanyaan &Jumlah \\\midrule
Apa &3.267 \\
Dimana &568 \\
Kapan &1.757 \\
Siapa &958 \\
Mengapa &122 \\
Bagaimana &111 \\
Berapa &1.667 \\
Lainnya &1.646 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari IDK-MRC, untuk bagian \emph{question type}.}
\end{table}

Kemudian, di bawah ini merupakan tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} IDK-MRC (Tabel 5.17), untuk bagian \emph{answer type}.

\begin{table}[H]\centering
\begin{tabular}{lr|lr}
\toprule
Tipe Jawaban & Jumlah & Tipe Jawaban & Jumlah \\
\midrule
\emph{Person} & 63 & \emph{Work of Art} & 7 \\
\emph{NORP} & 9 & \emph{Law} & 1 \\
\emph{Facility} & 2 & \emph{Language} & 2 \\
\emph{Organization} & 9 & \emph{Date} & 84 \\
\emph{GPE} & 60 & \emph{Time} & 1 \\
\emph{Location} & 25 & \emph{Percent} & 2 \\
\emph{Product} & 30 & \emph{Money} & 3 \\
\emph{Event} & 10 & \emph{Quantity} & 33 \\
\emph{Ordinal} & 10 & \emph{Cardinal} & 29 \\
\emph{REG} & 14 & \emph{Null} & 512 \\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari IDK-MRC, untuk bagian \emph{answer type}.}
\end{table}

Terakhir, di bawah ini merupakan tabel analisis berbasis karakteristik pertanyaan dan jawaban dari \emph{dataset} IDK-MRC (Tabel 5.18), untuk bagian \emph{reasoning type}.

\begin{table}[H]\centering
\begin{tabular}{lrr}\toprule
Tipe \emph{Reasoning} &Jumlah \\\midrule
\emph{Word Matching} & 9\\
\emph{Paraphrase} & 10\\
\emph{Single-Sentence Reasoning} & 5\\
\emph{Multi-Sentence Reasoning} & 13\\
\emph{Ambiguous or Insufficient} & 62\\
\bottomrule
\end{tabular}
\caption{Tabel analisis berbasis berbasis karakteristik pertanyaan dan jawaban dari IDK-MRC, untuk bagian \emph{reasoning type}.}
\end{table}

%-----------------------------------------------------------------------------%
\subsection{Kesimpulan Eksplorasi \emph{Dataset}}
%-----------------------------------------------------------------------------%
Dari eksplorasi \emph{dataset} yang dilakukan sebelumnya, maka dapat ditarik beberapa pola keunikan, antara lain: \emph{dataset} SQuAD-ID memiliki data terbanyak dibandingkan \emph{dataset} TyDI-QA-ID dan IDK-MRC, lalu, \emph{dataset} IDK-MRC memiliki data jawaban yang \emph{unanswerable} terbanyak dibandingkan \emph{dataset} TyDI-QA-ID dan SQuAD-ID, kemudian, \emph{dataset} SQuAD-ID memiliki persentase tipe pertanyaan apa terbanyak dibandingkan \emph{dataset} TyDI-QA-ID dan IDK-MRC, lalu, \emph{dataset} TyDI-QA-ID memiliki \emph{answer type} \emph{person} terbanyak dibandingkan \emph{dataset} IDK-MRC dan SQuAD-ID, terakhir \emph{dataset} IDK-MRC memiliki tipe \emph{reasoning type} \emph{ambiguous or insufficient} terbanyak dibandingkan \emph{dataset} TyDI-QA-ID dan SQuAD-ID.

%-----------------------------------------------------------------------------%
\section{Hasil \emph{Training Sequence Classification Task}}
\label{5.2}
%-----------------------------------------------------------------------------%
Pada sub-bab ini, akan dijelaskan mengenai hasil dari \emph{training sequence classification task} yang nantinya model dan \emph{dataset} yang terbaik akan digunakan sebagai \emph{intermediate-task} pada metode \emph{intermediate-task transfer learning} dan sebagai verifikator pada metode \emph{task recasting} sebagai verifikator.

\begin{table}[H]\centering
\begin{tabular}{llrr}
\toprule
         Model &    Dataset &  Akurasi &  Skor F1 \\
\midrule
 IndoBERT-base &      Basic &    0.764 &    0.763 \\
 IndoBERT-base & Translated &    \underline{0.809} &    \underline{0.809} \\
 IndoBERT-base &  Augmented &    0.803 &    0.804 \\
\hline
IndoBERT-large &      Basic &    0.772 &    0.773 \\
IndoBERT-large & Translated &    \underline{0.811} &    \underline{0.811} \\
IndoBERT-large &  Augmented &    0.805 &    0.806 \\
\hline
    XLMR-large &      Basic &    0.827 &    0.827 \\
    XLMR-large & Translated &    0.858 &    0.858 \\
    XLMR-large &  Augmented &    \underline{0.861} &    \underline{0.861} \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan skor akurasi dan skor F1 pada \emph{training sequence classification task}.}
\end{table}

Dapat dilihat pada tabel di atas, pada \emph{dataset} \emph{translated} mendapatkan skor akurasi dan skor F1 terbaik pada model \texttt{IndoBERT-base} dan model \texttt{IndoBERT-large}. Namun, hasil skor akurasi dan skor F1 terbaik untuk keseluruhan \emph{training sequence classification task} didapatkan oleh \emph{dataset} \emph{augmented} dan model \texttt{xlm-roberta-large} dengan mendapatkan skor akurasi dan skor F1 sebesar 0.861. Oleh karena itu \emph{dataset} \emph{augmented} dan model \texttt{xlm-roberta-large} dijadikan sebagai \emph{intermediate-task} pada metode \emph{intermediate-task transfer learning} dan sebagai verifikator pada metode \emph{task recasting} sebagai verifikator.

%-----------------------------------------------------------------------------%
\section{Hasil dan Analisis Performa Metode \emph{Intermediate-Task Transfer Learning}}
\label{5.3}
%-----------------------------------------------------------------------------%
Pada sub-bab ini, akan dijelaskan mengenai hasil dan analisis eksperimen metode \emph{intermediate-task transfer learning} yang penulis lakukan pada pada penelitian ini. Sebagai catatan, bahwa ITTL yang dimaksud di bab ini adalah singkatan dari \emph{intermediate-task transfer learning} dan ITTL + F merupakan singkatan dari \emph{intermediate-task transfer learning with freezing layer}. Pada tabel di bawah ini, akan dipaparkan skor \emph{exact match} dan skor F1 pada metode \emph{intermediate-task transfer learning}.


\begin{table}[H]\centering
\begin{tabular}{llrrrrrr}
\toprule
         \multirow{2}{*}{Model} &\multirow{2}{*}{Metode} &\multicolumn{2}{c}{SQuAD-ID} &\multicolumn{2}{c}{TyDI-QA-ID} &\multicolumn{2}{c}{IDK-MRC} \\\cmidrule{3-8}
& &EM &F1 &EM &F1 &EM &F1
\\\midrule
 IndoBERT-base & Baseline & 44.66 & 61.55 & \underline{52.51} & \underline{65.17} & 66.63 & 72.84 \\
 IndoBERT-base &     ITTL & 45.01 & 61.63 & 51.58 & 63.99 & 65.80 & 72.46 \\
 IndoBERT-base & ITTL + F & \underline{45.19} & \underline{61.95} & 51.81 & 64.70 & \underline{67.33} & \underline{73.44} \\
 \hline
IndoBERT-large & Baseline & 43.82 & \underline{61.09} & 55.08 & 68.89 & 53.89 & 60.51 \\
IndoBERT-large &     ITTL & \underline{44.23} & \underline{61.09} & 55.54 & 69.11 & 53.18 & 60.53 \\
IndoBERT-large & ITTL + F & 43.90 & 61.05 & \underline{57.29} & \underline{70.72} & \underline{59.55} & \underline{66.20} \\
\hline
    XLMR-large & Baseline & 49.54 & 66.69 & \underline{66.51} & \underline{78.27} & 77.95 & 84.64 \\
    XLMR-large &     ITTL & 49.94 & 67.20 & 65.11 & 76.40 & 77.95 & 84.23 \\
    XLMR-large & ITTL + F & \underline{50.41} & \underline{67.64} & \underline{66.51} & 77.59 & \underline{78.30} & \underline{85.14} \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan skor \emph{exact match} dan skor F1 pada metode \emph{intermediate-task transfer learning}.}
\end{table}

Dapat dilihat pada tabel di atas, pada model \texttt{IndoBERT-base}, dua dari tiga \emph{dataset} yang diuji memperlihatkan naiknya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{intermediate-task transfer learning} maupun \emph{intermediate-task transfer learning with freezing layer}, walaupun kenaikan skor \emph{exact match} dan skor F1 tidak naik secara signifikan; kemudian, hasil skor keseluruhan model ini juga masih kurang baik, dapat dilihat pada skor F1 masih sekitar 61.63 hingga 73.44.

Kemudian, pada model \texttt{IndoBERT-large}, dapat dilihat tren yang lebih baik dari model \texttt{IndoBERT-base}, yaitu: tiga dari tiga \emph{dataset} yang diuji memperlihatkan naiknya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{intermediate-task transfer learning} maupun \emph{intermediate-task transfer learning with freezing layer}, namun dengan kenaikan skor yang cukup tinggi pada \emph{dataset} IDK-MRC, skor naik sekitar 6 poin pada metode \emph{intermediate-task transfer learning with freezing layer}. Model \texttt{IndoBERT-large} tidak secara pasti memiliki skor \emph{exact match} dan skor F1 yang lebih tinggi dibandingkan model \texttt{IndoBERT-base}, walaupun memiliki jumlah parameter yang lebih banyak dibandingkan model \texttt{IndoBERT-large}.

Terakhir, pada model \texttt{xlm-roberta-large}, mengikuti tren pada model \texttt{IndoBERT-large}, yaitu: tiga dari tiga \emph{dataset} yang diuji memperlihatkan naiknya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{intermediate-task transfer learning} maupun \emph{intermediate-task transfer learning with freezing layer}, namun kenaikan skor \emph{exact match} dan skor F1 tidak naik secara signifikan. Walaupun skor tidak naik secara signifikan, namun dapat dilihat pada tabel di atas, skor secara keseluruhan, model \texttt{xlm-roberta-large} memiliki skor \emph{exact match} dan skor F1 yang lebih tinggi dibanding kedua model sebelumnya.

Secara kecenderungan, metode \emph{intermediate-task transfer learning with freezing layer} memiliki skor yang lebih tinggi dibandingkan dengan metode \emph{intermediate-task transfer learning}. Maka, dapat disimpulkan, bahwa model terbaik untuk metode \emph{intermediate-task transfer learning} adalah: model \texttt{xlm-roberta-large} dengan metode \emph{intermediate-task transfer learning with freezing layer}, dengan skor \emph{exact match} dan skor F1 model dan metode tersebut mengungguli semua model dan metode lainnya. Namun, kenaikan paling signifikan terdapat pada model \texttt{IndoBERT-large} dengan metode \emph{intermediate-task transfer learning with freezing layer}, dapat dilihat skor \emph{exact match} naik sekitar 5.66 dan skor F1 naik sekitar 5.69. Hal tersebut membuat model dan metode ini memiliki kenaikan skor paling signifikan di antara model dan metode lainnya. 

\begin{table}[H]\centering
\begin{tabular}{lrrrrr}\toprule
Model &Metode &SQuAD-ID &TyDI-QA-ID &IDK-MRC \\\midrule
IndoBERT-base &Baseline &0.09 &0.0 &0.86 \\
IndoBERT-base &ITTL &\underline{0.13} &0.0 &\underline{0.87} \\
IndoBERT-base &ITTL + F &0.10 &0.0 &\underline{0.87} \\
\hline
IndoBERT-large &Baseline &0.13 &0.0 &0.54 \\
IndoBERT-large &ITTL &\underline{0.14} &0.0 &0.54 \\
IndoBERT-large &ITTL + F &0.12 &0.0 &\underline{0.63} \\
\hline
XLMR-large &Baseline &0.10 &0.0 &0.92 \\
XLMR-large &ITTL &0.09 &0.0 &\underline{0.94} \\
XLMR-large &ITTL + F &\underline{0.11} &0.0 &0.92 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan skor \emph{exact match} dengan metode \emph{intermediate-task transfer learning} pada \emph{unanswerable set}.}
\end{table}

Dapat dilihat pada contoh tabel di atas, terlihat bahwa setiap model dan setiap \emph{dataset}, metode ITTL dan/atau ITTL + F secara kecenderungan meningkat skor \emph{exact match}-nya pada \emph{unanswerable set}. Maka, dapat disimpulkan bahwa, metode \emph{intermediate-task transfer learning} membantu meningkatkan performa terhadap jenis-jenis pertanyaan \emph{unanswerable} pada suatu \emph{dataset} sistem tanya jawab. Hasil \emph{dataset} TyDI-QA-ID selalu nol, karena pada \emph{dataset} TyDI-QA-ID tidak terdapat \emph{unanswerable set}. Kemudian, pada sub-bab selanjutnya akan dijelaskan mengenai perincian karakteristik pasangan konteks-pertanyaan-jawaban yang mengalami peningkatan atau penurunan performa setelah menggunakan metode \emph{intermediate-task transfer learning}.

%-----------------------------------------------------------------------------%
\subsection{\emph{Question Type}}
%-----------------------------------------------------------------------------%

\begin{table}[H]\centering
\scriptsize
\begin{tabular}{llrrrrrrrr}
\toprule
         \multirow{2}{*}{Model} &\multirow{2}{*}{Metode} &\multicolumn{8}{c}{IDK-MRC} \\\cmidrule{3-10}
& &Apa &Dimana &Kapan &Siapa &Bagaimana &Kenapa &Berapa &Lainnya \\\midrule
IndoBERT-base &Baseline &59.33 &61.22 &77.46 &\underline{75.00} &\underline{58.33} &\underline{62.5} &67.57 &\underline{66.89} \\
IndoBERT-base &ITTL &59.70 &61.22 &76.88 &71.05 &\underline{58.33} &\underline{62.5} &\underline{68.47} &63.58 \\
IndoBERT-base &ITTL + F &\underline{60.82} &\underline{63.27} &\underline{80.35} &\underline{75.00} &\underline{58.33} &\underline{62.5} &67.57 &64.24 \\
\hline
IndoBERT-large &Baseline &51.12 &48.98 &62.43 &59.21 &33.33 &37.5 &56.76 &49.01 \\
IndoBERT-large &ITTL &50.37 &48.98 &64.74 &48.68 &33.33 &37.5 &49.55 &54.30 \\
IndoBERT-large &ITTL + F &\underline{56.34} &\underline{51.02} &\underline{65.32} &\underline{63.16} &\underline{41.67} &\underline{50.0} &\underline{66.67} &\underline{56.95} \\
\hline
XLMR-large &Baseline &74.25 &\underline{77.55} &84.39 &78.95 &75.00 &\underline{87.5} &\underline{81.98} &73.51 \\
XLMR-large &ITTL &75.00 &75.51 &84.97 &\underline{80.26} &\underline{83.33} &\underline{87.5} &\underline{81.98} &71.52 \\
XLMR-large &ITTL + F &\underline{75.75} &75.51 &\underline{85.55} &77.63 &\underline{83.33} &\underline{87.5} &\underline{81.98} &\underline{72.85} \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis \emph{question type} pada metode \emph{intermediate-task transfer learning} pada \emph{dataset} IDK-MRC.}
\end{table}

Pada sub-bab ini, penulis mencontohkan untuk \emph{dataset} IDK-MRC, karena \emph{dataset} ini memberikan contoh yang penulis rasa lebih menarik, untuk kedua \emph{dataset} lainnya, penulis letakkan di bagian Lampiran \ref{Lampiran Terkait Tabel: 7.3}. Pada model \texttt{IndoBERT-base}, tipe pertanyaan apa dan dimana naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan tipe pertanyaan siapa, bagaimana, berapa, dan lainnya naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan tipe pertanyaan kenapa selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Kemudian, pada model \texttt{IndoBERT-large}, tipe pertanyaan kapan, siapa, dan berapa naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan tipe pertanyaan apa, dimana, bagaimana, kenapa, dan lainnya naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, tidak ada tipe pertanyaan yang selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan persentase nilai benar pada model ini cukup signifikan, kenaikan tertinggi ada pada metode \emph{intermediate-task transfer learning with freezing layer} pada \emph{dataset} IDK-MRC dengan tipe pertanyaan berapa, persentase nilai benar naik sekitar 9.91\% dibandingkan tanpa menggunakan metode \emph{intermediate-task transfer learning}.

Terakhir, pada model \texttt{xlm-roberta-large}, tipe pertanyaan apa, kapan, dan bagaimana naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan tipe pertanyaan dimana dan siapa naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan tipe pertanyaan berapa selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{intermediate-task transfer learning} berhasil menjawab lebih banyak benarnya pada tipe pertanyaan apa dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk tipe pertanyaan kenapa selalu turun pada model \texttt{IndoBERT-large} dan tipe pertanyaan berapa pada model \texttt{xlm-roberta-large}. Selain tipe pertanyaan di atas, metode \emph{intermediate-task transfer learning} cenderung berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan kenaikannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-large}. 

%-----------------------------------------------------------------------------%
\subsection{Panjang Konteks}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang konteks pada metode \emph{intermediate-task transfer learning}. Catatan: arti dari $\leq$100 adalah panjang konteks di bawah 100, dan arti dari $\leq$150 adalah panjang konteks di antara 101 sampai 150 (101$-$150).

\begin{table}[H]\centering
\begin{tabular}{lrrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode} &\multicolumn{2}{c}{SQuAD-ID} &\multicolumn{2}{c}{TyDI-QA-ID} &\multicolumn{2}{c}{IDK-MRC} \\\cmidrule{3-8}
& &$\leq$100 &$\leq$150 &$\leq$100 &$\leq$150 &$\leq$100 &$\leq$150 \\\midrule
IndoBERT-base &Baseline &45.03 &45.07 &\underline{57.82} &\underline{40.89} &68.94 &62.60 \\
IndoBERT-base &ITTL &45.54 &\underline{45.47} &57.65 &38.29 &67.75 &62.60 \\
IndoBERT-base &ITTL + F &\underline{46.12} &45.27 &56.80 &40.89 &\underline{69.45} &\underline{63.74} \\
\hline
IndoBERT-large &Baseline &\underline{45.40} &43.96 &60.24 &43.98 &56.95 &47.29 \\
IndoBERT-large &ITTL &45.29 &\underline{44.60} &60.74 &43.98 &54.75 &50.00 \\
IndoBERT-large &ITTL + F &45.31 &44.10 &\underline{62.27} &\underline{46.24} &\underline{62.71} &\underline{52.71} \\
\hline
XLMR-large &Baseline &49.83 &49.92 &69.29 &\underline{57.14} &79.79 &71.79 \\
XLMR-large &ITTL &\underline{50.56} &50.05 &68.08 &55.10 &79.02 &\underline{74.87} \\
XLMR-large &ITTL + F &50.09 &\underline{51.25} &\underline{70.20} &54.08 &\underline{80.25} &72.31 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang konteks pada metode \emph{intermediate-task transfer learning}.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang konteks $\leq100$ dan 101$-$150 naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Kemudian, pada model \texttt{IndoBERT-large}, panjang konteks 101$-$150 naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan panjang konteks $\leq100$ naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, tidak ada panjang konteks yang selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan persentase nilai benar pada model ini cukup signifikan, kenaikan tertinggi ada pada metode \emph{intermediate-task transfer learning with freezing layer} pada \emph{dataset} IDK-MRC dengan panjang konteks 101$-$150, persentase nilai benar naik sekitar 5.42\% dibandingkan tanpa menggunakan metode \emph{intermediate-task transfer learning}.

Kemudian, pada model \texttt{xlm-roberta-large}, panjang konteks $\leq100$ naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan panjang konteks 101$-$150 naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, tidak ada tipe pertanyaan yang selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{intermediate-task transfer learning} tidak berhasil menjawab lebih banyak benarnya pada sebagian panjang konteks dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Namun, metode \emph{intermediate-task transfer learning} cenderung berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan kenaikannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-large}.

%-----------------------------------------------------------------------------%
\subsection{Panjang Pertanyaan}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang pertanyaan pada metode \emph{intermediate-task transfer learning}. Catatan: arti dari $\leq$5 adalah panjang pertanyaan di bawah 5, dan arti dari $\leq$10 adalah panjang pertanyaan di antara 6 sampai 10 (6$-$10).

\begin{table}[H]\centering
\begin{tabular}{lrrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode} &\multicolumn{2}{c}{SQuAD-ID} &\multicolumn{2}{c}{TyDI-QA-ID} &\multicolumn{2}{c}{IDK-MRC} \\\cmidrule{3-8}
& &$\leq$5 &$\leq$10 &$\leq$5 &$\leq$10 &$\leq$5 &$\leq$10 \\\midrule
IndoBERT-base &Baseline &\underline{43.89} &45.21 &56.70 &\underline{44.92} &64.45 &\underline{69.15} \\
IndoBERT-base &ITTL &43.82 &45.73 &\underline{56.88} &41.97 &64.45 &67.61 \\
IndoBERT-base &ITTL + F &43.39 &\underline{45.90} &56.16 &43.93 &\underline{66.75} &68.49 \\
\hline
IndoBERT-large &Baseline &43.23 &44.71 &61.05 &44.59 &58.31 &50.33 \\
IndoBERT-large &ITTL &\underline{45.13} &\underline{44.84} &59.78 &47.87 &58.57 &48.80 \\
IndoBERT-large &ITTL + F &43.02 &44.79 &\underline{61.59} &\underline{49.51} &\underline{64.71} &\underline{55.36} \\
\hline
XLMR-large &Baseline &48.27 &50.11 &\underline{68.94} &\underline{62.00} &77.59 &78.28 \\
XLMR-large &ITTL &48.54 &50.55 &68.04 &59.67 &\underline{79.06} &77.15 \\
XLMR-large &ITTL + F &\underline{49.20} &\underline{50.89} &69.84 &60.33 &77.34 &\underline{79.41} \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang pertanyaan pada metode \emph{intermediate-task transfer learning}.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang pertanyaan $\leq$5 naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Kemudian, pada model \texttt{IndoBERT-large}, panjang pertanyaan $\leq$5 dan 6$-$10 naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji. Kenaikan persentase nilai benar pada model ini cukup signifikan, kenaikan tertinggi ada pada metode \emph{intermediate-task transfer learning with freezing layer} pada \emph{dataset} IDK-MRC dengan panjang pertanyaan $\leq$5, persentase nilai benar naik sekitar 6.40\% dibandingkan tanpa menggunakan metode \emph{intermediate-task transfer learning}.

Kemudian, pada model \texttt{xlm-roberta-large}, panjang pertanyaan $\leq$5 dan 6$-$10 naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{intermediate-task transfer learning} tidak berhasil menjawab lebih banyak benarnya pada sebagian panjang pertanyaan dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Namun, metode \emph{intermediate-task transfer learning} cenderung berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan kenaikannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-large}.

%-----------------------------------------------------------------------------%
\subsection{Panjang Jawaban \emph{Golden Truth}}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang jawaban \emph{golden truth} pada metode \emph{intermediate-task transfer learning}. Catatan: arti dari $\leq$5 adalah panjang jawaban \emph{golden truth} di bawah 5, dan arti dari $\leq$10 adalah panjang jawaban \emph{golden truth} di antara 6 sampai 10 (6$-$10).

\begin{table}[H]\centering
\begin{tabular}{lrrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode} &\multicolumn{2}{c}{SQuAD-ID} &\multicolumn{2}{c}{TyDI-QA-ID} &\multicolumn{2}{c}{IDK-MRC} \\\cmidrule{3-8}
& &$\leq$5 &$\leq$10 &$\leq$5 &$\leq$10 &$\leq$5 &$\leq$10 \\\midrule
IndoBERT-base &Baseline &48.85 &22.37 &\underline{57.49} &39.92 &71.51 &\underline{38.98} \\
IndoBERT-base &ITTL &49.22 &\underline{23.24} &56.51 &39.09 &71.10 &35.59 \\
IndoBERT-base &ITTL + F &\underline{49.42} &22.72 &56.03 &\underline{41.15} &\underline{72.74} &36.44 \\
\hline
IndoBERT-large &Baseline &48.24 &22.24 &60.10 &42.80 &55.48 &44.92 \\
IndoBERT-large &ITTL &\underline{48.58} &22.59 &60.26 &43.62 &55.48 &39.83 \\
IndoBERT-large &ITTL + F &48.23 &\underline{22.65} &\underline{62.38} &\underline{44.44} &\underline{61.37} &\underline{49.15} \\
\hline
XLMR-large &Baseline &52.89 &\underline{28.54} &70.29 &\underline{56.28} &82.15 &\underline{50.88} \\
XLMR-large &ITTL &53.51 &27.60 &69.33 &53.68 &82.43 &50.00 \\
XLMR-large &ITTL + F &\underline{53.97} &27.40 &\underline{70.77} &54.98 &\underline{82.97} &49.12 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang jawaban \emph{golden truth} pada metode \emph{intermediate-task transfer learning}.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang jawaban \emph{golden truth} $\leq$5 dan 6$-$10 naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Kemudian, pada model \texttt{IndoBERT-large}, panjang jawaban \emph{golden truth} $\leq$5 dan 6$-$10 naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji. Kenaikan persentase nilai benar pada model ini cukup signifikan, kenaikan tertinggi ada pada metode \emph{intermediate-task transfer learning with freezing layer} pada \emph{dataset} IDK-MRC dengan panjang jawaban \emph{golden truth} $\leq$5, persentase nilai benar naik sekitar 5.89\% dibandingkan tanpa menggunakan metode \emph{intermediate-task transfer learning}.

Kemudian, pada model \texttt{xlm-roberta-large}, panjang jawaban \emph{golden truth} $\leq$5 naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji. Sedangkan panjang jawaban \emph{golden truth} 6$-$10 selalu turun pada ketiga \emph{dataset} yang penulis uji. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{intermediate-task transfer learning} tidak berhasil menjawab lebih banyak benarnya pada sebagian panjang jawaban \emph{golden truth} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Namun, metode \emph{intermediate-task transfer learning} cenderung berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan kenaikannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-large}.

%-----------------------------------------------------------------------------%
\subsection{\emph{Answer Type}}
%-----------------------------------------------------------------------------%
Tabel pada bagian ini, telah penulis sertakan pada Lampiran \ref{Lampiran Terkait Tabel: 7.3}. Pada model \texttt{IndoBERT-base}, \emph{answer type} \emph{null} naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan \emph{answer type} \emph{facility}, \emph{organization}, \emph{GPE}, \emph{WoA}, dan \emph{date} naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{answer type} \emph{event}, \emph{law}, \emph{language}, \emph{time}, dan \emph{percent} selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Kemudian, pada model \texttt{IndoBERT-large}, \emph{answer type} NORP dan location naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan \emph{answer type} \emph{person}, \emph{GPE}, \emph{product}, \emph{money}, \emph{quantity},\emph{ordinal}, \emph{cardinal}, \emph{REG}, dan \emph{null} naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{answer type} \emph{law} dan \emph{time} selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan persentase nilai benar pada model ini cukup signifikan, kenaikan tertinggi ada pada metode \emph{intermediate-task transfer learning} pada \emph{dataset} TyDI-QA-ID dengan \emph{answer type} \emph{facility}, persentase nilai benar naik sekitar 80\% dibandingkan tanpa menggunakan metode \emph{intermediate-task transfer learning}.

Terakhir, pada model \texttt{xlm-roberta-large}, \emph{answer type} \emph{product}, \emph{date}, dan \emph{cardinal} naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan \emph{answer type} \emph{organization}, \emph{GPE}, \emph{WoA}, \emph{quantity}, \emph{ordinal}, \emph{REG}, dan \emph{null} naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{answer type} \emph{person}, \emph{law}, \emph{language,} \emph{time}, dan \emph{percent} selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{intermediate-task transfer learning} tidak berhasil menjawab lebih banyak benarnya pada sebagian \emph{answer type} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk \emph{answer type} \emph{law} dan \emph{time} mengalami penurunan pada setiap model dan \emph{dataset}. Selain \emph{answer type} di atas, metode \emph{intermediate-task transfer learning} cenderung berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan kenaikannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-large}. 

%-----------------------------------------------------------------------------%
\subsection{\emph{Reasoning Type}}
%-----------------------------------------------------------------------------%

\begin{table}[H]\centering
\begin{tabular}{lrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode} &\multicolumn{5}{c}{IDK-MRC} \\\cmidrule{3-7}
& &WM &PP &SSR &MSR &AoI \\\midrule
IndoBERT-base &Baseline &60.0 &77.78 &40.0 &\underline{53.85} &69.84 \\
IndoBERT-base &ITTL &60.0 &77.78 &40.0 &46.15 &\underline{74.60} \\
IndoBERT-base &ITTL + F &60.0 &77.78 &40.0 &46.15 &\underline{74.60} \\
\hline
IndoBERT-large &Baseline &60.0 &\underline{77.78} &0.0 &\underline{69.23} &53.97 \\
IndoBERT-large &ITTL &\underline{70.0} &44.44 &0.0 &61.54 &57.14 \\
IndoBERT-large &ITTL + F &\underline{70.0} &\underline{77.78} &\underline{20.0} &61.54 &\underline{63.49} \\
\hline
XLMR-large &Baseline &80.0 &77.78 &\underline{40.0} &\underline{61.54} &\underline{85.71} \\
XLMR-large &ITTL &80.0 &77.78 &20.0 &76.92 &82.54 \\
XLMR-large &ITTL + F &80.0 &\underline{88.89} &\underline{40.0} &76.92 &84.13 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis \emph{reasoning type} pada metode \emph{intermediate-task transfer learning} pada \emph{dataset} IDK-MRC.}
\end{table}

Pada sub-bab ini, penulis mencontohkan untuk \emph{dataset} IDK-MRC, karena \emph{dataset} ini memberikan contoh yang penulis rasa lebih menarik, untuk kedua \emph{dataset} lainnya, penulis letakkan di bagian Lampiran \ref{Lampiran Terkait Tabel: 7.3}. Pada model \texttt{IndoBERT-base}, \emph{reasoning type} PP dan AoI naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} AoI selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Kemudian, pada model \texttt{IndoBERT-large}, \emph{reasoning type} WM, SSR dan AoI naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} PP selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan persentase nilai benar pada model ini cukup signifikan, kenaikan tertinggi ada pada metode \emph{intermediate-task transfer learning with freezing layer} pada \emph{dataset} IDK-MRC dengan \emph{reasoning type} AoI, persentase nilai benar naik sekitar 20\% dibandingkan tanpa menggunakan metode \emph{intermediate-task transfer learning}.

Terakhir, pada model \texttt{xlm-roberta-large}, \emph{reasoning type} PP dan MSR naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} AoI selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{intermediate-task transfer learning}. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{intermediate-task transfer learning} tidak berhasil menjawab lebih banyak benarnya pada sebagian \emph{reasoning type} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk \emph{reasoning type} PP selalu turun pada model \texttt{IndoBERT-large} dan \emph{reasoning type} AoI pada model \texttt{xlm-roberta-large}. Selain tipe pertanyaan di atas, metode \emph{intermediate-task transfer learning} cenderung berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan kenaikannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-large}. 

%-----------------------------------------------------------------------------%
\section{Hasil dan Analisis Performa Metode \emph{Task Recasting} dengan IndoNLI Sebagai Verifikator Dengan Eksperimen Tipe \emph{Filtering}.}
\label{5.4}
%-----------------------------------------------------------------------------%
Pada sub-bab ini, akan dijelaskan mengenai hasil dan analisis eksperimen metode \emph{task recasting} dengan IndoNLI sebagai verifikator dengan eksperimen tipe \emph{filtering} yang penulis lakukan pada pada penelitian ini. Pada tabel di bawah ini, akan dipaparkan skor \emph{exact match} dan skor F1 pada metode \emph{task recasting} sebagai verifikator pada parameter tipe \emph{filtering}.

\begin{table}[H]\centering
\small
\begin{tabular}{lrrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode atau Parameter} &\multicolumn{2}{c}{SQuAD-ID} &\multicolumn{2}{c}{TyDI-QA-ID} &\multicolumn{2}{c}{IDK-MRC} \\\cmidrule{3-8}
& &EM &F1 &EM &F1 &EM &F1 \\\midrule
IndoBERT-base &Baseline &\underline{44.66} &\underline{61.55} &\underline{52.51} &\underline{65.17} &\underline{66.63} &\underline{72.84} \\
IndoBERT-base &Entailment Only &33.48 &46.51 &22.29 &33.04 &63.21 &68.70 \\
IndoBERT-base &Entailment or Neutral &41.39 &57.68 &22.29 &32.86 &63.21 &68.67 \\
\hline
IndoBERT-large &Baseline &\underline{43.82} &\underline{61.09} &\underline{55.08} &\underline{68.89} &53.89 &60.51 \\
IndoBERT-large &Entailment Only &33.31 &46.41 &50.18 &62.78 &\underline{55.66} &\underline{62.01} \\
IndoBERT-large &Entailment or Neutral &41.31 &57.70 &51.93 &65.04 &53.66 &59.98 \\
\hline
XLMR-large &Baseline &\underline{49.54} &\underline{66.69} &\underline{66.51} &\underline{78.27} &\underline{77.95} &\underline{84.64} \\
XLMR-large &Entailment Only &37.54 &50.78 &59.28 &69.78 &67.69 &74.36 \\
XLMR-large &Entailment or Neutral &46.36 &62.70 &61.38 &72.19 &72.52 &79.19 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan skor \emph{exact match} dan skor F1 pada metode \emph{task recasting} sebagai verifikator pada parameter tipe \emph{filtering}.}
\end{table}

Dapat dilihat pada tabel di atas, pada model \texttt{IndoBERT-base}, seluruh \emph{dataset} yang diuji memperlihatkan turunnya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{task recasting} sebagai verifikator pada parameter \emph{entailment only} maupun \emph{entailment or neutral}, penurunan skor \emph{exact match} dan skor F1 juga turun secara signifikan, dapat dilihat pada skor \emph{exact match} menurun hingga sekitar 30.22\% pada \emph{dataset} TyDI-QA-ID; kemudian, dapat dilihat bahwa, hasil skor keseluruhan model ini juga masih kurang baik, dapat dilihat pada skor F1 masih sekitar 46.51 hingga 68.70.

Kemudian, pada model \texttt{IndoBERT-large}, dapat dilihat tren yang lebih baik dari model \texttt{IndoBERT-base}, yaitu: ada satu dari tiga \emph{dataset} yang diuji memperlihatkan naiknya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{task recasting} sebagai verifikator pada parameter \emph{entailment only} maupun \emph{entailment or neutral}, yaitu pada \emph{dataset} IDK-MRC. Model \texttt{IndoBERT-large} secara kecenderungan memiliki skor \emph{exact match} dan skor F1 yang lebih tinggi dibandingkan model \texttt{IndoBERT-base}, dapat dilihat pada \emph{dataset} TyDI-QA-ID, hasil model \texttt{IndoBERT-large} lebih baik dengan dua parameter yang dipilih dibandingkan dengan model \texttt{IndoBERT-base} dan perubahan skor tersebut juga cenderung tidak terlalu signifikan.

Terakhir, pada model \texttt{xlm-roberta-large}, mengikuti tren pada model \texttt{IndoBERT-base}, yaitu: seluruh \emph{dataset} yang diuji memperlihatkan turunnya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{task recasting} sebagai verifikator pada parameter \emph{entailment only} maupun \emph{entailment or neutral}, penurunan skor \emph{exact match} dan skor F1 juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara kecenderungan, parameter \emph{entailment or neutral} memiliki skor yang lebih tinggi dibandingkan dengan parameter \emph{entailment only}. Maka, dapat disimpulkan, bahwa model terbaik untuk metode \emph{task recasting} sebagai verifikator adalah: model \texttt{xlm-roberta-large} dengan parameter \emph{entailment or neutral}, dengan skor \emph{exact match} dan skor F1 model dan metode tersebut setidaknya lebih baik dibandingkan model dan parameter lainnya. Namun, secara keseluruhan penggunaan metode \emph{task recasting} sebagai verifikator pada semua parameter tipe \emph{filtering}, memberikan penurunan performa dari sistem tanya jawab yang sedang diuji.

\begin{table}[H]\centering
\begin{tabular}{lrrrrr}\toprule
Model &Parameter &SQuAD-ID &TyDI-QA-ID &IDK-MRC \\\midrule
IndoBERT-base &Baseline &\underline{0.09} &0.0 &\underline{0.86} \\
IndoBERT-base &Entailment Only &0.04 &0.0 &0.10 \\
IndoBERT-base &Entailment or Neutral &0.07 &0.0 &0.60 \\
\hline
IndoBERT-large &Baseline &\underline{0.13} &0.0 &\underline{0.54} \\
IndoBERT-large &Entailment Only &0.06 &0.0 &0.06 \\
IndoBERT-large &Entailment or Neutral &0.09 &0.0 &0.36 \\
\hline
XLMR-large &Baseline &\underline{0.10} &0.0 &\underline{0.92} \\
XLMR-large &Entailment Only &0.04 &0.0 &0.13 \\
XLMR-large &Entailment or Neutral &0.06 &0.0 &0.63 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan skor \emph{exact match} dengan metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} pada \emph{unanswerable set}.}
\end{table}

Dapat dilihat pada contoh tabel di atas, terlihat bahwa setiap model dan setiap \emph{dataset}, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} secara kecenderungan menurun skor \emph{exact match}-nya pada \emph{unanswerable set}. Maka, dapat disimpulkan bahwa, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} tidak dapat membantu meningkatkan performa terhadap jenis-jenis pertanyaan \emph{unanswerable} pada suatu \emph{dataset} sistem tanya jawab. Hasil \emph{dataset} TyDI-QA-ID selalu nol, karena pada \emph{dataset} TyDI-QA-ID tidak terdapat \emph{unanswerable set}. Kemudian, pada sub-bab selanjutnya akan dijelaskan mengenai perincian karakteristik pasangan konteks-pertanyaan-jawaban yang mengalami peningkatan atau penurunan performa setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}.

%-----------------------------------------------------------------------------%
\subsection{\emph{Question Type}}
%-----------------------------------------------------------------------------%
\begin{table}[H]\centering
\scriptsize
\begin{tabular}{lrrrrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode} &\multicolumn{8}{c}{TyDI-QA-ID} \\\cmidrule{3-10}
& &Apa &Dimana &Kapan &Siapa &Bagaimana &Kenapa &Berapa &Lainnya \\\midrule
IndoBERT-base &Baseline &\underline{47.51} &\underline{29.41} &\underline{65.44} &\underline{54.39} &0.0 &0.00 &\underline{69.47} &\underline{45.99} \\
IndoBERT-base &Entailment Only &23.59 &2.94 &29.41 &7.02 &0.0 &0.00 &32.82 &17.11 \\
IndoBERT-base &Entailment or Neutral &23.26 &2.94 &31.62 &5.26 &0.0 &0.00 &32.06 &17.11 \\
\hline
IndoBERT-large &Baseline &\underline{51.16} &32.35 &\underline{67.65} &\underline{56.14} &20.0 &0.00 &\underline{66.41} &\underline{51.34} \\
IndoBERT-large &Entailment Only &48.17 &32.35 &62.50 &43.86 &20.0 &0.00 &62.60 &43.32 \\
IndoBERT-large &Entailment or Neutral &48.84 &32.35 &63.97 &50.88 &20.0 &0.00 &62.60 &47.06 \\
\hline
XLMR-large &Baseline &\underline{60.13} &\underline{44.12} &\underline{78.68} &\underline{66.67} &20.0 &33.33 &\underline{80.15} &\underline{64.71} \\
XLMR-large &Entailment Only &55.15 &41.18 &71.32 &47.37 &\underline{40.0} &33.33 &77.10 &52.94 \\
XLMR-large &Entailment or Neutral &56.48 &41.18 &72.79 &56.14 &\underline{40.0} &33.33 &77.10 &56.68 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis \emph{question type} pada metode \emph{task recasting} sebagai verifikator parameter tipe \emph{filtering} pada \emph{dataset} TyDI-QA-ID.}
\end{table}

Pada sub-bab ini, penulis mencontohkan untuk \emph{dataset} TyDI-QA-ID, karena \emph{dataset} ini memberikan contoh yang penulis rasa lebih menarik, untuk kedua \emph{dataset} lainnya, penulis letakkan di bagian Lampiran \ref{Lampiran Terkait Tabel: 7.3}. Pada model \texttt{IndoBERT-base}, tipe pertanyaan bagaimana naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan tipe pertanyaan apa, dimana, kapan, siapa, berapa, dan lainnya selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian tipe pertanyaan lainnya, dimana penurunannya paling banyak sekitar 28.88\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada tipe pertanyaan yang naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, namun, sebaran nilai kenaikan tipe pertanyaan lebih banyak dibandingkan model \emph{IndoBERT-base}, yaitu tipe pertanyaan kapan, bagaimana, kenapa, dan lainnya setidaknya naik pada satu dari tiga \emph{dataset} yang sedang diuji. Tipe pertanyaan apa, dimana, siapa, dan berapa selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, tipe pertanyaan bagaimana naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan tipe pertanyaan apa, dimana, kapan, siapa, berapa, dan lainnya selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} tidak berhasil menjawab lebih banyak benarnya pada semua tipe pertanyaan dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk tipe pertanyaan apa, dimana, siapa, dan berapa selalu turun pada setiap model yang diuji. Selain tipe pertanyaan di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{Panjang Konteks}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang konteks pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Catatan: arti dari $\leq$100 adalah panjang konteks di bawah 100, dan arti dari $\leq$150 adalah panjang konteks di antara 101 sampai 150 (101$-$150).

\begin{table}[H]\centering
\footnotesize
\begin{tabular}{lrrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode atau Parameter} &\multicolumn{2}{c}{SQuAD-ID} &\multicolumn{2}{c}{TyDI-QA-ID} &\multicolumn{2}{c}{IDK-MRC} \\\cmidrule{3-8}
& &$\leq$100 &$\leq$150 &$\leq$100 &$\leq$150 &$\leq$100 &$\leq$150 \\\midrule
IndoBERT-base &Baseline &\underline{45.03} &\underline{45.07} &\underline{57.82} &\underline{40.89} &\underline{68.94} &\underline{62.60} \\
IndoBERT-base &Entailment Only &34.14 &33.06 &25.00 &16.36 &64.51 &60.31 \\
IndoBERT-base &Entailment or Neutral &42.22 &40.86 &25.17 &15.99 &65.53 &58.02 \\
\hline
IndoBERT-large &Baseline &\underline{45.40} &\underline{43.96} &\underline{60.24} &\underline{43.98} &56.95 &\underline{47.29} \\
IndoBERT-large &Entailment Only &33.76 &33.02 &54.31 &40.98 &\underline{61.02} &43.41 \\
IndoBERT-large &Entailment or Neutral &41.83 &40.96 &56.01 &42.86 &58.31 &43.02 \\
\hline
XLMR-large &Baseline &\underline{49.83} &\underline{49.92} &\underline{69.29} &\underline{57.14} &\underline{79.79} &\underline{71.79} \\
XLMR-large &Entailment Only &37.64 &37.45 &60.97 &53.57 &69.98 &60.00 \\
XLMR-large &Entailment or Neutral &46.46 &46.25 &63.24 &55.10 &73.97 &67.69 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang konteks pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang konteks $\leq100$ dan 101$-$150 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian panjang konteks $\leq100$, dimana penurunannya paling banyak sekitar 32.82\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada panjang konteks yang naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, namun, sebaran nilai kenaikan panjang konteks lebih banyak dibandingkan model \emph{IndoBERT-base}, yaitu panjang konteks  $\leq100$ setidaknya naik pada satu dari tiga \emph{dataset} yang sedang diuji. Panjang konteks  101$-$150 selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, panjang konteks $\leq100$ dan 101$-$150 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} tidak berhasil menjawab lebih banyak benarnya pada semua panjang konteks dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk panjang konteks 101$-$150 selalu turun pada setiap model yang diuji. Selain panjang konteks di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{Panjang Pertanyaan}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang pertanyaan pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Catatan: arti dari $\leq$5 adalah panjang pertanyaan di bawah 5, dan arti dari $\leq$10 adalah panjang pertanyaan di antara 6 sampai 10 (6$-$10).

\begin{table}[H]\centering
\small
\begin{tabular}{lrrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode atau Parameter} &\multicolumn{2}{c}{SQuAD-ID} &\multicolumn{2}{c}{TyDI-QA-ID} &\multicolumn{2}{c}{IDK-MRC} \\\cmidrule{3-8}
& &$\leq$5 &$\leq$10 &$\leq$5 &$\leq$10 &$\leq$5 &$\leq$10 \\\midrule
IndoBERT-base &Baseline &\underline{43.89} &\underline{45.21} &\underline{56.70} &\underline{44.92} &\underline{64.45} &\underline{69.15} \\
IndoBERT-base &Entailment Only &34.28 &33.38 &26.99 &13.77 &61.38 &64.77 \\
IndoBERT-base &Entailment or Neutral &41.41 &41.39 &26.81 & 14.10&60.87 &65.21 \\
\hline
IndoBERT-large &Baseline &\underline{43.23} &\underline{44.71} &\underline{61.05} &\underline{44.59} &\underline{58.31} &50.33 \\
IndoBERT-large &Entailment Only &33.57 &33.28 &55.80 &40.00 &57.80 &\underline{53.83} \\
IndoBERT-large &Entailment or Neutral &40.62 &41.40 &58.15 &40.66 &\underline{58.31} &49.67 \\
\hline
XLMR-large &Baseline &\underline{48.27} &\underline{50.11} &\underline{68.94} &\underline{62.00} &\underline{77.59} &\underline{78.28} \\
XLMR-large &Entailment Only &37.97 &37.48 &62.30 &53.67 &68.23 &67.19 \\
XLMR-large &Entailment or Neutral &45.68 &46.45 &64.63 &55.33 &74.14 &71.04 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang pertanyaan pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang pertanyaan $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian panjang pertanyaan 6$-$10, dimana penurunannya paling banyak sekitar 31.15\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada panjang pertanyaan yang naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, namun, sebaran nilai kenaikan panjang pertanyaan lebih banyak dibandingkan model \emph{IndoBERT-base}, yaitu panjang pertanyaan  6$-$10 setidaknya naik pada satu dari tiga \emph{dataset} yang sedang diuji. Panjang konteks  $\leq$5 selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, panjang pertanyaan $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} tidak berhasil menjawab lebih banyak benarnya pada semua panjang pertanyaan dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk panjang pertanyaan $\leq$5 selalu turun pada setiap model yang diuji. Selain panjang pertanyaan di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{Panjang Jawaban \emph{Golden Truth}}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang jawaban \emph{golden truth} pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Catatan: arti dari $\leq$5 adalah panjang jawaban \emph{golden truth} di bawah 5, dan arti dari $\leq$10 adalah panjang jawaban \emph{golden truth} di antara 6 sampai 10 (6$-$10).

\begin{table}[H]\centering
\small
\begin{tabular}{lrrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode atau Parameter} &\multicolumn{2}{c}{SQuAD-ID} &\multicolumn{2}{c}{TyDI-QA-ID} &\multicolumn{2}{c}{IDK-MRC} \\\cmidrule{3-8}
& &$\leq$5 &$\leq$10 &$\leq$5 &$\leq$10 &$\leq$5 &$\leq$10 \\\midrule
IndoBERT-base &Baseline &\underline{48.85} &\underline{22.37} &\underline{57.49} &\underline{39.92} &\underline{71.51} &\underline{38.98} \\
IndoBERT-base &Entailment Only &36.41 &15.98 &20.68 &26.34 &67.67 &35.59 \\
IndoBERT-base &Entailment or Neutral &44.80 &21.02 &20.85 &25.93 &67.67 &35.59 \\
\hline
IndoBERT-large &Baseline &\underline{48.24} &\underline{22.24} &\underline{60.10} &\underline{42.80} &55.48 &\underline{44.92} \\
IndoBERT-large &Entailment Only &36.20 &15.94 &53.26 &42.39 &\underline{57.53} &44.07 \\
IndoBERT-large &Entailment or Neutral &44.58 &21.59 &55.70 &42.39 &55.21 &44.07 \\
\hline
XLMR-large &Baseline &\underline{52.89} &\underline{28.54} &\underline{70.29} &\underline{56.28} &\underline{82.15} &\underline{50.88} \\
XLMR-large &Entailment Only &39.89 &20.99 &61.50 &53.25 &70.57 &49.12 \\
XLMR-large &Entailment or Neutral &49.03 &27.46 &63.90 &54.55 &76.16 &49.12 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang jawaban \emph{golden truth} pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang jawaban \emph{golden truth} $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian panjang jawaban \emph{golden truth} $\leq$5, dimana penurunannya paling banyak sekitar 36.81\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada panjang jawaban \emph{golden truth} yang naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, namun, sebaran nilai kenaikan panjang jawaban \emph{golden truth} lebih banyak dibandingkan model \emph{IndoBERT-base}, yaitu panjang jawaban \emph{golden truth}  $\leq$5 setidaknya naik pada satu dari tiga \emph{dataset} yang sedang diuji. Panjang konteks  6$-$10 selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, panjang jawaban \emph{golden truth} $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} tidak berhasil menjawab lebih banyak benarnya pada semua panjang jawaban \emph{golden truth} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk panjang jawaban \emph{golden truth} 6$-$10 selalu turun pada setiap model yang diuji. Selain panjang jawaban \emph{golden truth} di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{\emph{Answer Type}}
%-----------------------------------------------------------------------------%
Tabel pada bagian ini, telah penulis sertakan pada Lampiran \ref{Lampiran Terkait Tabel: 7.3}. Pada model \texttt{IndoBERT-base}, tidak ada \emph{answer type} yang naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan \emph{answer type} \emph{organization}, \emph{location}, \emph{WoA}, dan \emph{ordinal} naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{answer type} selain yang disebutkan di atas selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat dilihat pada \emph{dataset} TyDI-QA-ID dengan parameter \emph{entailment only} pada \emph{answer type} \emph{ordinal}, persentase nilai benarnya turun sebesar 51.43\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada \emph{answer type} yang naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan \emph{answer type} \emph{facility}, \emph{organization}, \emph{date}, dan \emph{null} naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{answer type} selain yang disebutkan di atas selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Penurunan persentase nilai benar pada model ini cenderung tidak berubah secara signifikan, namun uniknya kenaikannya dalam kasus \emph{dataset} TyDI-QA-ID pada \emph{answer type} \emph{facility} persentase nilai benarnya naik sekitar 80.0\%.

Terakhir, pada model \texttt{xlm-roberta-large}, semua \emph{answer type} selain yang disebutkan di atas selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Penurunan persentase nilai benar pada model ini cenderung tidak berubah secara signifikan.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} tidak berhasil menjawab lebih banyak benarnya pada sebagian \emph{answer type} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk \emph{answer type} \emph{person}, \emph{norp}, \emph{gpe}, \emph{prod}, \emph{event}, \emph{law}, \emph{lang}, \emph{time}, \emph{percent}, \emph{money}, \emph{quantity}, \emph{cardinal}, dan \emph{reg} mengalami penurunan pada setiap model dan \emph{dataset}. Selain \emph{answer type} di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} cenderung tidak berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-base}. 

%-----------------------------------------------------------------------------%
\subsection{\emph{Reasoning Type}}
%-----------------------------------------------------------------------------%
\begin{table}[H]\centering
\begin{tabular}{lrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode} &\multicolumn{5}{c}{TyDI-QA-ID} \\\cmidrule{3-7}
& &WM &PP &SSR &MSR &AoI \\\midrule
IndoBERT-base &Baseline &\underline{66.67} &\underline{50.00} &\underline{58.82} &\underline{50.00} &\underline{40.0} \\
IndoBERT-base &Entailment Only &22.22 &25.00 &11.76 &13.64 &20.0 \\
IndoBERT-base &Entailment or Neutral &22.22 &25.00 &11.76 &18.18 &20.0 \\
\hline
IndoBERT-large &Baseline &\underline{55.56} &\underline{59.38} &\underline{47.06} &\underline{50.00} &\underline{65.0} \\
IndoBERT-large &Entailment Only &33.33 &53.12 &41.18 &40.91 &55.0 \\
IndoBERT-large &Entailment or Neutral &44.44 &53.12 &\underline{47.06} &\underline{50.00} &55.0 \\
\hline
XLMR-large &Baseline &\underline{88.89} &\underline{65.62} &\underline{58.82} &\underline{77.27} &\underline{65.0} \\
XLMR-large &Entailment Only &66.67 &53.12 &47.06 &72.73 &55.0 \\
XLMR-large &Entailment or Neutral &77.78 &59.38 &\underline{58.82} &\underline{77.27} &55.0 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis \emph{reasoning type} pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} \emph{dataset} pada TyDI-QA-ID.}
\end{table}

Pada sub-bab ini, penulis mencontohkan untuk \emph{dataset} TyDI-QA-ID, karena \emph{dataset} ini memberikan contoh yang penulis rasa lebih menarik, untuk kedua \emph{dataset} lainnya, penulis letakkan di bagian Lampiran \ref{Lampiran Terkait Tabel: 7.3}. Pada model \texttt{IndoBERT-base}, tidak ada \emph{reasoning type} yang naik persentase nilai benarnya pada semua \emph{dataset} yang penulis uji, lalu, \emph{reasoning type} SSR berhasil naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} WM, PP, MSR, dan AoI selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat dilihat pada \emph{dataset} TyDI-QA-ID  dengan parameter \emph{entailment only} di bagian \emph{reasoning type} MSR, persentase nilai benarnya turun sebesar 36.36\%.

Kemudian, pada model \texttt{IndoBERT-large}, \emph{reasoning type} PP naik persentase nilai benarnya pada semua \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} WM, SSR, MSR, dan AoI selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Terakhir, pada model \texttt{xlm-roberta-large}, tidak ada \emph{reasoning type} yang naik persentase nilai benarnya pada semua \emph{dataset} yang penulis uji, lalu, \emph{reasoning type} WM berhasil naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} PP, SSR, MSR, dan AoI selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering}. Penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} tidak berhasil menjawab lebih banyak benarnya pada sebagian \emph{reasoning type} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk \emph{reasoning type} MSR dan AoI selalu turun pada setiap model dan \emph{dataset} yang penulis uji. Selain tipe pertanyaan di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} cenderung tidak berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-base}.

%-----------------------------------------------------------------------------%
\section{Hasil dan Analisis Performa Metode \emph{Task Recasting} dengan IndoNLI Sebagai Verifikator Dengan Eksperimen Tipe Perubahan Format Kalimat.}
\label{5.5}
%-----------------------------------------------------------------------------%
Pada sub-bab ini, akan dijelaskan mengenai hasil dan analisis eksperimen metode \emph{task recasting} dengan IndoNLI sebagai verifikator dengan eksperimen tipe perubahan format kalimat yang penulis lakukan pada pada penelitian ini. Sebagai catatan, RB pada \texttt{Machine Generation With RB} artinya adalah \texttt{Rule Base}. Pada tabel di bawah ini, akan dipaparkan skor \emph{exact match} dan skor F1 pada metode \emph{task recasting} sebagai verifikator pada parameter tipe perubahan format kalimat.

\begin{table}[H]\centering
\scriptsize
\begin{tabular}{lrrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode atau Parameter} &\multicolumn{2}{c}{SQuAD-ID} &\multicolumn{2}{c}{TyDI-QA-ID} &\multicolumn{2}{c}{IDK-MRC} \\\cmidrule{3-8}
& &EM &F1 &EM &F1 &EM &F1 \\\midrule
IndoBERT-base &Baseline &\underline{44.66} &\underline{61.55} &\underline{52.51} &\underline{65.17} &\underline{66.63} &\underline{72.84} \\
IndoBERT-base &Replace First &41.09 &57.08 &22.17 &32.74 &65.57 &70.93 \\
IndoBERT-base &Replace Question Word &41.50 &57.57 &22.17 &32.72 &65.09 &70.46 \\
IndoBERT-base &Add Adalah &41.24 &57.55 &22.17 &33.50 &63.09 &68.62 \\
IndoBERT-base &Just Concat Answer and Question &39.91 &55.77 &21.94 &33.13 &65.21 &70.56 \\
IndoBERT-base &Rule Base &41.39 &57.68 &22.29 &32.86 &63.21 &68.67 \\
IndoBERT-base &Machine Generation With RB &40.44 &56.31 & 22.05 &33.68 &62.26 &67.98 \\
IndoBERT-base &Pure Machine Generation &39.87 &55.28 &22.75 &34.37 &64.62 &70.26 \\
IndoBERT-base &Machine Generation With Translation &34.61 &48.12 &20.42 &31.66 &63.44 &69.02 \\
\hline
IndoBERT-large &Baseline &\underline{43.82} &\underline{61.09} &\underline{55.08} &\underline{68.89} &53.89 &60.51 \\
IndoBERT-large &Replace First &41.00 &57.17 &52.28 &65.05 &51.42 &57.44 \\
IndoBERT-large &Replace Question Word &41.39 &57.66 &52.28 &65.17 &51.42 &57.48 \\
IndoBERT-large &Add Adalah &41.14 &57.59 &52.51 &65.71 &52.59 &59.21 \\
IndoBERT-large &Just Concat Answer and Question &39.78 &55.81 &51.81 &64.84 &\underline{54.48} &\underline{61.07} \\
IndoBERT-large &Rule Base &41.31 &57.70 &51.93 &65.04 &53.66 &59.98 \\
IndoBERT-large &Machine Generation With RB &40.07 &56.17 &52.04 &66.05 &44.93 &51.89 \\
IndoBERT-large &Pure Machine Generation &39.77 &55.62 &52.74 &66.31 &45.87 &53.02 \\
IndoBERT-large &Machine Generation With Translation &34.93 &48.93 &49.71 &63.12 &48.00 &54.53 \\
\hline
XLMR-large &Baseline &\underline{49.54} &\underline{66.69} &\underline{66.51} &\underline{78.27} &\underline{77.95} &\underline{84.64} \\
XLMR-large &Replace First &45.88 &62.12 &61.96 &72.51 &73.70 &80.45 \\
XLMR-large &Replace Question Word &46.16 &62.41 &61.84 &72.40 &73.58 &80.26 \\
XLMR-large &Add Adalah &46.20 &62.61 &62.31 &73.41 &70.99 &77.61 \\
XLMR-large &Just Concat Answer and Question &44.36 &60.48 &59.63 &70.76 &73.11 &79.35 \\
XLMR-large &Rule Base &46.36 &62.70 &61.38 &72.19 &72.52 &79.19 \\
XLMR-large &Machine Generation With RB &45.34 &61.42 &61.96 &73.78 &72.29 &79.07 \\
XLMR-large &Pure Machine Generation &45.33 &61.42 &63.24 &74.64 &74.17 &81.03 \\
XLMR-large &Machine Generation With Translation &40.05 &54.72 &59.28 &70.85 &72.17 &79.09 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang konteks pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat.}
\end{table}

Dapat dilihat pada tabel di atas, pada model \texttt{IndoBERT-base}, seluruh \emph{dataset} yang diuji memperlihatkan turunnya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{task recasting} sebagai verifikator pada semua parameter tipe perubahan format kalimat, penurunan skor \emph{exact match} dan skor F1 juga turun secara signifikan, dapat dilihat pada skor \emph{exact match} menurun hingga sekitar 30.34\% pada \emph{dataset} TyDI-QA-ID; kemudian, dapat dilihat bahwa, hasil skor keseluruhan model ini juga masih kurang baik, dapat dilihat pada skor F1 masih sekitar 20.42 hingga 70.93.

Kemudian, pada model \texttt{IndoBERT-large}, dapat dilihat tren yang lebih baik dari model \texttt{IndoBERT-base}, yaitu: ada satu dari tiga \emph{dataset} yang diuji memperlihatkan naiknya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{task recasting} sebagai verifikator pada parameter \emph{just concat answer and question}, yaitu pada \emph{dataset} IDK-MRC. Model \texttt{IndoBERT-large} secara kecenderungan memiliki skor \emph{exact match} dan skor F1 yang lebih tinggi dibandingkan model \texttt{IndoBERT-base}, dapat dilihat pada \emph{dataset} TyDI-QA-ID, hasil model \texttt{IndoBERT-large} lebih baik dengan dua parameter yang dipilih dibandingkan dengan model \texttt{IndoBERT-base} dan perubahan skor tersebut juga cenderung tidak terlalu signifikan.

Terakhir, pada model \texttt{xlm-roberta-large}, mengikuti tren pada model \texttt{IndoBERT-base}, yaitu: seluruh \emph{dataset} yang diuji memperlihatkan turunnya skor \emph{exact match} dan skor F1 dengan menggunakan metode \emph{task recasting} sebagai verifikator pada semua parameter tipe perubahan format kalimat, penurunan skor \emph{exact match} dan skor F1 juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara kecenderungan, parameter \emph{just concat answer and question} dan parameter \emph{pure machine generation} memiliki skor yang lebih tinggi dibandingkan dengan parameter lainnya. Maka, dapat disimpulkan, bahwa model terbaik untuk metode \emph{task recasting} sebagai verifikator adalah: model \texttt{xlm-roberta-large} dengan parameter \emph{just concat answer and question}, dengan skor \emph{exact match} dan skor F1 model dan metode tersebut setidaknya lebih baik dibandingkan model dan parameter lainnya. Namun, secara keseluruhan penggunaan metode \emph{task recasting} sebagai verifikator pada semua parameter tipe perubahan format kalimat, memberikan penurunan performa dari sistem tanya jawab yang sedang diuji. 

\begin{table}[H]\centering
\scriptsize
\begin{tabular}{lrrrrr}\toprule
Model &Parameter &SQuAD-ID &TyDI-QA-ID &IDK-MRC \\\midrule
IndoBERT-base &Baseline &0.09 &0.0 &\underline{0.86} \\
IndoBERT-base &Replace First &0.08 &0.0 &0.69 \\
IndoBERT-base &Replace Question Word &0.07 &0.0 &0.68 \\
IndoBERT-base &Add Adalah &0.08 &0.0 &0.60 \\
IndoBERT-base &Just Concat Answer and Question &0.07 &0.0 &0.68 \\
IndoBERT-base &Rule Base &0.07 &0.0 &0.60 \\
IndoBERT-base &Machine Generation With RB &0.10 &0.0 &0.66 \\
IndoBERT-base &Pure Machine Generation &0.10 &0.0 &0.79 \\
IndoBERT-base &Machine Generation With Translation &\underline{0.13} &0.0 &0.72 \\
\hline
IndoBERT-large &Baseline &0.13 &0.0 &\underline{0.54} \\
IndoBERT-large &Replace First &0.11 &0.0 &0.40 \\
IndoBERT-large &Replace Question Word &0.11 &0.0 &0.40 \\
IndoBERT-large &Add Adalah &0.11 &0.0 &0.35 \\
IndoBERT-large &Just Concat Answer and Question &0.10 &0.0 &0.41 \\
IndoBERT-large &Rule Base &0.09 &0.0 &0.36 \\
IndoBERT-large &Machine Generation With RB &0.13 &0.0 &0.34 \\
IndoBERT-large &Pure Machine Generation &0.13 &0.0 &0.39 \\
IndoBERT-large &Machine Generation With Translation &\underline{0.18} &0.0 &0.42 \\
\hline
XLMR-large &Baseline &0.10 &0.0 &\underline{0.92} \\
XLMR-large &Replace First &0.08 &0.0 &0.72 \\
XLMR-large &Replace Question Word &0.08 &0.0 &0.71 \\
XLMR-large &Add Adalah &0.08 &0.0 &0.64 \\
XLMR-large &Just Concat Answer and Question &0.08 &0.0 &0.71 \\
XLMR-large &Rule Base &0.06 &0.0 &0.63 \\
XLMR-large &Machine Generation With RB &0.11 &0.0 &0.74 \\
XLMR-large &Pure Machine Generation &0.12 &0.0 &0.85 \\
XLMR-large &Machine Generation With Translation &\underline{0.16} &0.0 &0.77 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan skor \emph{exact match} dengan metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat pada \emph{unanswerable set}.}
\end{table}

Dapat dilihat pada contoh tabel di atas, terlihat bahwa pada \emph{dataset} SQuAD-ID setiap modelnya, parameter \emph{machine generation with translation} selalu lebih unggul dibandingkan parameter lainnya. Sedangkan pada \emph{dataset} IDK-MRC setiap modelnya, hasil \emph{baseline} selalu lebih unggul dibandingkan parameter lainnya. Maka, dapat disimpulkan bahwa, metode \emph{task recasting} sebagai verifikator dengan parameter tipe \emph{filtering} belum tentu dapat membantu meningkatkan performa terhadap jenis-jenis pertanyaan \emph{unanswerable} pada suatu \emph{dataset} sistem tanya jawab. Hasil \emph{dataset} TyDI-QA-ID selalu nol, karena pada \emph{dataset} TyDI-QA-ID tidak terdapat \emph{unanswerable set}. Kemudian, pada sub-bab selanjutnya akan dijelaskan mengenai perincian karakteristik pasangan konteks-pertanyaan-jawaban yang mengalami peningkatan atau penurunan performa setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat.

%-----------------------------------------------------------------------------%
\subsection{\emph{Question Type}}
%-----------------------------------------------------------------------------%
\begin{table}[H]\centering
\tiny
\begin{tabular}{lrrrrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode} &\multicolumn{8}{c}{TyDI-QA-ID} \\\cmidrule{3-10}
& &Apa &Dimana &Kapan &Siapa &Bagaimana &Kenapa &Berapa &Lainnya \\\midrule
IndoBERT-base &Baseline &\underline{47.51} &\underline{29.41} &\underline{65.44} &\underline{54.39} &0.0 &0.00 &\underline{69.47} &\underline{45.99} \\
IndoBERT-base &Replace First &22.92 &2.94 &33.09 &3.51 &0.0 &0.00 &31.30 &17.11 \\
IndoBERT-base &Replace Question Word &22.92 &2.94 &33.09 &3.51 &0.0 &0.00 &31.30 &17.11 \\
IndoBERT-base &Add Adalah &23.26 &2.94 &32.35 &3.51 &0.0 &0.00 &32.06 &16.58 \\
IndoBERT-base &Just Concat Answer and Question &22.92 &2.94 &30.88 &3.51 &0.0 &0.00 &32.82 &16.58 \\
IndoBERT-base &Rule Base &23.26 &2.94 &31.62 &5.26 &0.0 &0.00 &32.06 &17.11 \\
IndoBERT-base &Machine Generation With RB &21.26 &2.94 &32.35 &3.51 &0.0 &0.00 &34.35 &17.65 \\
IndoBERT-base &Pure Machine Generation &22.26 &2.94 &32.35 &3.51 &0.0 &0.00 &35.11 &18.72 \\
IndoBERT-base &Machine Generation With Translation &21.59 &5.88 &27.94 &3.51 &0.0 &0.00 &28.24 &16.58 \\
\hline
IndoBERT-large &Baseline &\underline{51.16} &\underline{32.35} &\underline{67.65} &\underline{56.14} &20.0 &0.00 &\underline{66.41} &\underline{51.34} \\
IndoBERT-large &Replace First &48.50 &\underline{32.35} &66.91 &50.88 &20.0 &0.00 &62.60 &47.06 \\
IndoBERT-large &Replace Question Word &48.50 &\underline{32.35} &66.91 &50.88 &20.0 &0.00 &62.60 &47.06 \\
IndoBERT-large &Add Adalah &49.17 &\underline{32.35} &64.71 &52.63 &20.0 &0.00 &62.60 &48.13 \\
IndoBERT-large &Just Concat Answer and Question &48.84 &\underline{32.35} &62.50 &50.88 &20.0 &0.00 &63.36 &47.06 \\
IndoBERT-large &Rule Base &48.84 &\underline{32.35} &63.97 &50.88 &20.0 &0.00 &62.60 &47.06 \\
IndoBERT-large &Machine Generation With RB &46.18 &29.41 &66.91 &52.63 &20.0 &\underline{16.67} &64.12 &48.13 \\
IndoBERT-large &Pure Machine Generation &48.17 &\underline{32.35} &65.44 &54.39 &20.0 &0.00 &63.36 &49.20 \\
IndoBERT-large &Machine Generation With Translation &48.50 &29.41 &57.35 &50.88 &20.0 &\underline{16.67} &57.25 &45.99 \\
\hline
XLMR-large &Baseline &\underline{60.13} &\underline{44.12} &\underline{78.68} &\underline{66.67} &20.0 &\underline{33.33} &\underline{80.15} &\underline{64.71} \\
XLMR-large &Replace First &55.48 &41.18 &77.94 &56.14 &20.0 &\underline{33.33} &76.34 &58.29 \\
XLMR-large &Replace Question Word &55.48 &41.18 &77.94 &56.14 &20.0 &\underline{33.33} &76.34 &57.75 \\
XLMR-large &Add Adalah &56.81 &\underline{44.12} &75.00 &61.40 &\underline{40.0} &16.67 &75.57 &58.29 \\
XLMR-large &Just Concat Answer and Question &54.49 &38.24 &72.06 &54.39 &\underline{40.0} &16.67 &76.34 &54.55 \\
XLMR-large &Rule Base &56.48 &41.18 &72.79 &56.14 &\underline{40.0} &\underline{33.33} &77.10 &56.68 \\
XLMR-large &Machine Generation With RB &54.49 &41.18 &77.21 &56.14 &20.0 &\underline{33.33} &77.86 &59.36 \\
XLMR-large &Pure Machine Generation &55.48 &\underline{44.12} &75.74 &64.91 &20.0 &16.67 &77.10 &62.57 \\
XLMR-large &Machine Generation With Translation &54.82 &\underline{44.12} &66.91 &59.65 &20.0 &16.67 &71.76 &57.22 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis \emph{question type} pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat pada \emph{dataset} TyDI-QA-ID.}
\end{table}

Pada sub-bab ini, penulis mencontohkan untuk \emph{dataset} TyDI-QA-ID, karena \emph{dataset} ini memberikan contoh yang penulis rasa lebih menarik, untuk kedua \emph{dataset} lainnya, penulis letakkan di bagian Lampiran \ref{Lampiran Terkait Tabel: 7.3}. Pada model \texttt{IndoBERT-base}, tipe pertanyaan bagaimana naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, sedangkan tipe pertanyaan apa, kapan, siapa, berapa, dan lainnya selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian tipe pertanyaan siapa, dimana penurunannya paling banyak sekitar 50.88\%.

Kemudian, pada model \texttt{IndoBERT-large}, tipe pertanyaan kenapa naik persentase nilai benarnya pada tiga dari tiga \emph{dataset} yang penulis uji, dan tipe pertanyaan bagaimana naik pada dua dari tiga \emph{dataset} yang sedang diuji. Tipe pertanyaan siapa dan berapa selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, tipe pertanyaan bagaimana dan kenapa naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan tipe pertanyaan apa, dimana, kapan, siapa, berapa, dan lainnya selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator. Kenaikan dan/atau penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat tidak berhasil menjawab lebih banyak benarnya pada semua tipe pertanyaan dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk tipe pertanyaan siapa dan berapa selalu turun pada setiap model yang diuji. Selain tipe pertanyaan di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{Panjang Konteks}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang konteks pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Catatan: arti dari $\leq$100 adalah panjang konteks di bawah 100, dan arti dari $\leq$150 adalah panjang konteks di antara 101 sampai 150 (101$-$150).

\begin{table}[H]\centering
\scriptsize
\begin{tabular}{lrrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode atau Parameter} &\multicolumn{2}{c}{SQuAD-ID} &\multicolumn{2}{c}{TyDI-QA-ID} &\multicolumn{2}{c}{IDK-MRC} \\\cmidrule{3-8}
& &$\leq$100 &$\leq$150 &$\leq$100 &$\leq$150 &$\leq$100 &$\leq$150 \\\midrule
IndoBERT-base &Baseline &\underline{45.03} &\underline{45.07} &\underline{57.82} &\underline{40.89} &\underline{68.94} &\underline{62.60} \\
IndoBERT-base &Replace First &41.92 &40.56 &25.34 &15.24 &68.43 &59.16 \\
IndoBERT-base &Replace Question Word &42.17 &41.07 &25.34 &15.24 &67.92 &58.78 \\
IndoBERT-base &Add Adalah &42.37 &40.52 &25.17 &15.61 &64.85 &59.16 \\
IndoBERT-base &Just Concat Answer and Question &41.54 &38.86 &25.00 &15.24 &68.26 &58.40 \\
IndoBERT-base &Rule Base &42.22 &40.86 &25.17 &15.99 &65.53 &58.02 \\
IndoBERT-base &Machine Generation With RB &41.60 &39.69 &25.17 &15.24 &63.99 &58.40 \\
IndoBERT-base &Pure Machine Generation &41.54 &38.79 &26.19 &15.24 &66.55 &60.31 \\
IndoBERT-base &Machine Generation With Translation &37.29 &32.87 &24.15 &12.27 &65.53 &58.78 \\
\hline
IndoBERT-large &Baseline &\underline{45.40} &\underline{43.96} &\underline{60.24} &\underline{43.98} &56.95 &\underline{47.29} \\
IndoBERT-large &Replace First &41.98 &40.34 &57.36 &40.98 &56.10 &40.70 \\
IndoBERT-large &Replace Question Word &42.08 &40.93 &57.36 &40.98 &55.93 &41.09 \\
IndoBERT-large &Add Adalah &41.90 &40.64 &57.02 &42.48 &56.95 &42.64 \\
IndoBERT-large &Just Concat Answer and Question &40.99 &38.98 &57.19 &39.85 &59.49 &43.02 \\
IndoBERT-large &Rule Base &41.83 &40.96 &56.01 &42.86 &\underline{58.31} &43.02 \\
IndoBERT-large &Machine Generation With RB &41.20 &39.31 &56.68 &41.73 &47.63 &38.76 \\
IndoBERT-large &Pure Machine Generation &41.46 &38.65 &58.04 &40.98 &48.81 &39.15 \\
IndoBERT-large &Machine Generation With Translation &37.39 &33.30 &55.16 &37.59 &51.02 &41.09 \\
\hline
XLMR-large &Baseline &\underline{49.83} &\underline{49.92} &\underline{69.29} &\underline{57.14} &\underline{79.79} &\underline{71.79} \\
XLMR-large &Replace First &45.94 &45.82 &64.30 &54.08 &75.34 &68.21 \\
XLMR-large &Replace Question Word &45.90 &46.41 &64.30 &53.57 &75.19 &68.21 \\
XLMR-large &Add Adalah &46.48 &45.94 &64.90 &53.57 &72.43 &66.15 \\
XLMR-large &Just Concat Answer and Question &45.15 &43.59 &62.33 &50.51 &75.96 &63.59 \\
XLMR-large &Rule Base &46.46 &46.25 &63.24 &55.10 &73.97 &67.69 \\
XLMR-large &Machine Generation With RB &46.07 &44.62 &65.05 &51.53 &73.81 &67.18 \\
XLMR-large &Pure Machine Generation &46.02 &44.65 &66.41 &52.55 &75.96 &68.21 \\
XLMR-large &Machine Generation With Translation &41.02 &39.11 &62.63 &47.96 &73.81 &66.67 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang konteks pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang konteks $\leq100$ dan 101$-$150 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian panjang konteks $\leq100$, dimana penurunannya paling banyak sekitar 33.67\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada panjang konteks yang naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, namun, sebaran nilai kenaikan panjang konteks lebih banyak dibandingkan model \emph{IndoBERT-base}, yaitu panjang konteks  $\leq100$ setidaknya naik pada satu dari tiga \emph{dataset} yang sedang diuji. Panjang konteks  101$-$150 selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, panjang konteks $\leq100$ dan 101$-$150 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat tidak berhasil menjawab lebih banyak benarnya pada semua panjang konteks dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk panjang konteks 101$-$150 selalu turun pada setiap model yang diuji. Selain panjang konteks di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{Panjang Pertanyaan}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang pertanyaan pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Catatan: arti dari $\leq$5 adalah panjang pertanyaan di bawah 5, dan arti dari $\leq$10 adalah panjang pertanyaan di antara 6 sampai 10 (6$-$10).

\begin{table}[H]\centering
\scriptsize
\begin{tabular}{lrrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode atau Parameter} &\multicolumn{2}{c}{SQuAD-ID} &\multicolumn{2}{c}{TyDI-QA-ID} &\multicolumn{2}{c}{IDK-MRC} \\\cmidrule{3-8}
& &$\leq$5 &$\leq$10 &$\leq$5 &$\leq$10 &$\leq$5 &$\leq$10 \\\midrule
IndoBERT-base &Baseline &\underline{43.89} &\underline{45.21} &\underline{56.70} &\underline{44.92} &\underline{64.45} &\underline{69.15} \\
IndoBERT-base &Replace First &41.48 &41.04 &26.99 &13.44 &61.89 &68.71 \\
IndoBERT-base &Replace Question Word &41.41 &41.52 &26.99 &13.44 &61.64 &68.05 \\
IndoBERT-base &Add Adalah &41.70 &41.18 &26.63 &14.10 &60.36 &65.43 \\
IndoBERT-base &Just Concat Answer and Question &39.58 &39.96 &26.63 &13.44 &62.66 &67.40 \\
IndoBERT-base &Rule Base &41.41 &41.39 &26.81 &14.10 &60.87 &65.21 \\
IndoBERT-base &Machine Generation With RB &39.72 &40.54 &26.45 &14.10 &61.64 &62.80 \\
IndoBERT-base &Pure Machine Generation &40.07 &39.84 &27.72 &13.77 &62.92 &66.08 \\
IndoBERT-base &Machine Generation With Translation &36.61 &34.34 &24.64 &12.79 &59.34 &66.96 \\
\hline
IndoBERT-large &Baseline &\underline{43.23} &\underline{44.71} &\underline{61.05} &\underline{44.59} &\underline{58.31} &50.33 \\
IndoBERT-large &Replace First &41.04 &40.99 &58.70 &40.66 &57.03 &46.61 \\
IndoBERT-large &Replace Question Word &40.97 &41.45 &58.70 &40.66 &57.03 &46.61 \\
IndoBERT-large &Add Adalah &40.90 &41.17 &58.70 &41.31 &56.52 &49.23 \\
IndoBERT-large &Just Concat Answer and Question &39.21 &39.86 &58.15 &40.33 &57.80 &\underline{51.64} \\
IndoBERT-large &Rule Base &40.62 &41.40 &58.15 &40.66 &\underline{58.31} &49.67 \\
IndoBERT-large &Machine Generation With RB &40.06 &40.07 &57.97 &41.31 &52.43 &38.51 \\
IndoBERT-large &Pure Machine Generation &39.49 &39.81 &58.70 &41.97 &52.43 &40.26 \\
IndoBERT-large &Machine Generation With Translation &36.81 &34.68 &54.35 &41.31 &50.90 &45.51 \\
\hline
XLMR-large &Baseline &\underline{48.27} &\underline{50.11} &\underline{68.94} &\underline{62.00} &\underline{77.59} &\underline{78.28} \\
XLMR-large &Replace First &45.41 &45.95 &65.17 &56.00 &74.38 &73.08 \\
XLMR-large &Replace Question Word &45.08 &46.32 &65.17 &55.67 &74.38 &72.85 \\
XLMR-large &Add Adalah &45.41 &46.32 &65.89 &55.67 &72.66 &69.46 \\
XLMR-large &Just Concat Answer and Question &42.95 &44.56 &62.84 &53.67 &72.91 &73.30 \\
XLMR-large &Rule Base &45.68 &46.45 &64.63 &55.33 &74.14 &71.04 \\
XLMR-large &Machine Generation With RB &44.68 &45.43 &65.71 &55.00 &72.91 &71.72 \\
XLMR-large &Pure Machine Generation &44.48 &45.45 &66.79 &56.67 &74.14 &74.21 \\
XLMR-large &Machine Generation With Translation &42.29 &39.73 &60.68 &56.67 &70.44 &73.76 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang pertanyaan pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang pertanyaan $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian panjang pertanyaan $\leq$5, dimana penurunannya paling banyak sekitar 30.06\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada panjang pertanyaan yang naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji, namun, sebaran nilai kenaikan panjang pertanyaan lebih banyak dibandingkan model \emph{IndoBERT-base}, yaitu panjang pertanyaan 6$-$10 setidaknya naik pada satu dari tiga \emph{dataset} yang sedang diuji. Panjang konteks  $\leq$5 selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, panjang pertanyaan $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat tidak berhasil menjawab lebih banyak benarnya pada semua panjang pertanyaan dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk panjang pertanyaan $\leq$5 selalu turun pada setiap model yang diuji. Selain panjang pertanyaan di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{Panjang Jawaban \emph{Golden Truth}}
%-----------------------------------------------------------------------------%
Berikut tabel perbandingan persentase nilai benar dengan basis panjang jawaban \emph{golden truth} pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Catatan: arti dari $\leq$5 adalah panjang jawaban \emph{golden truth} di bawah 5, dan arti dari $\leq$10 adalah panjang jawaban \emph{golden truth} di antara 6 sampai 10 (6$-$10).

\begin{table}[H]\centering
\scriptsize
\begin{tabular}{lrrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode atau Parameter} &\multicolumn{2}{c}{SQuAD-ID} &\multicolumn{2}{c}{TyDI-QA-ID} &\multicolumn{2}{c}{IDK-MRC} \\\cmidrule{3-8}
& &$\leq$5 &$\leq$10 &$\leq$5 &$\leq$10 &$\leq$5 &$\leq$10 \\\midrule
IndoBERT-base &Baseline &\underline{48.85} &\underline{22.37} &\underline{57.49} &\underline{39.92} &\underline{71.51} &\underline{38.98} \\
IndoBERT-base &Replace First &44.57 &20.26 &21.01 &25.10 &70.41 &35.59 \\
IndoBERT-base &Replace Question Word &45.00 &20.55 &21.01 &25.10 &69.86 &35.59 \\
IndoBERT-base &Add Adalah &44.63 &20.96 &20.68 &25.93 &67.40 &36.44 \\
IndoBERT-base &Just Concat Answer and Question &43.19 &20.26 &20.36 &25.93 &69.86 &36.44 \\
IndoBERT-base &Rule Base &44.80 &21.02 &20.85 &25.93 &67.67 &35.59 \\
IndoBERT-base &Machine Generation With RB &44.01 &19.09 &21.34 &23.87 &66.30 &37.29 \\
IndoBERT-base &Pure Machine Generation &43.44 &18.50 &21.66 &25.51 &69.32 &35.59 \\
IndoBERT-base &Machine Generation With Translation &37.89 &14.93 &19.06 &23.87 &68.22 &33.90 \\
\hline
IndoBERT-large &Baseline &\underline{48.24} &\underline{22.24} &\underline{60.10} &\underline{42.80} &55.48 &44.92 \\
IndoBERT-large &Replace First &44.33 &20.94 &56.51 &41.56 &52.74 &43.22 \\
IndoBERT-large &Replace Question Word &44.74 &21.24 &56.51 &41.56 &52.74 &43.22 \\
IndoBERT-large &Add Adalah &44.39 &21.59 &56.35 &\underline{42.80} &53.84 &44.92 \\
IndoBERT-large &Just Concat Answer and Question &42.86 &21.24 &55.21 &43.21 &\underline{55.89} &\underline{45.76} \\
IndoBERT-large &Rule Base &44.58 &21.59 &55.70 &42.39 &55.21 &44.07 \\
IndoBERT-large &Machine Generation With RB &43.47 &19.59 &56.35 &41.15 &45.07 &44.07 \\
IndoBERT-large &Pure Machine Generation &43.20 &19.12 &57.17 &41.56 &46.30 &43.22 \\
IndoBERT-large &Machine Generation With Translation &38.06 &16.12 &53.91 &39.09 &48.90 &42.37 \\
\hline
XLMR-large &Baseline &52.89 &\underline{28.54} &\underline{70.29} &\underline{56.28} &\underline{82.15} &\underline{50.88} \\
XLMR-large &Replace First &48.65 &26.32 &65.50 &52.38 &77.66 &48.25 \\
XLMR-large &Replace Question Word &48.89 &26.86 &65.34 &52.38 &77.52 &48.25 \\
XLMR-large &Add Adalah &48.86 &27.40 &65.02 &54.98 &74.25 &50.00 \\
XLMR-large &Just Concat Answer and Question &46.79 &27.13 &61.50 &54.55 &76.70 &50.00 \\
XLMR-large &Rule Base &49.03 &27.46 &63.90 &54.55 &76.16 &49.12 \\
XLMR-large &Machine Generation With RB &48.12 &25.64 &65.97 &51.08 &76.16 &47.37 \\
XLMR-large &Pure Machine Generation &48.05 &26.05 &67.25 &52.38 &78.07 &49.12 \\
XLMR-large &Machine Generation With Translation &42.84 &20.31 &63.10 &48.92 &75.75 &49.12 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis panjang jawaban \emph{golden truth} pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat.}
\end{table}

Pada model \texttt{IndoBERT-base}, panjang jawaban \emph{golden truth} $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat terlihat pada \emph{dataset} TyDI-QA-ID bagian panjang jawaban \emph{golden truth} $\leq$5, dimana penurunannya paling banyak sekitar 38.43\%.

Kemudian, pada model \texttt{IndoBERT-large}, panjang jawaban \emph{golden truth} 6$-$10 naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang penulis uji. Panjang konteks  6$-$10 selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator.

Terakhir, pada model \texttt{xlm-roberta-large}, mirip dengan model \emph{IndoBERT-base}, panjang jawaban \emph{golden truth} $\leq$5 dan 6$-$10 turun persentase nilai benarnya pada semua \emph{dataset} yang penulis uji. Penurunan persentase nilai benar juga turun secara signifikan; walaupun penurunan skornya tidak se-signifikan model \texttt{IndoBERT-base}.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat tidak berhasil menjawab lebih banyak benarnya pada semua panjang jawaban \emph{golden truth} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk panjang jawaban \emph{golden truth} $\leq$5 selalu turun pada setiap model yang diuji. Selain panjang jawaban \emph{golden truth} di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat cenderung masih belum berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan.

%-----------------------------------------------------------------------------%
\subsection{\emph{Answer Type}}
%-----------------------------------------------------------------------------%
Tabel pada bagian ini, telah penulis sertakan pada Lampiran \ref{Lampiran Terkait Tabel: 7.3}. Pada model \texttt{IndoBERT-base}, tidak ada \emph{answer type} yang naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, sedangkan \emph{answer type} \emph{facility}, \emph{organization}, \emph{location}, \emph{WoA}, \emph{ordinal}, dan \emph{cardinal} naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{answer type} selain yang disebutkan di atas selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat dilihat pada \emph{dataset} TyDI-QA-ID dengan parameter \emph{replace first} pada \emph{answer type} \emph{language}, persentase nilai benarnya turun sebesar 66.67\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada \emph{answer type} yang naik persentase nilai benarnya pada ketiga \emph{dataset} sistem tanya jawab yang penulis uji, namun \emph{answer type} \emph{date} naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang diuji, sedangkan \emph{answer type} \emph{facility}, \emph{organization}, \emph{event}, \emph{language}, \emph{date}, \emph{cardinal}, \emph{reg}, dan \emph{null} naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{answer type} selain yang disebutkan di atas selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Penurunan persentase nilai benar pada model ini cenderung tidak berubah secara signifikan.

Terakhir, pada model \texttt{xlm-roberta-large}, \emph{answer type} \emph{woa} naik persentase nilai benarnya pada dua dari tiga \emph{dataset} yang diuji, sedangkan semua \emph{answer type} selain yang disebutkan di atas selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Penurunan persentase nilai benar pada model ini cenderung tidak berubah secara signifikan, kecuali pada beberapa kasus khusus, seperti pada \emph{dataset} IDK-MRC bagian \emph{answer type} {language}, persentase nilai benarnya turun sebesar 50\%.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat tidak berhasil menjawab lebih banyak benarnya pada sebagian \emph{answer type} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, untuk \emph{answer type} \emph{person}, \emph{norp}, \emph{gpe}, \emph{product}, \emph{time}, \emph{percent}, \emph{money}, dan \emph{quantity} mengalami penurunan pada setiap model dan \emph{dataset}. Selain \emph{answer type} di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat cenderung tidak berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-base}. 

%-----------------------------------------------------------------------------%
\subsection{\emph{Reasoning Type}}
%-----------------------------------------------------------------------------%
\begin{table}[H]\centering
\footnotesize
\begin{tabular}{lrrrrrrr}\toprule
\multirow{2}{*}{Model} &\multirow{2}{*}{Metode} &\multicolumn{5}{c}{TyDI-QA-ID} \\\cmidrule{3-7}
& &WM &PP &SSR &MSR &AoI \\\midrule
IndoBERT-base &Baseline &\underline{66.67} &\underline{50.00} &\underline{58.82} &\underline{50.00} &\underline{40.0} \\
IndoBERT-base &Replace First &22.22 &25.00 &11.76 &18.18 &20.0 \\
IndoBERT-base &Replace Question Word &22.22 &25.00 &11.76 &18.18 &20.0 \\
IndoBERT-base &Add Adalah &22.22 &21.88 &11.76 &18.18 &20.0 \\
IndoBERT-base &Just Concat Answer and Question &22.22 &25.00 &11.76 &18.18 &20.0 \\
IndoBERT-base &Rule Base &22.22 &25.00 &11.76 &18.18 &20.0 \\
IndoBERT-base &Machine Generation With RB &22.22 &25.00 &11.76 &18.18 &20.0 \\
IndoBERT-base &Pure Machine Generation &22.22 &21.88 &11.76 &18.18 &20.0 \\
IndoBERT-base &Machine Generation With Translation &22.22 &21.88 &5.88 &9.09 &20.0 \\
\hline
IndoBERT-large &Baseline &\underline{55.56} &\underline{59.38} &\underline{47.06} &\underline{50.00} &\underline{65.0} \\
IndoBERT-large &Replace First &44.44 &56.25 &\underline{47.06} &45.45 &55.0 \\
IndoBERT-large &Replace Question Word &44.44 &56.25 &\underline{47.06} &45.45 &55.0 \\
IndoBERT-large &Add Adalah &44.44 &53.12 &\underline{47.06} &\underline{50.00} &60.0 \\
IndoBERT-large &Just Concat Answer and Question &33.33 &56.25 &\underline{47.06} &\underline{50.00} &60.0 \\
IndoBERT-large &Rule Base &44.44 &53.12 &\underline{47.06} &\underline{50.00} &55.0 \\
IndoBERT-large &Machine Generation With RB &\underline{55.56} &56.25 &41.18 &\underline{50.00} &\underline{65.0} \\
IndoBERT-large &Pure Machine Generation &\underline{55.56} &50.00 &\underline{47.06} &45.45 &65.0 \\
IndoBERT-large &Machine Generation With Translation &\underline{55.56} &50.00 &35.29 &45.45 &55.0 \\
\hline
XLMR-large &Baseline &\underline{88.89} &\underline{65.62} &\underline{58.82} &\underline{77.27} &\underline{65.0} \\
XLMR-large &Replace First &77.78 &62.50 &\underline{58.82} &72.73 &55.0 \\
XLMR-large &Replace Question Word &77.78 &62.50 &\underline{58.82} &72.73 &55.0 \\
XLMR-large &Add Adalah &66.67 &59.38 &\underline{58.82} &\underline{77.27} &\underline{65.0} \\
XLMR-large &Just Concat Answer and Question &66.67 &59.38 &\underline{58.82} &\underline{77.27} &60.0 \\
XLMR-large &Rule Base &77.78 &59.38 &\underline{58.82} &\underline{77.27} &55.0 \\
XLMR-large &Machine Generation With RB &77.78 &62.50 &47.06 &\underline{77.27} &\underline{65.0} \\
XLMR-large &Pure Machine Generation &\underline{88.89} &56.25 &\underline{58.82} &\underline{77.27} &\underline{65.0} \\
XLMR-large &Machine Generation With Translation &77.78 &56.25 &47.06 &63.64 &60.0 \\
\bottomrule
\end{tabular}
\caption{Tabel perbandingan persentase nilai benar dengan basis \emph{reasoning type} pada metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat pada \emph{dataset} pada TyDI-QA-ID.}
\end{table}

Pada sub-bab ini, penulis mencontohkan untuk \emph{dataset} TyDI-QA-ID, karena \emph{dataset} ini memberikan contoh yang penulis rasa lebih menarik, untuk kedua \emph{dataset} lainnya, penulis letakkan di bagian Lampiran \ref{Lampiran Terkait Tabel: 7.3}. Pada model \texttt{IndoBERT-base}, tidak ada \emph{reasoning type} yang naik persentase nilai benarnya pada semua \emph{dataset} yang penulis uji, lalu, \emph{reasoning type} SSR dan AoI berhasil naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} WM, PP, dan MSR selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Penurunan persentase nilai benar pada model ini berubah secara signifikan, dapat dilihat pada \emph{dataset} TyDI-QA-ID  dengan parameter \emph{machine generation with translation} di bagian \emph{reasoning type} MSR, persentase nilai benarnya turun sebesar 40.91\%.

Kemudian, pada model \texttt{IndoBERT-large}, tidak ada \emph{reasoning type} yang naik persentase nilai benarnya pada semua \emph{dataset} yang penulis uji, lalu, \emph{reasoning type} WM dan MSR berhasil naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} PP, SSR, dan AoI selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Terakhir, pada model \texttt{xlm-roberta-large}, tidak ada \emph{reasoning type} yang naik persentase nilai benarnya pada semua \emph{dataset} yang penulis uji, lalu, \emph{reasoning type} WM, PP, dan MSR berhasil naik persentase nilai benarnya pada hanya satu dari tiga \emph{dataset} yang penulis uji, sedangkan \emph{reasoning type} SSR dan AoI selalu turun maupun stagnan persentase nilai benarnya setelah menggunakan metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat. Penurunan persentase nilai benar pada model ini tidak berubah secara signifikan.

Secara pasti, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat tidak berhasil menjawab lebih banyak benarnya pada sebagian \emph{reasoning type} dalam ketiga model dan ketiga \emph{dataset} sistem tanya jawab yang diuji. Kemudian, tidak ada juga \emph{reasoning type} yang selalu turun pada setiap model dan \emph{dataset} yang penulis uji. Selain tipe pertanyaan di atas, metode \emph{task recasting} sebagai verifikator dengan parameter tipe perubahan format kalimat cenderung tidak berhasil meningkatkan persentase nilai benarnya pada sebagian besar model dan sebagian besar \emph{dataset}, dan penurunannya ini cenderung untuk tidak signifikan kecuali dengan model \emph{IndoBERT-base}.